{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp engine.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECODE Network\n",
    "\n",
    "> Definition of the classes and modules we use to build our DECODE network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "import torch.nn as nn\n",
    "import types\n",
    "from functools import partial\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def number_of_features_per_level(init_channel_number, num_levels):\n",
    "    return [init_channel_number * 2 ** k for k in range(num_levels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding):\n",
    "    \"\"\"\n",
    "    Create a list of modules with together constitute a single conv layer with non-linearity\n",
    "    and optional batchnorm/groupnorm.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size(int or tuple): size of the convolving kernel\n",
    "        order (string): order of things, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'gcr' -> groupnorm + conv + ReLU\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "            'bcr' -> batchnorm + conv + ReLU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    Return:\n",
    "        list of tuple (name, module)\n",
    "    \"\"\"\n",
    "    assert 'c' in order, \"Conv layer MUST be present\"\n",
    "    assert order[0] not in 'rle', 'Non-linearity cannot be the first operation in the layer'\n",
    "\n",
    "    modules = []\n",
    "    for i, char in enumerate(order):\n",
    "        if char == 'r':\n",
    "            modules.append(('ReLU', nn.ReLU(inplace=True)))\n",
    "        elif char == 'l':\n",
    "            modules.append(('LeakyReLU', nn.LeakyReLU(negative_slope=0.1, inplace=True)))\n",
    "        elif char == 'e':\n",
    "            modules.append(('ELU', nn.ELU(inplace=True)))\n",
    "        elif char == 'c':\n",
    "            # add learnable bias only in the absence of batchnorm/groupnorm\n",
    "            bias = not ('g' in order or 'b' in order)\n",
    "            modules.append(('conv', nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding, bias=bias, padding_mode='replicate')))\n",
    "        elif char == 'g':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                num_channels = in_channels\n",
    "            else:\n",
    "                num_channels = out_channels\n",
    "\n",
    "            # use only one group if the given number of groups is greater than the number of channels\n",
    "            if num_channels < num_groups:\n",
    "                num_groups = 1\n",
    "\n",
    "            assert num_channels % num_groups == 0, f'Expected number of channels in input to be divisible by num_groups. num_channels={num_channels}, num_groups={num_groups}'\n",
    "            modules.append(('groupnorm', nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)))\n",
    "        elif char == 'b':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(in_channels)))\n",
    "            else:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(out_channels)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported layer type '{char}'. MUST be one of ['b', 'g', 'r', 'l', 'e', 'c']\")\n",
    "\n",
    "    return modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SingleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Basic convolutional module consisting of a Conv3d, non-linearity and optional batchnorm/groupnorm. The order\n",
    "    of operations can be specified via the `order` parameter\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple):\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
    "        super(SingleConv, self).__init__()\n",
    "\n",
    "        for name, module in create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding=padding):\n",
    "            self.add_module(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DoubleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A module consisting of two consecutive convolution layers (e.g. BatchNorm3d+ReLU+Conv3d).\n",
    "    We use (Conv3d+ReLU+GroupNorm3d) by default.\n",
    "    This can be changed however by providing the 'order' argument, e.g. in order\n",
    "    to change to Conv3d+BatchNorm3d+ELU use order='cbe'.\n",
    "    Use padded convolutions to make sure that the output (H_out, W_out) is the same\n",
    "    as (H_in, W_in), so that you don't have to crop in the decoder path.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        encoder (bool): if True we're in the encoder path, otherwise we're in the decoder\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, encoder, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        if encoder:\n",
    "            # we're in the encoder path\n",
    "            conv1_in_channels = in_channels\n",
    "            conv1_out_channels = out_channels // 2\n",
    "            if conv1_out_channels < in_channels:\n",
    "                conv1_out_channels = in_channels\n",
    "            conv2_in_channels, conv2_out_channels = conv1_out_channels, out_channels\n",
    "        else:\n",
    "            # we're in the decoder path, decrease the number of channels in the 1st convolution\n",
    "            conv1_in_channels, conv1_out_channels = in_channels, out_channels\n",
    "            conv2_in_channels, conv2_out_channels = out_channels, out_channels\n",
    "\n",
    "        # conv1\n",
    "        self.add_module('SingleConv1',\n",
    "                        SingleConv(conv1_in_channels, conv1_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding))\n",
    "        # conv2\n",
    "        self.add_module('SingleConv2',\n",
    "                        SingleConv(conv2_in_channels, conv2_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Upsampling(nn.Module):\n",
    "    \"\"\"\n",
    "    Upsamples a given multi-channel 3D data using either interpolation or learned transposed convolution.\n",
    "    Args:\n",
    "        transposed_conv (bool): if True uses ConvTranspose3d for upsampling, otherwise uses interpolation\n",
    "        in_channels (int): number of input channels for transposed conv\n",
    "            used only if transposed_conv is True\n",
    "        out_channels (int): number of output channels for transpose conv\n",
    "            used only if transposed_conv is True\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "            used only if transposed_conv is True\n",
    "        scale_factor (int or tuple): stride of the convolution\n",
    "            used only if transposed_conv is True\n",
    "        mode (str): algorithm used for upsampling:\n",
    "            'nearest' | 'linear' | 'bilinear' | 'trilinear' | 'area'. Default: 'nearest'\n",
    "            used only if transposed_conv is False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transposed_conv, in_channels=None, out_channels=None, kernel_size=3,\n",
    "                 scale_factor=(2, 2, 2), mode='nearest'):\n",
    "        super(Upsampling, self).__init__()\n",
    "\n",
    "        if transposed_conv:\n",
    "            # make sure that the output size reverses the MaxPool3d from the corresponding encoder\n",
    "            # (D_out = (D_in − 1) ×  stride[0] − 2 ×  padding[0] +  kernel_size[0] +  output_padding[0])\n",
    "            self.upsample = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=kernel_size, stride=scale_factor,\n",
    "                                               padding=1)\n",
    "        else:\n",
    "            self.upsample = partial(self._interpolate, mode=mode)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        output_size = encoder_features.size()[2:]\n",
    "        return self.upsample(x, output_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def _interpolate(x, size, mode):\n",
    "        return F.interpolate(x, size=size, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module from the encoder path consisting of the optional max\n",
    "    pooling layer (one may specify the MaxPool kernel_size to be different\n",
    "    than the standard (2,2,2), e.g. if the volumetric data is anisotropic\n",
    "    (make sure to use complementary scale_factor in the decoder path) followed by\n",
    "    a DoubleConv module.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        apply_pooling (bool): if True use MaxPool3d before DoubleConv\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        pool_type (str): pooling layer: 'max' or 'avg'\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, apply_pooling=True,\n",
    "                 pool_kernel_size=2, pool_type='max', basic_module=DoubleConv, conv_layer_order='gcr',\n",
    "                 num_groups=8, padding=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        assert pool_type in ['max', 'avg']\n",
    "        if apply_pooling:\n",
    "            if pool_type == 'max':\n",
    "                self.pooling = nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
    "            else:\n",
    "                self.pooling = nn.AvgPool3d(kernel_size=pool_kernel_size)\n",
    "        else:\n",
    "            self.pooling = None\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=True,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.pooling is not None:\n",
    "            x = self.pooling(x)\n",
    "        x = self.basic_module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module for decoder path consisting of the upsampling layer\n",
    "    (either learned ConvTranspose3d or nearest neighbor interpolation) followed by a basic module (DoubleConv or ExtResNetBlock).\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        scale_factor (tuple): used as the multiplier for the image H/W/D in\n",
    "            case of nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation\n",
    "            from the corresponding encoder\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, scale_factor=(2, 2, 2), basic_module=DoubleConv,\n",
    "                 conv_layer_order='gcr', num_groups=8, mode='nearest', padding=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        if basic_module == DoubleConv:\n",
    "            # if DoubleConv is the basic_module use interpolation for upsampling and concatenation joining\n",
    "            self.upsampling = Upsampling(transposed_conv=False, in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=conv_kernel_size, scale_factor=scale_factor, mode=mode)\n",
    "            # concat joining\n",
    "            self.joining = partial(self._joining, concat=True)\n",
    "        else:\n",
    "            # if basic_module=ExtResNetBlock use transposed convolution upsampling and summation joining\n",
    "            self.upsampling = Upsampling(transposed_conv=True, in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=conv_kernel_size, scale_factor=scale_factor, mode=mode)\n",
    "            # sum joining\n",
    "            self.joining = partial(self._joining, concat=False)\n",
    "            # adapt the number of in_channels for the ExtResNetBlock\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=False,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        x = self.upsampling(encoder_features=encoder_features, x=x)\n",
    "        x = self.joining(encoder_features, x)\n",
    "        x = self.basic_module(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _joining(encoder_features, x, concat):\n",
    "        if concat:\n",
    "            return torch.cat((encoder_features, x), dim=1)\n",
    "        else:\n",
    "            return encoder_features + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Abstract3DUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for standard and residual UNet.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        final_sigmoid (bool): if True apply element-wise nn.Sigmoid after the\n",
    "            final 1x1 convolution, otherwise apply nn.Softmax. MUST be True if nn.BCELoss (two-class) is used\n",
    "            to train the model. MUST be False if nn.CrossEntropyLoss (multi-class) is used to train the model.\n",
    "        basic_module: basic model for the encoder/decoder (DoubleConv, ExtResNetBlock, ....)\n",
    "        layer_order (string): determines the order of layers\n",
    "            in `SingleConv` module. e.g. 'crg' stands for Conv3d+ReLU+GroupNorm3d.\n",
    "            See `SingleConv` for more info\n",
    "        f_maps (int, tuple): if int: number of feature maps in the first conv layer of the encoder (default: 64);\n",
    "            if tuple: number of feature maps at each level\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        num_levels (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
    "        is_segmentation (bool): if True (semantic segmentation problem) Sigmoid/Softmax normalization is applied\n",
    "            after the final convolution; if False (regression problem) the normalization layer is skipped at the end\n",
    "        testing (bool): if True (testing mode) the `final_activation` (if present, i.e. `is_segmentation=true`)\n",
    "            will be applied as the last operation during the forward pass; if False the model is in training mode\n",
    "            and the `final_activation` (even if present) won't be applied; default: False\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel in the basic_module\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        conv_padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, final_sigmoid, basic_module, f_maps=64, is_2D=False, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, testing=False,\n",
    "                 conv_kernel_size=3, pool_kernel_size=2, conv_padding=1, **kwargs):\n",
    "        super(Abstract3DUNet, self).__init__()\n",
    "\n",
    "        self.testing = testing\n",
    "        if is_2D:\n",
    "            conv_kernel_size = [1, conv_kernel_size, conv_kernel_size]\n",
    "            pool_kernel_size = [1, pool_kernel_size, pool_kernel_size]\n",
    "            conv_padding = [0, conv_padding, conv_padding]\n",
    "\n",
    "        if isinstance(f_maps, int):\n",
    "            f_maps = number_of_features_per_level(f_maps, num_levels=num_levels)\n",
    "\n",
    "        # create encoder path consisting of Encoder modules. Depth of the encoder is equal to `len(f_maps)`\n",
    "        encoders = []\n",
    "        for i, out_feature_num in enumerate(f_maps):\n",
    "            if i == 0:\n",
    "                encoder = Encoder(in_channels, out_feature_num,\n",
    "                                  apply_pooling=False,  # skip pooling in the firs encoder\n",
    "                                  basic_module=basic_module,\n",
    "                                  conv_layer_order=layer_order,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  num_groups=num_groups,\n",
    "                                  padding=conv_padding)\n",
    "            else:\n",
    "                # TODO: adapt for anisotropy in the data, i.e. use proper pooling kernel to make the data isotropic after 1-2 pooling operations\n",
    "                encoder = Encoder(f_maps[i - 1], out_feature_num,\n",
    "                                  basic_module=basic_module,\n",
    "                                  conv_layer_order=layer_order,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  num_groups=num_groups,\n",
    "                                  pool_kernel_size=pool_kernel_size,\n",
    "                                  padding=conv_padding)\n",
    "\n",
    "            encoders.append(encoder)\n",
    "\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "\n",
    "        # create decoder path consisting of the Decoder modules. The length of the decoder is equal to `len(f_maps) - 1`\n",
    "        decoders = []\n",
    "        reversed_f_maps = list(reversed(f_maps))\n",
    "        for i in range(len(reversed_f_maps) - 1):\n",
    "            if basic_module == DoubleConv:\n",
    "                in_feature_num = reversed_f_maps[i] + reversed_f_maps[i + 1]\n",
    "            else:\n",
    "                in_feature_num = reversed_f_maps[i]\n",
    "\n",
    "            out_feature_num = reversed_f_maps[i + 1]\n",
    "            # TODO: if non-standard pooling was used, make sure to use correct striding for transpose conv\n",
    "            # currently strides with a constant stride: (2, 2, 2)\n",
    "            decoder = Decoder(in_feature_num, out_feature_num,\n",
    "                              basic_module=basic_module,\n",
    "                              conv_layer_order=layer_order,\n",
    "                              conv_kernel_size=conv_kernel_size,\n",
    "                              num_groups=num_groups,\n",
    "                              padding=conv_padding)\n",
    "            decoders.append(decoder)\n",
    "\n",
    "        self.decoders = nn.ModuleList(decoders)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder part\n",
    "        encoders_features = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            # reverse the encoder outputs to be aligned with the decoder\n",
    "            encoders_features.insert(0, x)\n",
    "\n",
    "        # remove the last encoder's output from the list\n",
    "        # !!remember: it's the 1st in the list\n",
    "        encoders_features = encoders_features[1:]\n",
    "\n",
    "        # decoder part\n",
    "        for decoder, encoder_features in zip(self.decoders, encoders_features):\n",
    "            # pass the output from the corresponding encoder and the output\n",
    "            # of the previous decoder\n",
    "            x = decoder(encoder_features, x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UNet3D(Abstract3DUNet):\n",
    "    \"\"\"\n",
    "    3DUnet model from\n",
    "    `\"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation\"\n",
    "        <https://arxiv.org/pdf/1606.06650.pdf>`.\n",
    "    Uses `DoubleConv` as a basic_module and nearest neighbor upsampling in the decoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, final_sigmoid=True, f_maps=64, is_2D=False, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1,  **kwargs):\n",
    "        super(UNet3D, self).__init__(in_channels=in_channels, final_sigmoid=final_sigmoid,\n",
    "                                     basic_module=DoubleConv, f_maps=f_maps, is_2D=is_2D, layer_order=layer_order,\n",
    "                                     num_groups=num_groups, num_levels=num_levels, is_segmentation=is_segmentation,\n",
    "                                     conv_padding=conv_padding, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IntensityDist(nn.Module):\n",
    "    \"\"\"\n",
    "    Stores the three parameters that determine the distribution of intensities for simulator learning (and which are optimized during autoencoder learning)\n",
    "    Args:\n",
    "        int_conc, int_rate: parameters of the torch.distributions.gamma class.\n",
    "        int_loc: shift parameter. \n",
    "    \"\"\"\n",
    "    def __init__(self, int_conc, int_rate, int_loc):\n",
    "        super().__init__()\n",
    "        self.int_conc = torch.nn.Parameter(torch.tensor(float(int_conc)))\n",
    "        self.int_rate = torch.nn.Parameter(torch.tensor(float(int_rate)))\n",
    "        self.int_loc = torch.nn.Parameter(torch.tensor(float(int_loc)))  \n",
    "        \n",
    "class OutputNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes the output maps from the U-net and processes them seperately, using two conv3D layers for each group (xyzi_mean, xyzi_sigma, probability, background)\n",
    "    Args:\n",
    "        f_maps: number of channels of the U-net output\n",
    "        p_offset: probability channel bias \n",
    "    \"\"\"\n",
    "    def __init__(self, f_maps=64, p_offset=-5., is_2D=False, n_p_ch=1, n_bg_ch=1, n_int_ch=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.is_2D = is_2D\n",
    "        self.n_p_ch = n_p_ch\n",
    "        self.n_bg_ch = n_bg_ch\n",
    "        self.n_int_ch = n_int_ch\n",
    "        \n",
    "        xyzi_dim = 3 + n_int_ch\n",
    "        \n",
    "        kernel_size = [1,3,3] if is_2D else [3,3,3]\n",
    "        padding = [0,1,1] if is_2D else [1,1,1]\n",
    "\n",
    "        self.p_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.p_out2 = nn.Conv3d(f_maps, n_p_ch, kernel_size=1, padding=0)\n",
    "        nn.init.constant_(self.p_out2.bias,p_offset)\n",
    "        \n",
    "        self.xyzi_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.xyzi_out2 = nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.xyzis_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.xyzis_out2 = nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.bg_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.bg_out2 = nn.Conv3d(f_maps, n_bg_ch, kernel_size=1, padding=0)\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.p_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.p_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.xyzi_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.xyzi_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.xyzis_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.xyzis_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.bg_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.bg_out2.weight, mode='fan_in', nonlinearity='linear')    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        logit    = F.elu(self.p_out1(x))\n",
    "        logit    = self.p_out2(logit)\n",
    "        logit    = torch.clamp(logit, -20., 20)\n",
    "        \n",
    "        xyzi = F.elu(self.xyzi_out1(x))\n",
    "        xyzi = self.xyzi_out2(xyzi)\n",
    "\n",
    "        xyz_mu   = torch.tanh(xyzi[:, :3])\n",
    "\n",
    "        i_mu     = F.softplus(xyzi[:, 3:])\n",
    "        xyzi_mu = torch.cat((xyz_mu, i_mu), dim=1)\n",
    "        \n",
    "        xyzis = F.elu(self.xyzis_out1(x))\n",
    "        xyzis = self.xyzis_out2(xyzis)\n",
    "        xyzi_sig = F.softplus(xyzis) + 0.01\n",
    "        \n",
    "        background = F.elu(self.bg_out1(x))\n",
    "        background = self.bg_out2(background)\n",
    "        background = F.softplus(background)\n",
    "        return torch.cat([logit,xyzi_mu,xyzi_sig,background],1)\n",
    "            \n",
    "\n",
    "class UnetDecodeNoBn(nn.Module):\n",
    "    \"\"\"\n",
    "    Our DECODE network consists of a 3D U-net, and an output net module.\n",
    "    The network parameters can accessed through model.network\n",
    "    \n",
    "    We also store the parameters of the intensity distribution here for easier access. (model.int_dist)\n",
    "    \n",
    "    The forward function returns a tensor batch_size x 10 tensor to make it compatible with the monai.inferers.sliding_window_inference function.\n",
    "    \n",
    "    To get the final output dictionary one has to also apply the tensor_to_dict function.\n",
    "    \n",
    "    Args:\n",
    "        ch_in (int): number of input channels\n",
    "            Multiple input channels are currently not supported\n",
    "        depth (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
    "        inp_offset, inp_scale (float): Values used for normalizing the input. \n",
    "        order (string): determines the order of layers\n",
    "            in `SingleConv` module. e.g. 'ce' stands for Conv3d+ELU.\n",
    "            See `SingleConv` for more info\n",
    "            Before the input is given to the network is is normalized using these variables.\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        p_offset (float):\n",
    "            bias of the probabilty channel. The negative value avoids very high rates at the start of the training which might cause memory issues.\n",
    "        int_conc, int_rate (float): parameters of the torch.distributions.gamma class.\n",
    "        int_loc (float): shift parameter. \n",
    "        \n",
    "    ToDo:\n",
    "        Support for multiple channels?\n",
    "            \n",
    "            \n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in=1, depth=3, inp_scale=1., inp_offset=0., order='ce', f_maps=64, \n",
    "                 is_2D=False, pred_z=True, p_offset=-5., int_conc=4., int_rate=1., int_loc=1., n_p_ch=1, n_bg_ch=1, n_int_ch=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.inp_scale = inp_scale\n",
    "        self.inp_offset = inp_offset\n",
    "        \n",
    "        ch_in = ch_in #+ 3\n",
    "        \n",
    "        self.ch_in = ch_in\n",
    "        self.is_2D = is_2D\n",
    "        self.pred_z = pred_z\n",
    "        self.n_p_ch = n_p_ch\n",
    "        self.n_bg_ch = n_bg_ch\n",
    "        self.n_int_ch = n_int_ch\n",
    "        \n",
    "        self.unet = UNet3D(ch_in, final_sigmoid=False, num_levels=depth, is_2D=is_2D,\n",
    "                           layer_order = order, f_maps=f_maps)\n",
    "        self.outnet = OutputNet(f_maps=f_maps, p_offset=p_offset, is_2D=is_2D, n_p_ch=n_p_ch, n_bg_ch=n_bg_ch, n_int_ch=n_int_ch)\n",
    "        \n",
    "        self.network = nn.ModuleList([self.unet, self.outnet])\n",
    "        self.int_dist = IntensityDist(int_conc, int_rate, int_loc)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = (x-self.inp_offset) / self.inp_scale\n",
    "        \n",
    "        for net in self.network:\n",
    "            x = net(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "    def tensor_to_dict(self, x):\n",
    "        \n",
    "        logits = x[:, 0:self.n_p_ch]\n",
    "        xyzi_mu = x[:, self.n_p_ch:self.n_p_ch+3+self.n_int_ch]\n",
    "        xyzi_sig = x[:, self.n_p_ch+3+self.n_int_ch:self.n_p_ch+2*(3+self.n_int_ch)]\n",
    "        bg = x[:, self.n_p_ch+2*(3+self.n_int_ch):self.n_p_ch+2*(3+self.n_int_ch)+self.n_bg_ch]\n",
    "        \n",
    "        # Scale bg output\n",
    "        bg = bg * self.inp_scale #[None,:,None,None,None].to(bg.device)\n",
    "    \n",
    "        if not self.pred_z:\n",
    "        \n",
    "            xyzi_mu[:,3] *= 0\n",
    "            xyzi_sig[:,3] *= 0\n",
    "            xyzi_sig[:,3] += 1\n",
    "\n",
    "        ret_dict = {'logits': logits, \n",
    "                    'xyzi_mu': xyzi_mu, \n",
    "                    'xyzi_sigma': xyzi_sig, \n",
    "                    'background': bg}\n",
    "        \n",
    "        return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.funcs.utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1)\n",
    "inp = torch.randn([2,9,37,48,48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([3, 252, 7, 48, 48])\n",
      "xyzi_mu torch.Size([3, 25, 7, 48, 48])\n",
      "xyzi_sigma torch.Size([3, 25, 7, 48, 48])\n",
      "background torch.Size([3, 22, 7, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "model = UnetDecodeNoBn(order= 'ce', ch_in=22, f_maps=256, depth=2, is_2D=False, pred_z=False, n_p_ch=252, n_bg_ch=22, n_int_ch=22)\n",
    "output = model.tensor_to_dict(model(torch.randn([3,22,7,48,48])))\n",
    "# output = model.tensor_to_dict(model(torch.randn([7,16,1,48,48]), shuffle_ch=True))\n",
    "\n",
    "for k in output.keys():\n",
    "    print(k, output[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7ff696469310>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((output['logits'])[0,0,0].detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(output, '../data/model_batch_output_class2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = OmegaConf.load('../config/experiment/msp300_n2.yaml')\n",
    "# model = hydra.utils.instantiate(cfg.model, inp_scale=float(5), inp_offset=float(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6846244"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7436324"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9206564"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578542"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.unet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85831"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.outnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85831"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.outnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 20_MERFISH_visualization.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode2_dev]",
   "language": "python",
   "name": "conda-env-decode2_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
