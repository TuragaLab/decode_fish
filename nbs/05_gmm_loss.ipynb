{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp engine.gmm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from torch import distributions as D, Tensor\n",
    "from torch.distributions import Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PointProcessGaussian(Distribution):\n",
    "    def __init__(self, logits: torch.tensor, xyzi_mu: torch.tensor,\n",
    "                 xyzi_sigma: torch.tensor, **kwargs):\n",
    "        \"logits: BS, C, H, W, D\"\n",
    "        self.logits = logits\n",
    "        self.xyzi_mu = xyzi_mu\n",
    "        self.xyzi_sigma = xyzi_sigma\n",
    "\n",
    "    def sample(self, N:int =1):\n",
    "        if N ==1:\n",
    "            return self._sample()\n",
    "       \n",
    "        res_ = [self._sample() for i in range(N)]\n",
    "        locations   =  torch.cat([i[0] for i in res_], dim=1)\n",
    "        x_offset    =  torch.cat([i[1] for i in res_], dim=1)\n",
    "        y_offset    =  torch.cat([i[2] for i in res_], dim=1)\n",
    "        z_offset    =  torch.cat([i[3] for i in res_], dim=1)\n",
    "        intensities =  torch.cat([i[4] for i in res_], dim=1)\n",
    "        return locations, x_offset, y_offset, z_offset, intensities\n",
    "\n",
    "\n",
    "\n",
    "    def _sample(self):\n",
    "        #ask about this sampling\n",
    "        locations = D.Bernoulli(logits=self.logits).sample()\n",
    "        xyzi = D.Independent(D.Normal(self.xyzi_mu, self.xyzi_sigma),\n",
    "                             1).sample()\n",
    "        x_offset, y_offset, z_offset, intensities = (i.unsqueeze(1) for i in\n",
    "                                  torch.unbind(xyzi, dim=1))\n",
    "        \n",
    "        output_shape = tuple(locations.shape)\n",
    "        locations = locations.nonzero(as_tuple=True)\n",
    "        x_offset  = x_offset[locations]\n",
    "        y_offset  = y_offset[locations]        \n",
    "        z_offset  = z_offset[locations]\n",
    "        intensities = intensities[locations]\n",
    "        return locations, x_offset, y_offset, z_offset, intensities, output_shape\n",
    "\n",
    "\n",
    "    def log_prob(self, locations_3d, x_offset_3d, y_offset_3d, z_offset_3d, intensities_3d, p_threshold):\n",
    "        \n",
    "        batch_size = self.logits.shape[0]\n",
    "        xyzi, counts, s_mask = get_true_labels(batch_size, locations_3d, x_offset_3d, y_offset_3d, z_offset_3d, intensities_3d )\n",
    "        x_mu, y_mu, z_mu, i_mu = (i.unsqueeze(1) for i in\n",
    "                                  torch.unbind(self.xyzi_mu, dim=1))\n",
    "        x_si, y_si, z_si, i_si = (i.unsqueeze(1) for i in\n",
    "                                  torch.unbind(self.xyzi_sigma, dim=1))\n",
    "        \n",
    "        P = torch.sigmoid(self.logits) + 0.00001\n",
    "        count_mean = P.sum(dim=[2, 3, 4]).squeeze(-1)\n",
    "        count_var = (P - P ** 2).sum(dim=[2, 3, 4]).squeeze(-1)  #avoid situation where we have perfect match\n",
    "        count_dist = D.Normal(count_mean, torch.sqrt(count_var))\n",
    "        count_prob = count_dist.log_prob(counts)\n",
    "        mixture_probs = P / P.sum(dim=[2, 3, 4], keepdim=True)\n",
    "        \n",
    "        xyz_mu_list, _, _, i_mu_list, x_sigma_list, y_sigma_list, z_sigma_list, i_sigma_list, mixture_probs_l = img_to_coord(\n",
    "            batch_size, p_threshold, P, x_mu, y_mu, z_mu, i_mu, x_si, y_si, z_si, i_si, mixture_probs)\n",
    "        xyzi_mu = torch.cat((xyz_mu_list, i_mu_list), dim=-1)\n",
    "        xyzi_sigma = torch.cat((x_sigma_list, y_sigma_list, z_sigma_list, i_sigma_list), dim=-1) #to avoind NAN\n",
    "        mix = D.Categorical(mixture_probs_l.squeeze(-1))\n",
    "        comp = D.Independent(D.Normal(xyzi_mu, xyzi_sigma + 0.00001), 1)\n",
    "        spatial_gmm = D.MixtureSameFamily(mix, comp)\n",
    "        spatial_prob = spatial_gmm.log_prob(xyzi.transpose(0, 1)).transpose(0,1)\n",
    "        spatial_prob = (spatial_prob * s_mask).sum(-1)\n",
    "        log_prob = count_prob + spatial_prob\n",
    "        return log_prob\n",
    "    \n",
    "def img_to_coord(bs, p_quantile, locations, x_os, y_os, z_os, *args):\n",
    "    \"\"\"\n",
    "    Given `locations'  will extract value of x_os, y_os, z_os where probability is more than 0.\n",
    "    also generates counts of location and returns mask \n",
    "    \n",
    "    Args:\n",
    "        locations: Tuple(BS, Frames, D, H, W)\n",
    "        x_offsets: (N_emitters,)\n",
    "        y_offsets: (N_emitters,)\n",
    "        z_offsets: (N_emitters,)\n",
    "        intensities: (N_emitters,)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if type(locations) == torch.Tensor:\n",
    "        #this is done for model outputs since they are volumes\n",
    "        if p_quantile > 0:\n",
    "            threshold = torch.quantile(locations.flatten(1), p_quantile, dim=1)\n",
    "            locations = torch.nonzero(locations>threshold[:,None,None,None,None],as_tuple=True)\n",
    "        else:\n",
    "            locations = torch.nonzero(locations,as_tuple=True)\n",
    "        x_os      = x_os[locations]\n",
    "        y_os      = y_os[locations]\n",
    "        z_os      = z_os[locations] \n",
    "        a = [item[locations].unsqueeze(-1) for item in args]\n",
    "    else:    \n",
    "        a = [item.unsqueeze(-1) for item in args]\n",
    "        \n",
    "    # D == z 2, H == y 3, W == x 4\n",
    "    x =  x_os + locations[4].type(torch.cuda.FloatTensor) + 0.5 \n",
    "    y =  y_os + locations[3].type(torch.cuda.FloatTensor) + 0.5 \n",
    "    z =  z_os + locations[2].type(torch.cuda.FloatTensor) + 0.5 \n",
    "\n",
    "    xyz =  torch.stack((x, y, z), dim=1)\n",
    "    \n",
    "    #to match where in batch we have a counts (if there is no count at this \n",
    "    #position we will get 0 in tensor\n",
    "    counts_ = torch.unique_consecutive(locations[0], return_counts=True)[1]\n",
    "    bsz_loc = torch.unique(locations[0])\n",
    "    #getting batch size\n",
    "#     bs = (locations[0].max() + 1).item()\n",
    "    counts = torch.cuda.LongTensor(bs).fill_(0)\n",
    "    counts[bsz_loc] = counts_\n",
    "    \n",
    "    max_counts    = counts.max()\n",
    "    if max_counts==0: max_counts = 1 #if all 0 will return empty matrix of correct size\n",
    "    xyz_list = torch.cuda.FloatTensor(bs,max_counts,3).fill_(0)\n",
    "    i_list   = [torch.cuda.FloatTensor(bs,max_counts,1).fill_(0) for i in range(len(a))]\n",
    "    s_arr    = torch.cat([torch.arange(c) for c in counts], dim = 0)\n",
    "    s_mask   = torch.cuda.FloatTensor(bs,max_counts).fill_(0)\n",
    "    s_mask[locations[0],s_arr] = 1\n",
    "    xyz_list[locations[0],s_arr] = xyz\n",
    "    for i,k in zip(i_list, a): i[locations[0],s_arr] = k\n",
    "    return (xyz_list, counts, s_mask) + tuple(i_list)\n",
    "    \n",
    "def get_true_labels(bs, locations, x_os, y_os, z_os, ints):\n",
    "    xyz_list, counts_true, s_mask, i_1 = img_to_coord(bs, 0., locations, x_os, y_os, z_os, ints)\n",
    "    xyzi_true = torch.cat((xyz_list, i_1), dim=-1)\n",
    "    return xyzi_true, counts_true, s_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['logits', 'xyzi_mu', 'xyzi_sigma', 'background'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_out = torch.load('../data/model_output.pt')\n",
    "model_out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_loss = PointProcessGaussian(**model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train_sl.ipynb.\n",
      "Converted 14_train_ae.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode2_dev]",
   "language": "python",
   "name": "conda-env-decode2_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
