# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/23_MERFISH_comparison.ipynb (unless otherwise specified).

__all__ = ['get_istdeco_df', 'get_bardensr_tensor', 'get_bardensr_df']

# Cell
from ..imports import *

os.environ["CUDA_VISIBLE_DEVICES"] = '1'

from .file_io import *
from .emitter_io import *
from .utils import *
from .dataset import *
from .plotting import *
from ..engine.noise import estimate_noise_scale
import shutil
from .visualization import *
from .predict import predict
import torch.nn as nn
import torch.nn.functional as F
import torch.tensor as T
from .predict import *

from omegaconf import open_dict
from hydra import compose, initialize
from .merfish_eval import *

sys.path.append('/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/FQ/istdeco/')

from istdeco import ISTDeco
from utils import random_codebook, random_image_stack
from codebook import Codebook
from starfish.image import Filter

sys.path.append('/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/FQ/bardensr/')
import bardensr

import optuna
optuna.logging.set_verbosity(optuna.logging.INFO)

# Cell
def get_istdeco_df(sim_data, codebook, psf_sig=(1.7, 1.7), n_iter=100, bg=100.):

    istd_results = pd.DataFrame()

    n_rounds = codebook.shape[1]
    n_cols = codebook.shape[2]

    for i in range(len(sim_data)):

        image_data = sim_data[i,:,0]
        image_data = image_data.reshape([n_rounds,n_cols,image_data.shape[-2],image_data.shape[-1]], order='F')

        init_th = np.percentile(image_data,50)

        istdeco_model = ISTDeco(image_data, codebook, psf_sig, b=bg)
        X, Q, loss = istdeco_model.run(niter=n_iter)

        # Get codes
        code_id, y, x = np.where(np.logical_and(X>init_th,Q>0.1))

        intensity = X[code_id, y, x]
        quality = Q[code_id, y, x]

        # Store in dataframe
        df = pd.DataFrame(data={
                'frame_idx': i,
                'x': x.astype('float')+0.5,
                'y': y.astype('float')+0.5,
                'z': 0.5,
                'intensity': intensity,
                'quality': quality,
                'code_inds': code_id
        })

        istd_results = istd_results.append(df)

    istd_results = px_to_nm(istd_results)

    return istd_results

# Cell
def get_bardensr_tensor(sim_data, codebook, bg=100., n_iter=400, l1_pen=0.):

    bard_results = pd.DataFrame()
    evd_tensors = []
    codeflat = codebook.T

    for i in range(len(sim_data)):

        image_data = sim_data[i]
        Xnorm = bardensr.preprocessing.minmax(image_data - bg)

    #     Xnorm = bardensr.preprocessing.minmax(image_data)
    #     Xnorm = bardensr.preprocessing.background_subtraction(Xnorm,[0,10,10])
    #     Xnorm = bardensr.preprocessing.minmax(Xnorm)

        evidence_tensor_iterative,extra_learned_params=\
            bardensr.spot_calling.estimate_density_iterative(Xnorm.astype('float64'),codeflat,l1_penalty=l1_pen,use_tqdm_notebook=False,iterations=n_iter)

    #     evidence_tensor_iterative= bardensr.spot_calling.estimate_density_singleshot(Xnorm.astype('float64'), codeflat, noisefloor=0.05)

        evd_tensors.append(evidence_tensor_iterative)

    return evd_tensors

def get_bardensr_df(evd_tensors, th):

    bard_results = pd.DataFrame()

    for i in range(len(evd_tensors)):
    #     thresh_iterative=evd_tensors[i].max()*.1
        result_iterative=bardensr.spot_calling.find_peaks(evd_tensors[i],th, poolsize=(1.0,1.0,1.0))

        code_inds = np.array(result_iterative.j.values, dtype=np.int16)
        df = pd.DataFrame(data={
                    'frame_idx': i,
                    'x': result_iterative.m2.values + 0.5,
                    'y': result_iterative.m1.values + 0.5,
                    'z': 0.5,
                    'intensity': result_iterative.int.values,
                    'code_inds': code_inds
            })

        bard_results = bard_results.append(df)

    bard_results = px_to_nm(bard_results)
    return bard_results