{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random assortment of helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from itertools import product as iter_product\n",
    "from tifffile import imread\n",
    "\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()\n",
    "\n",
    "def free_mem():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()    \n",
    "    \n",
    "def center_crop(volume, zyx_ext):\n",
    "    \n",
    "    shape_3d = volume.shape[-3:]\n",
    "    center = [s//2 for s in shape_3d]\n",
    "    volume = volume[...,center[0]-math.floor(zyx_ext[0]/2):center[0]+math.ceil(zyx_ext[0]/2),\n",
    "                        center[1]-math.floor(zyx_ext[1]/2):center[1]+math.ceil(zyx_ext[1]/2),\n",
    "                        center[2]-math.floor(zyx_ext[2]/2):center[2]+math.ceil(zyx_ext[2]/2)]\n",
    "    return volume\n",
    "\n",
    "def smooth(x,window_len=11,window='flat'):\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n",
    "    \n",
    "def gaussian_sphere(shape, radius, position):\n",
    "    grid = [slice(-x0, dim - x0) for x0, dim in zip(position, shape)]\n",
    "    position = np.ogrid[grid]\n",
    "    arr = np.exp(-position[0]**2 / (2 * (radius[0] ** 2))) * np.exp(-position[1]**2 / (2 * (radius[1] ** 2))) * np.exp(-position[2]**2 / (2 * (radius[2] ** 2))) / (2 * np.pi * (radius[0] * radius[1] * radius[2]))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tiff_imread(path):\n",
    "    '''helper function to read tiff file with pathlib object or str'''\n",
    "    if isinstance(path, str) : return imread(path)\n",
    "    if isinstance(path, Path): return imread(str(path))\n",
    "    \n",
    "def load_tiff_image(image_path: str):\n",
    "    \"Given tiff stack path, loads the stack and converts it to a tensor. If necessary adds a dimension for the batch size\"\n",
    "    image_path = Path(image_path)\n",
    "    image  = torch.tensor(tiff_imread(image_path).astype('float32'))\n",
    "    if len(image.shape) == 3: image.unsqueeze_(0)\n",
    "    assert len(image.shape) == 4, 'the shape of image must be 4, (1, Z, X, Y)'\n",
    "    #removing minum values of the image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gpu(x):\n",
    "    '''Transforms numpy array or torch tensor torch torch.cuda.FloatTensor'''\n",
    "    return FloatTensor(x).cuda()\n",
    "\n",
    "def cpu(x):\n",
    "    '''Transforms torch tensor into numpy array'''\n",
    "    if torch.is_tensor(x):\n",
    "        return x.cpu().detach().numpy()\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def zip_longest_special(*iterables):\n",
    "    def filter(items, defaults):\n",
    "        return tuple(d if i is sentinel else i for i, d in zip(items, defaults))\n",
    "    sentinel = object()\n",
    "    iterables = itertools.zip_longest(*iterables, fillvalue=sentinel)\n",
    "    first = next(iterables)\n",
    "    yield filter(first, [None] * len(first))\n",
    "    for item in iterables:\n",
    "        yield filter(item, first)\n",
    "\n",
    "class param_iter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.keys = []\n",
    "        self.vals = []\n",
    "\n",
    "    def add(self, name, *args):\n",
    "\n",
    "        self.keys.append(name)\n",
    "        self.vals.append(args)\n",
    "\n",
    "    def param_product(self):\n",
    "\n",
    "        all_params = []\n",
    "        for values in iter_product(*self.vals):\n",
    "\n",
    "            params = dict()\n",
    "            for i,val in zip(self.keys,values):\n",
    "                params.update({i : val })\n",
    "\n",
    "            all_params.append(params)\n",
    "\n",
    "        return all_params\n",
    "\n",
    "    def param_zip(self):\n",
    "\n",
    "        all_params = []\n",
    "        for values in zip_longest_special(*self.vals):\n",
    "\n",
    "            params = dict()\n",
    "            for i,val in zip(self.keys,values):\n",
    "                params.update({i : val })\n",
    "\n",
    "            all_params.append(params)\n",
    "\n",
    "        return all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'lr': 0.001, 'lasso_mat': True}, {'lr': 0.001, 'lasso_mat': False}, {'lr': 0.005, 'lasso_mat': True}, {'lr': 0.005, 'lasso_mat': False}]\n",
      "[{'lr': 0.001, 'lasso_mat': True}, {'lr': 0.005, 'lasso_mat': False}]\n"
     ]
    }
   ],
   "source": [
    "variable_col = param_iter()\n",
    "variable_col.add('lr', 1e-3, 5e-3)\n",
    "variable_col.add('lasso_mat', True, False)\n",
    "\n",
    "par_prod = variable_col.param_product()\n",
    "print(par_prod)\n",
    "\n",
    "par_zip = variable_col.param_zip()\n",
    "print(par_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode2_dev]",
   "language": "python",
   "name": "conda-env-decode2_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
