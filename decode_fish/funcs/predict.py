# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/18_predict_funcs.ipynb (unless otherwise specified).

__all__ = ['predict', 'merfish_predict', 'selective_predict']

# Cell
from ..imports import *
from .file_io import *
from .emitter_io import *
from .utils import *
from monai.inferers import sliding_window_inference
from .plotting import *

# Cell
def predict(model, post_proc, image_paths, sm_fish_ch=0, window_size=[None,128,128], device='cuda'):
    pred_df = DF()
    with torch.no_grad():
        for p in tqdm(image_paths):
            print(p.split('/')[-1])
            img = load_tiff_image(p)[sm_fish_ch]
            z, y, x = img.shape[-3:]
            img = img.reshape(-1,z,y,x)

            for i in range(len(img)):
                print(img[i][None,None].shape)
                output = sliding_window_inference(img[i][None,None], window_size, 1, model.to(device), overlap=0.2, sw_device=device, device='cpu', mode='gaussian')
                # output = model.cpu()(img[i][None,None])
                output = model.tensor_to_dict(output)
                p_si = sliding_window_inference(output['logits'], window_size, 1, post_proc, overlap=0.2, sw_device=device, device='cpu', mode='gaussian')
                i_df = post_proc.get_df(output, p_si)
                print('N. emitters: ', len(i_df))
                pred_df = append_emitter_df(pred_df, i_df)
                free_mem()
        return pred_df

def merfish_predict(model, post_proc, image_paths, window_size=[None,256,256], crop=np.s_[:,:,:,:,:], bs=1, device='cuda'):
    pred_df = DF()
    with torch.no_grad():
        for p in image_paths:
#             print(p.split('/')[-1])
            if 'aligned' in p:
                from .exp_specific import read_MOp_tiff
                img = read_MOp_tiff(p, scaled=True, z_to_batch=True)
            else:
                img = load_tiff_image(p)

            print(img.shape)
            if img.ndim == 4:
                img = img[None]

            n_batches = int(np.ceil(len(img)/bs))

            for i in tqdm(range(n_batches)):

                inp = img[i*bs:(i+1)*bs][crop]
                output = sliding_window_inference(inp, window_size, 1, model.to(device), overlap=0.2, sw_device=device, device='cpu', mode='gaussian')
                output = model.tensor_to_dict(output)
                p_si = sliding_window_inference(output['logits'], window_size, 1, post_proc, overlap=0.2, sw_device=device, device='cpu', mode='gaussian')
                i_df = post_proc.get_df(output, p_si)
#                 i_df.loc[:,'frame_idx'] += i*bs
                pred_df = append_emitter_df(pred_df, i_df)
                free_mem()
        return pred_df

# Cell
def selective_predict(model, post_proc, image_paths, window_size=[None, 128, 128], threshold=-1e6, device='cuda'):
    pred_df = DF()
    with torch.no_grad():
        for p in tqdm(image_paths):
            print(p.split('/')[-1])
            img = load_tiff_image(p)
            z,y,x = img.shape[-3:]
            img = img.reshape(-1,z,y,x)
            for i in range(len(img)):
                print(img[i][None,None].shape)
                output = sliding_window_inference(img[i][None,None], window_size, sw_batch_size=1, predictor=model.to(device), overlap=0.2, threshold=threshold, sw_device=device, device='cpu', mode='gaussian')
                # output = model.cpu()(img[i][None,None])
                output = model.tensor_to_dict(output)
                p_si = sliding_window_inference(output['logits'], window_size, sw_batch_size=1, predictor=post_proc, overlap=0.2, threshold=-5, sw_device=device, device='cpu', mode='gaussian')
                i_df = post_proc.get_df(output, p_si)
                print('N. emitters: ', len(i_df))
                pred_df = append_emitter_df(pred_df, i_df)
                free_mem()
        return pred_df