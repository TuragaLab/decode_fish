{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random assortment of helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from itertools import product as iter_product\n",
    "from tifffile import imread\n",
    "\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()\n",
    "\n",
    "def free_mem():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()    \n",
    "    \n",
    "def center_crop(volume, zyx_ext):\n",
    "    \n",
    "    shape_3d = volume.shape[-3:]\n",
    "    center = [s//2 for s in shape_3d]\n",
    "    volume = volume[...,center[0]-math.floor(zyx_ext[0]/2):center[0]+math.ceil(zyx_ext[0]/2),\n",
    "                        center[1]-math.floor(zyx_ext[1]/2):center[1]+math.ceil(zyx_ext[1]/2),\n",
    "                        center[2]-math.floor(zyx_ext[2]/2):center[2]+math.ceil(zyx_ext[2]/2)]\n",
    "    return volume\n",
    "\n",
    "def smooth(x,window_len=11,window='flat'):\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n",
    "    \n",
    "def gaussian_sphere(shape, radius, position):\n",
    "    grid = [slice(-x0, dim - x0) for x0, dim in zip(position, shape)]\n",
    "    position = np.ogrid[grid]\n",
    "    arr = np.exp(-position[0]**2 / (2 * (radius[0] ** 2))) * np.exp(-position[1]**2 / (2 * (radius[1] ** 2))) * np.exp(-position[2]**2 / (2 * (radius[2] ** 2))) / (2 * np.pi * (radius[0] * radius[1] * radius[2]))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tiff_imread(path):\n",
    "    '''helper function to read tiff file with pathlib object or str'''\n",
    "    if isinstance(path, str) : return imread(path)\n",
    "    if isinstance(path, Path): return imread(str(path))\n",
    "    \n",
    "def load_tiff_image(image_path: str):\n",
    "    \"Given tiff stack path, loads the stack and converts it to a tensor. If necessary adds a dimension for the batch size\"\n",
    "    image_path = Path(image_path)\n",
    "    image  = torch.tensor(tiff_imread(image_path).astype('float32'))\n",
    "#     if len(image.shape) == 3: image.unsqueeze_(0)\n",
    "#     assert len(image.shape) == 4, 'the shape of image must be 4, (1, Z, X, Y)'\n",
    "    #removing minum values of the image\n",
    "    return image\n",
    "\n",
    "def load_tiff_from_list(path_list):\n",
    "    imgs = []\n",
    "    for p in path_list:\n",
    "        imgs.append(load_tiff_image(p))\n",
    "    return np.concatenate(imgs,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gpu(x):\n",
    "    '''Transforms numpy array or torch tensor torch torch.cuda.FloatTensor'''\n",
    "    return torch.cuda.FloatTensor(x).cuda()\n",
    "\n",
    "def cpu(x):\n",
    "    '''Transforms torch tensor into numpy array'''\n",
    "    if torch.is_tensor(x):\n",
    "        return x.cpu().detach().numpy()\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prepend_line(file_name, line):\n",
    "    \"\"\" Insert given string as a new line at the beginning of a file \"\"\"\n",
    "    dummy_file = file_name + '.bak'\n",
    "    with open(file_name, 'r') as read_obj, open(dummy_file, 'w') as write_obj:\n",
    "        write_obj.write(line + '\\n')\n",
    "        for line in read_obj:\n",
    "            write_obj.write(line)\n",
    "    os.remove(file_name)\n",
    "    os.rename(dummy_file, file_name)\n",
    "\n",
    "def zip_longest_special(*iterables):\n",
    "    def filter(items, defaults):\n",
    "        return tuple(d if i is sentinel else i for i, d in zip(items, defaults))\n",
    "    sentinel = object()\n",
    "    iterables = itertools.zip_longest(*iterables, fillvalue=sentinel)\n",
    "    first = next(iterables)\n",
    "    yield filter(first, [None] * len(first))\n",
    "    for item in iterables:\n",
    "        yield filter(item, first)\n",
    "\n",
    "class param_iter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.keys = []\n",
    "        self.vals = []\n",
    "\n",
    "    def add(self, name, *args):\n",
    "\n",
    "        self.keys.append(name)\n",
    "        self.vals.append(args)\n",
    "\n",
    "    def param_product(self):\n",
    "\n",
    "        all_params = []\n",
    "        for values in iter_product(*self.vals):\n",
    "\n",
    "            params = dict()\n",
    "            for i,val in zip(self.keys,values):\n",
    "                params.update({i : val })\n",
    "\n",
    "            all_params.append(params)\n",
    "\n",
    "        return all_params\n",
    "\n",
    "    def param_zip(self):\n",
    "\n",
    "        all_params = []\n",
    "        for values in zip_longest_special(*self.vals):\n",
    "\n",
    "            params = dict()\n",
    "            for i,val in zip(self.keys,values):\n",
    "                params.update({i : val })\n",
    "\n",
    "            all_params.append(params)\n",
    "\n",
    "        return all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'lr': 0.001, 'lasso_mat': True}, {'lr': 0.001, 'lasso_mat': False}, {'lr': 0.005, 'lasso_mat': True}, {'lr': 0.005, 'lasso_mat': False}]\n",
      "[{'lr': 0.001, 'lasso_mat': True}, {'lr': 0.005, 'lasso_mat': False}]\n"
     ]
    }
   ],
   "source": [
    "variable_col = param_iter()\n",
    "variable_col.add('lr', 1e-3, 5e-3)\n",
    "variable_col.add('lasso_mat', True, False)\n",
    "\n",
    "par_prod = variable_col.param_product()\n",
    "print(par_prod)\n",
    "\n",
    "par_zip = variable_col.param_zip()\n",
    "print(par_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def generate_perlin_noise_2d_torch(shape, res, device='cpu'):\n",
    "    ''' Adopted from https://pvigier.github.io/2018/11/02/2d-perlin-noise-numpy.html '''\n",
    "    \n",
    "    def f(t):\n",
    "        return 6*t**5 - 15*t**4 + 10*t**3\n",
    "    \n",
    "    delta = (res[0] / shape[0], res[1] / shape[1])\n",
    "    d = (shape[0] // res[0], shape[1] // res[1])\n",
    "    grid = torch.stack(torch.meshgrid(torch.arange(0, res[0], delta[0], device=device), \n",
    "                                      torch.arange(0, res[1], delta[1], device=device)), dim = -1) % 1\n",
    "    # Gradients\n",
    "    angles = 2*np.pi*torch.rand(res[0]+1, res[1]+1).to(device)\n",
    "    gradients = torch.stack((torch.cos(angles), torch.sin(angles)),  axis=2).to(device)\n",
    "    gradients = gradients.repeat_interleave(d[0], 0).repeat_interleave(d[1], 1)\n",
    "    g00 = gradients[    :-d[0],    :-d[1]]\n",
    "    g10 = gradients[d[0]:     ,    :-d[1]]\n",
    "    g01 = gradients[    :-d[0],d[1]:     ]\n",
    "    g11 = gradients[d[0]:     ,d[1]:     ]\n",
    "    # Ramps\n",
    "    n00 = torch.sum(torch.dstack((grid[:,:,0]  , grid[:,:,1]  )) * g00, 2)\n",
    "    n10 = torch.sum(torch.dstack((grid[:,:,0]-1, grid[:,:,1]  )) * g10, 2)\n",
    "    n01 = torch.sum(torch.dstack((grid[:,:,0]  , grid[:,:,1]-1)) * g01, 2)\n",
    "    n11 = torch.sum(torch.dstack((grid[:,:,0]-1, grid[:,:,1]-1)) * g11, 2)\n",
    "    # Interpolation\n",
    "    t = f(grid)\n",
    "    n0 = n00*(1-t[:,:,0]) + t[:,:,0]*n10\n",
    "    n1 = n01*(1-t[:,:,0]) + t[:,:,0]*n11\n",
    "    return np.sqrt(2.)*((1-t[:,:,1])*n0 + t[:,:,1]*n1)\n",
    "\n",
    "\n",
    "def generate_fractal_noise_2d_torch(shape, res, octaves=1, persistence=0.5, device='cpu'):\n",
    "\n",
    "    noise = torch.zeros(shape).to(device)\n",
    "    frequency = 1\n",
    "    amplitude = 1\n",
    "    for _ in range(octaves):\n",
    "        noise += amplitude * generate_perlin_noise_2d_torch(shape, (frequency*res[0], frequency*res[1]), device=device)\n",
    "        amplitude *= persistence\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    tra = generate_fractal_noise_2d_torch((48,48), (12,12), 1, 0.5, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def generate_perlin_noise_3d_torch(shape, res, device='cpu'):\n",
    "    ''' Adopted from https://pvigier.github.io/2018/11/02/3d-perlin-noise-numpy.html '''\n",
    "    def f(t):\n",
    "        return 6*t**5 - 15*t**4 + 10*t**3\n",
    "\n",
    "    delta = (res[0] / shape[0], res[1] / shape[1], res[2] / shape[2])\n",
    "    d = (shape[0] // res[0], shape[1] // res[1], shape[2] // res[2])\n",
    "    \n",
    "    grid = torch.stack(torch.meshgrid(torch.arange(0, res[0], delta[0], device=device), \n",
    "                                      torch.arange(0, res[1], delta[1], device=device), \n",
    "                                      torch.arange(0, res[2], delta[2], device=device)), dim = -1) % 1\n",
    "    \n",
    "    theta = 2*np.pi*torch.rand(res[0]+1, res[1]+1, res[2]+1).to(device)\n",
    "    phi = 2*np.pi*torch.rand(res[0]+1, res[1]+1, res[2]+1).to(device)\n",
    "    \n",
    "    gradients = torch.stack((torch.sin(phi)*torch.cos(theta), torch.sin(phi)*torch.sin(theta), torch.cos(phi)), axis=3)\n",
    "    gradients[-1] = gradients[0]\n",
    "        \n",
    "    g000 = gradients[0:-1,0:-1,0:-1].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)\n",
    "    g100 = gradients[1:  ,0:-1,0:-1].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)\n",
    "    g010 = gradients[0:-1,1:  ,0:-1].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)\n",
    "    g110 = gradients[1:  ,1:  ,0:-1].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)\n",
    "    g001 = gradients[0:-1,0:-1,1:  ].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)\n",
    "    g101 = gradients[1:  ,0:-1,1:  ].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)\n",
    "    g011 = gradients[0:-1,1:  ,1:  ].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)\n",
    "    g111 = gradients[1:  ,1:  ,1:  ].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)\n",
    "#     # Ramps\n",
    "    n000 = torch.sum(torch.stack((grid[:,:,:,0]  , grid[:,:,:,1]  , grid[:,:,:,2]  ), axis=3) * g000, 3)\n",
    "    n100 = torch.sum(torch.stack((grid[:,:,:,0]-1, grid[:,:,:,1]  , grid[:,:,:,2]  ), axis=3) * g100, 3)\n",
    "    n010 = torch.sum(torch.stack((grid[:,:,:,0]  , grid[:,:,:,1]-1, grid[:,:,:,2]  ), axis=3) * g010, 3)\n",
    "    n110 = torch.sum(torch.stack((grid[:,:,:,0]-1, grid[:,:,:,1]-1, grid[:,:,:,2]  ), axis=3) * g110, 3)\n",
    "    n001 = torch.sum(torch.stack((grid[:,:,:,0]  , grid[:,:,:,1]  , grid[:,:,:,2]-1), axis=3) * g001, 3)\n",
    "    n101 = torch.sum(torch.stack((grid[:,:,:,0]-1, grid[:,:,:,1]  , grid[:,:,:,2]-1), axis=3) * g101, 3)\n",
    "    n011 = torch.sum(torch.stack((grid[:,:,:,0]  , grid[:,:,:,1]-1, grid[:,:,:,2]-1), axis=3) * g011, 3)\n",
    "    n111 = torch.sum(torch.stack((grid[:,:,:,0]-1, grid[:,:,:,1]-1, grid[:,:,:,2]-1), axis=3) * g111, 3)\n",
    "#     # Interpolation\n",
    "    t = f(grid)\n",
    "    n00 = n000*(1-t[:,:,:,0]) + t[:,:,:,0]*n100\n",
    "    n10 = n010*(1-t[:,:,:,0]) + t[:,:,:,0]*n110\n",
    "    n01 = n001*(1-t[:,:,:,0]) + t[:,:,:,0]*n101\n",
    "    n11 = n011*(1-t[:,:,:,0]) + t[:,:,:,0]*n111\n",
    "    n0 = (1-t[:,:,:,1])*n00 + t[:,:,:,1]*n10\n",
    "    n1 = (1-t[:,:,:,1])*n01 + t[:,:,:,1]*n11\n",
    "    return ((1-t[:,:,:,2])*n0 + t[:,:,:,2]*n1)\n",
    "\n",
    "def generate_fractal_noise_3d_torch(shape, res, octaves=1, persistence=0.5, device='cpu'):\n",
    "    noise = torch.zeros(shape, device=device)\n",
    "    frequency = 1\n",
    "    amplitude = 1\n",
    "    for _ in range(octaves):\n",
    "        noise += amplitude * generate_perlin_noise_3d_torch(shape, (frequency*res[0], frequency*res[1], frequency*res[2]), device=device)\n",
    "        frequency *= 2\n",
    "        amplitude *= persistence\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    tra = generate_fractal_noise_3d_torch((48,48,48), (3,6,6), 3, 0.5, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    tra = generate_fractal_noise_3d((48,48,48), (3,6,6), 3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 20_MERFISH_visualization.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode2_dev]",
   "language": "python",
   "name": "conda-env-decode2_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
