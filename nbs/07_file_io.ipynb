{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from decode_fish.funcs.utils import *\n",
    "from tifffile import imread\n",
    "from decode_fish.engine.microscope import Microscope\n",
    "from decode_fish.engine.psf import crop_psf\n",
    "from decode_fish.engine.psf import LinearInterpolatedPSF\n",
    "from decode_fish.funcs.emitter_io import *\n",
    "from decode_fish.funcs.dataset import *\n",
    "from torch.utils.data import DataLoader\n",
    "from collections.abc import MutableSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_model_state(model, path):\n",
    "    \"\"\"\n",
    "    Loads the network parameters, the intensity parameters and the scaling into model given a path.\n",
    "    \"\"\"\n",
    "    model_dict = torch.load(path)\n",
    "    model.load_state_dict(model_dict['state_dict'])\n",
    "    model.inp_scale = model_dict['scaling'][0]\n",
    "    model.inp_offset = model_dict['scaling'][1]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def swap_psf_vol(psf, vol):\n",
    "    state_dict = psf.state_dict()\n",
    "    for i in range(len(state_dict['psf_volume'])):\n",
    "        state_dict['psf_volume'][i] = torch.cuda.FloatTensor(torch.Tensor(vol).cuda())\n",
    "    psf.load_state_dict(state_dict)\n",
    "    return psf\n",
    "\n",
    "def get_gaussian_psf(size_zyx, radii, pred_z, n_cols=1):\n",
    "    \n",
    "    if not pred_z:\n",
    "        size_zyx[0] = 1\n",
    "        \n",
    "    if not isinstance(radii, MutableSequence):\n",
    "        radii = 3*[radii]\n",
    "    \n",
    "    psf = LinearInterpolatedPSF(size_zyx, device='cuda', n_cols=n_cols)\n",
    "    gauss_vol = gaussian_sphere(size_zyx, radii, [size_zyx[0]//2,size_zyx[1]//2,size_zyx[2]//2])\n",
    "    gauss_vol = gauss_vol/gauss_vol.max()\n",
    "    \n",
    "    psf = swap_psf_vol(psf, gauss_vol)\n",
    "    return psf\n",
    "\n",
    "def get_vol_psf(filename, device='cuda', psf_extent_zyx=None):\n",
    "    \n",
    "    if 'tif' in filename:\n",
    "        psf_vol = load_tiff_image(filename)\n",
    "        psf_vol = psf_vol/psf_vol.max()\n",
    "        psf = LinearInterpolatedPSF(psf_vol.shape[-3:], device=device)\n",
    "        psf = swap_psf_vol(psf, psf_vol)\n",
    "\n",
    "    else:\n",
    "        psf_state = torch.load(filename)\n",
    "        psf = LinearInterpolatedPSF(psf_state['psf_volume'].shape[-3:], device=device)\n",
    "        psf.load_state_dict(psf_state)\n",
    "\n",
    "        if psf_extent_zyx:\n",
    "            psf = crop_psf(psf,psf_extent_zyx)\n",
    "            \n",
    "    return psf\n",
    "\n",
    "def load_psf(cfg):\n",
    "\n",
    "    if cfg.data_path.psf_path:\n",
    "        psf = get_vol_psf(cfg.data_path.psf_path,cfg.genm.PSF.device, cfg.genm.PSF.psf_extent_zyx)\n",
    "    else:\n",
    "        psf = get_gaussian_psf(cfg.genm.PSF.psf_extent_zyx, cfg.genm.PSF.gauss_radii, cfg.genm.exp_type.pred_z, cfg.genm.PSF.n_cols)\n",
    "        \n",
    "    return psf\n",
    "\n",
    "def load_psf_noise_micro(cfg):\n",
    "    \n",
    "    psf = load_psf(cfg)\n",
    "    noise = hydra.utils.instantiate(cfg.genm.noise)\n",
    "    if 'max' in cfg.genm.microscope.norm:\n",
    "        micro = hydra.utils.instantiate(cfg.genm.microscope, psf=psf, noise=noise).cuda()\n",
    "    else:\n",
    "        micro = hydra.utils.instantiate(cfg.genm.microscope, psf=psf, noise=noise, sum_fac=psf.psf_volume.sum().item()).cuda()\n",
    "    return psf, noise, micro\n",
    "\n",
    "def load_post_proc(cfg):\n",
    "    if cfg.other.pp == 'si':\n",
    "        return hydra.utils.instantiate(cfg.post_proc_si)\n",
    "    if cfg.other.pp == 'isi':\n",
    "        return hydra.utils.instantiate(cfg.post_proc_isi)\n",
    "    \n",
    "def get_dataloader(cfg):\n",
    "    \n",
    "    sim = True if cfg.data_path.image_path is None else False\n",
    "    sl = eval(cfg.data_path.image_proc.crop_sl,{'__builtins__': None},{'s_': np.s_})\n",
    "\n",
    "    if not sim:\n",
    "        if 'override' in cfg.data_path.image_proc:\n",
    "            imgs_3d = [hydra.utils.instantiate(cfg.data_path.image_proc.override, image_path=f) for f in sorted(glob.glob(cfg.data_path.image_path))]\n",
    "        else:\n",
    "            imgs_3d   = [load_tiff_image(f) for f in sorted(glob.glob(cfg.data_path.image_path))]    \n",
    "        imgs_3d       = [img.permute(*cfg.data_path.image_proc.swap_dim)[sl] for img in imgs_3d] \n",
    "        roi_masks     = [get_roi_mask(img, tuple(cfg.sim.roi_mask.pool_size), percentile= cfg.sim.roi_mask.percentile) for img in imgs_3d]\n",
    "    else:\n",
    "        imgs_3d       = [torch.empty(list(cfg.data_path.image_shape))]\n",
    "        roi_masks     = None\n",
    "        gen_bg        = [hydra.utils.instantiate(cfg.sim.bg_estimation.uniform)]\n",
    "        dataset_tfms  = []\n",
    "        \n",
    "    min_shape = tuple(np.stack([v.shape for v in imgs_3d]).min(0)[-3:])\n",
    "    crop_zyx = (cfg.sim.random_crop.crop_sz, cfg.sim.random_crop.crop_sz,cfg.sim.random_crop.crop_sz)\n",
    "    if crop_zyx > min_shape:\n",
    "        crop_zyx = tuple(np.stack([min_shape, crop_zyx]).min(0))\n",
    "        print('Crop size larger than volume in at least one dimension. Crop size changed to', crop_zyx)\n",
    "        \n",
    "    if not sim:\n",
    "        gen_bg        = [hydra.utils.instantiate(cfg.sim.bg_estimation.smoothing, z_size=crop_zyx[0])]\n",
    "        rand_crop = RandomCrop3D(crop_zyx, roi_masks)\n",
    "        dataset_tfms  = [rand_crop]\n",
    "    \n",
    "    if cfg.sim.bg_estimation.fractal.scale:\n",
    "        gen_bg.append(hydra.utils.instantiate(cfg.sim.bg_estimation.fractal))\n",
    "\n",
    "    probmap_generator = UniformValue(cfg.genm.prob_generator.low, cfg.genm.prob_generator.high)\n",
    "    rate_tfms = [probmap_generator]\n",
    "    \n",
    "    if cfg.genm.foci.n_foci_avg > 0:\n",
    "        rate_tfms.append(hydra.utils.instantiate(cfg.genm.foci))\n",
    "\n",
    "    ds = DecodeDataset(volumes = imgs_3d,\n",
    "                       dataset_tfms =  dataset_tfms, \n",
    "                       rate_tfms = rate_tfms, \n",
    "                       bg_tfms = gen_bg, \n",
    "                       device='cuda:0', \n",
    "                       num_iter=(cfg.training.num_iters) * cfg.training.bs) \n",
    "\n",
    "    decode_dl = DataLoader(ds, batch_size=cfg.training.bs, num_workers=0)\n",
    "    \n",
    "    return imgs_3d, decode_dl\n",
    "    \n",
    "def load_all(cfg):\n",
    "    \n",
    "    path = Path(cfg.output.save_dir)\n",
    "    model = hydra.utils.instantiate(cfg.network)\n",
    "    model = load_model_state(model, path/'model.pkl')\n",
    "    post_proc = hydra.utils.instantiate(cfg.post_proc_isi, samp_threshold=0.5)\n",
    "    _, noise, micro = load_psf_noise_micro(cfg)\n",
    "    micro.load_state_dict(torch.load(path/'microscope.pkl'))\n",
    "    img_3d, decode_dl = get_dataloader(cfg)\n",
    "    \n",
    "    return model, post_proc, micro, img_3d, decode_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('../config/experiment/MERFISH_ci_2d_sl12.yaml')\n",
    "if 'n_cols' not in cfg.PSF:\n",
    "    cfg.PSF.n_cols = 1\n",
    "# cfg = OmegaConf.load(default_conf)\n",
    "psf = load_psf(cfg)\n",
    "# psf.load_state_dict(torch.load(Path(cfg.output.save_dir)/'psf.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.data_path.image_path = None\n",
    "# cfg.data_path.image_shape = [16,1,48,48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop size larger than volume in at least one dimension. Crop size changed to (1, 48, 48)\n",
      "tra\n",
      "1 volumes\n"
     ]
    }
   ],
   "source": [
    "imgs_3d, decode_dl = get_dataloader(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from decode_fish.funcs.plotting import *\n",
    "# plot_3d_projections(psf.psf_volume[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    x, local_rate, background = next(iter(decode_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_zyx = [1,21,21]\n",
    "\n",
    "vol_3d = []\n",
    "facs = np.linspace(0.7,1.3,11)\n",
    "for i in range(len(facs)):\n",
    "    \n",
    "    s = gaussian_sphere(size_zyx, [1.7,1.7*facs[i],1.7*facs[i]], [size_zyx[0]//2,size_zyx[1]//2,size_zyx[2]//2])\n",
    "    vol_3d.append(s)\n",
    "    \n",
    "vol_3d = np.concatenate(vol_3d,0)\n",
    "vol_3d /= vol_3d.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "tifffile.imsave('../figures/MF_psf.tif', data=vol_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 20_MERFISH_visualization.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode2_dev]",
   "language": "python",
   "name": "conda-env-decode2_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
