{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp engine.microscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microscope model\n",
    "\n",
    "> Definition of the classes and functions we use to generate recordings given network outputs or simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "import torch.nn as nn\n",
    "from decode_fish.funcs.utils import *\n",
    "from torch.jit import script\n",
    "from typing import Union, List\n",
    "import torch.nn.functional as F\n",
    "from decode_fish.funcs.plotting import *\n",
    "from decode_fish.engine.place_psfs import _place_psf, CudaPlaceROI\n",
    "# import elasticdeform.torch as etorch\n",
    "import kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Microscope(nn.Module):\n",
    "    \"\"\"\n",
    "    The Mircoscope module takes  5 vectors 'locations', 'x_os', 'y_os', 'z_os',\n",
    "    'ints_3d' turns them into 3D data through the following steps:\n",
    "    1) Apply continuous shifts to the PSF according to x_os, y_os, z_os\n",
    "    2) Clamping the PSF (retaining only positive values)\n",
    "    3) Normalize the PSF dividing it by it's max value\n",
    "    6) Place point spread function according to locations  to\n",
    "    generate 'x_sim'\n",
    "    7) Multiplies x_sim with scale\n",
    "\n",
    "    Args:\n",
    "        psf (torch.nn.Module): Parametric PSF\n",
    "        noise (torch.nn.Module): Camera noise model\n",
    "        scale(float): Constant for scaling \n",
    "        \n",
    "    Shape:\n",
    "        -Input: locations: Tuple(torch.Tensor)\n",
    "                x_os_val: (N_emitters,)\n",
    "                y_os_val: (N_emitters,)\n",
    "                z_os_val: (N_emitters,)\n",
    "                ints_val: (N_emitters,C)\n",
    "                output_shape: Shape Tuple(BS, C, H, W, D)\n",
    "\n",
    "        -Output: xsim: (BS, C, H, W, D)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, psf: torch.nn.Module=None, noise: Union[torch.nn.Module, None]=None, scale: float = 10000., norm='max', psf_noise=0, pos_noise_xy=0, pos_noise_z=0, slice_rec=False, ch_facs=None, ch_cols=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.psf = psf\n",
    "        self.psf_init_vol = psf.psf_volume.detach().to('cuda')\n",
    "        self.scale = scale\n",
    "        self.noise = noise\n",
    "        self.norm = norm\n",
    "        \n",
    "        self.psf_norm_init = 1.\n",
    "        if slice_rec:\n",
    "            if norm == 'sum':\n",
    "                self.psf_norm_init = self.psf.psf_volume.detach().sum(2, keepdim=True).sum(3, keepdim=True).to('cuda')\n",
    "            if norm == 'max':\n",
    "                self.psf_norm_init = self.psf.psf_volume.detach().amax(2, keepdim=True).amax(3, keepdim=True).to('cuda')\n",
    "        else:\n",
    "            if norm == 'sum':\n",
    "                self.psf_norm_init = self.psf.psf_volume.detach().sum().to('cuda')\n",
    "            if norm == 'max':\n",
    "                self.psf_norm_init = self.psf.psf_volume.detach().amax().to('cuda')        \n",
    "        \n",
    "        self.theta = self.noise.theta_scale * self.noise.theta_par\n",
    "        \n",
    "        self.psf_noise = psf_noise\n",
    "        self.pos_noise_xy = pos_noise_xy\n",
    "        self.pos_noise_z = pos_noise_z\n",
    "\n",
    "        self.slice_rec = slice_rec\n",
    "        self.psf_z_size = self.psf.psf_volume.shape[-3]\n",
    "        self.ch_cols = ch_cols\n",
    "        \n",
    "        self.register_parameter(name='channel_shifts', param=self.noise.channel_shifts)\n",
    "\n",
    "        ###      \n",
    "        self.register_parameter(name='color_shifts', param=torch.nn.Parameter(torch.zeros([2, 3, 41, 41])))\n",
    "        ###\n",
    "        \n",
    "        self.ch_scale = 1. if ch_facs is None else torch.tensor(ch_facs).cuda()\n",
    "        self.register_parameter(name='channel_facs', param=torch.nn.Parameter(torch.ones(len(self.channel_shifts))))\n",
    "        self.ch_norm = self.channel_facs.sum().detach().cuda()\n",
    "            \n",
    "        self.register_parameter(name='theta_par', param=self.noise.theta_par)\n",
    "        self.register_parameter(name='psf_vol', param=self.psf.psf_volume)\n",
    "        \n",
    "    def add_psf_noise(self, psf_stack):\n",
    "\n",
    "        '''Gaussian noise'''\n",
    "        noise = torch.distributions.Normal(loc=0, scale=self.psf_noise).sample(psf_stack.shape).to(psf_stack.device)\n",
    "        noise *= torch.sqrt(psf_stack)\n",
    "#         noise *= torch.rand(len(psf_stack), device='cuda')[:,None,None,None,None]\n",
    "        return psf_stack + noise\n",
    "    \n",
    "        '''Individual elastic deformation for each PSF (to slow)'''\n",
    "#         psf_deformed = torch.cat([etorch.deform_grid(psf, torch.distributions.Normal(loc=0, scale=self.psf_noise).sample([3,3,3,3]).to(psf_stack.device), order=3)[None] \n",
    "#                                   for psf in psf_stack[:,0]])\n",
    "        '''Single deformation for all PSF in batch (kinda stupid)'''\n",
    "#         psf_deformed = etorch.deform_grid(psf_stack[:,0], torch.distributions.Normal(loc=0, scale=self.psf_noise).sample([3,3,3,3]).to(psf_stack.device), axis=(1,2,3),order=3)\n",
    "#         return psf_deformed[:,None]\n",
    "\n",
    "    def add_pos_noise(self, x_os, y_os, z_os):\n",
    "        \n",
    "        # Hardcoded n_bits for now. \n",
    "        x_n = torch.distributions.Normal(loc=0, scale=self.pos_noise_xy).sample(x_os.shape).to(x_os.device).reshape(-1,4)\n",
    "        x_n -= x_n.mean(-1, keepdim=True)\n",
    "        x_os = x_os + x_n.reshape(-1)\n",
    "        y_n = torch.distributions.Normal(loc=0, scale=self.pos_noise_xy).sample(y_os.shape).to(y_os.device).reshape(-1,4)\n",
    "        y_n -= y_n.mean(-1, keepdim=True)\n",
    "        y_os = y_os + y_n.reshape(-1)\n",
    "        z_n = torch.distributions.Normal(loc=0, scale=self.pos_noise_z).sample(z_os.shape).to(z_os.device).reshape(-1,4)\n",
    "        z_n -= z_n.mean(-1, keepdim=True)\n",
    "        z_os = z_os + z_n.reshape(-1)\n",
    "        \n",
    "        return x_os, y_os, z_os\n",
    "\n",
    "    def get_single_ch_inputs(self, locations, x_os_val, y_os_val, z_os_val, i_val, output_shape=None, ycrop=0, xcrop=0):\n",
    "        \n",
    "        ch_inds = i_val.nonzero(as_tuple=True)\n",
    "        \n",
    "        if ch_inds[1].max() > 0:\n",
    "            \n",
    "            locations = [l[ch_inds[0]] for l in locations]\n",
    "            locations.insert(1,ch_inds[1])   \n",
    "            \n",
    "            shifts = self.channel_shifts - self.channel_shifts.mean(0)[None]\n",
    "\n",
    "            ###\n",
    "            c_inds = torch.tensor(self.ch_cols)[ch_inds[1]]\n",
    "            blurred_col_shift = kornia.filters.gaussian_blur2d(self.color_shifts,  (9,9), (3,3))\n",
    "            col_shifts = blurred_col_shift[c_inds, :, (locations[2][ch_inds[0]] + ycrop.cuda()[locations[0]])//50, (locations[3][ch_inds[0]] + xcrop.cuda()[locations[0]])//50]\n",
    "            ###\n",
    "\n",
    "            x_os_ch = x_os_val[ch_inds[0]] + shifts[ch_inds[1], 0] + col_shifts[:, 0]\n",
    "            y_os_ch = y_os_val[ch_inds[0]] + shifts[ch_inds[1], 1] + col_shifts[:, 1]\n",
    "            z_os_ch = z_os_val[ch_inds[0]] + shifts[ch_inds[1], 2] + col_shifts[:, 2]\n",
    "\n",
    "            i_val = i_val[ch_inds]\n",
    "            \n",
    "            \n",
    "        return locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape\n",
    "    \n",
    "    def get_psf_norm(self, c_inds = None, z_inds=None):\n",
    "        \n",
    "        if self.norm != 'max' and self.norm != 'sum':\n",
    "            return 1.\n",
    "        if not self.slice_rec:\n",
    "            if self.norm == 'max': psf_norm = self.psf.psf_volume.max() \n",
    "            if self.norm == 'sum': psf_norm = torch.clamp_min(self.psf.psf_volume, 0).sum() \n",
    "            init = self.psf_norm_init     \n",
    "        else:\n",
    "            if self.norm == 'max':\n",
    "                psf_norm = self.psf.psf_volume.amax(2, keepdim=True).amax(3, keepdim=True)\n",
    "            if self.norm == 'sum':\n",
    "                psf_norm = torch.clamp_min(self.psf.psf_volume, 0).sum(2, keepdim=True).sum(3, keepdim=True)\n",
    "            if c_inds is not None:\n",
    "                psf_norm = psf_norm[c_inds, z_inds][:,:,None,None]\n",
    "                init = self.psf_norm_init[c_inds, z_inds][:,:,None,None]\n",
    "            else:\n",
    "                psf_norm = psf_norm[0,z_inds][:,None,None]\n",
    "                init = self.psf_norm_init[0,z_inds][:,None,None]\n",
    "  \n",
    "        return psf_norm/init\n",
    "        \n",
    "    def forward(self, locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, ret_psfs=False, add_noise=False, add_pos_noise=False):\n",
    "        \n",
    "        if len(locations[0]):\n",
    "            c_inds=torch.tensor(self.ch_cols)[locations[1]] if self.ch_cols is not None else None\n",
    "\n",
    "            # Apply continuous shift\n",
    "            if self.slice_rec and self.psf_z_size > 1:\n",
    "                z_os_ch = torch.clamp(z_os_ch,-0.49999,0.49999) + 0.5 # transform to [0,1]\n",
    "                z_scaled = z_os_ch * (self.psf_z_size - 2) # [0, z_size]\n",
    "                z_inds = (z_scaled//1).type(torch.cuda.LongTensor) + 1\n",
    "                z_os = -(z_scaled%1.) + 0.5\n",
    "\n",
    "                if self.pos_noise_xy and add_pos_noise: \n",
    "                    x_os_ch, y_os_ch, z_os = self.add_pos_noise(x_os_ch, y_os_ch, z_os)\n",
    "\n",
    "                psf = self.psf(x_os_ch, y_os_ch, z_os, z_inds, c_inds=c_inds)\n",
    "#                 psf = psf[torch.arange(len(z_os_ch)),:,z_inds][:,:,None]\n",
    "            else:\n",
    "                if self.pos_noise_xy and add_noise: \n",
    "                    x_os_ch, y_os_ch, z_os_ch = self.add_pos_noise(x_os_ch, y_os_ch, z_os_ch)\n",
    "                psf = self.psf(x_os_ch, y_os_ch, z_os_ch, c_inds=c_inds)\n",
    "                z_inds = None\n",
    "                \n",
    "            torch.clamp_min_(psf,0)\n",
    "            psf = psf/self.get_psf_norm(c_inds, z_inds)\n",
    "            \n",
    "            if self.psf_noise and add_noise: \n",
    "                psf = self.add_psf_noise(psf)\n",
    "                \n",
    "            # applying intenseties\n",
    "#             tot_intensity = torch.clamp_min(i_val, 0)  * self.channel_facs[locations[1]]\n",
    "            tot_intensity = torch.clamp_min(i_val, 0)  * (self.ch_scale * self.channel_facs)[locations[1]] * (self.ch_norm/self.channel_facs.sum())\n",
    "    \n",
    "            psf = psf * tot_intensity[:,None,None,None,None]\n",
    "            \n",
    "            if ret_psfs:\n",
    "                return self.scale * psf\n",
    "            \n",
    "            # place psf according to locations\n",
    "            xsim = place_psf(locations, psf, output_shape)\n",
    "            \n",
    "            # scale (not learnable)\n",
    "            xsim = self.scale * xsim\n",
    "            \n",
    "            return xsim\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return torch.zeros(output_shape).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def place_psf(locations, psf_volume, output_shape):\n",
    "    \"\"\"\n",
    "    Places point spread functions (psf_volume) in to corresponding locations.\n",
    "\n",
    "    Args:\n",
    "        locations: tuple with the 5D voxel coordinates\n",
    "        psf_volume: torch.Tensor\n",
    "        output_shape: Shape Tuple(BS, C, H, W, D) \n",
    "\n",
    "    Returns:\n",
    "        placed_psf: torch.Tensor with shape (BS, C, H, W, D)\n",
    "    \"\"\"\n",
    "\n",
    "    b, c, z, y, x = locations\n",
    "    # Deprecated python loop\n",
    "#     placed_psf = _place_psf(psf_volume, b, c, z, y, x, torch.tensor(output_shape))\n",
    "    \n",
    "    # New fancy cuda loop\n",
    "    N_psfs, _, psf_s_z, psf_s_y, psf_s_x = psf_volume.shape   \n",
    "    placed_psf = CudaPlaceROI.apply(psf_volume[:,0], output_shape[0], output_shape[1], output_shape[2], output_shape[3], output_shape[4], N_psfs, psf_s_z, psf_s_y, psf_s_x, b, c, z-psf_s_z//2, y-psf_s_y//2, x-psf_s_x//2)\n",
    "    \n",
    "    assert placed_psf.shape == output_shape\n",
    "    return placed_psf\n",
    "\n",
    "def extract_psf_roi(locations, x_vol, roi_shape):\n",
    "    \"\"\"\n",
    "    Extract ROIs from a given volume\n",
    "    \"\"\"\n",
    "    \n",
    "    batch, ch, z, y, x = locations \n",
    "    rois = _extract_psf_roi(x_vol, batch, ch, z, y, x, roi_shape)\n",
    "    \n",
    "    return rois\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "def get_roi_filt_inds(batch, ch, z, y, x, psf_shape, vol_shape, min_dist=None, slice_rec=False):\n",
    "    \"\"\"\n",
    "    Filter locations that are used for gen. model training.\n",
    "    Returns remaining indices.\n",
    "    \"\"\"\n",
    "    \n",
    "    inds = torch.arange(len(x))\n",
    "    \n",
    "    if min_dist:\n",
    "        # scale z if slice_rec ?? \n",
    "        bczyx = np.stack([cpu(batch)*1000,cpu(ch)*1000,cpu(z),cpu(y),cpu(x)]).T\n",
    "        tree = KDTree(bczyx)\n",
    "        pairs = tree.query_pairs(r=min_dist, output_type='ndarray')\n",
    "        pair_inds = np.unique(pairs.reshape(-1))\n",
    "        \n",
    "    psf_d, psf_h, psf_w = psf_shape[-3:]\n",
    "    vol_d, vol_h, vol_w = vol_shape[-3:]\n",
    "    # Filter locs at the edges\n",
    "    cond = (x > psf_w//2) & (x < vol_w - psf_w//2)\n",
    "    cond*= (y > psf_h//2) & (y < vol_h - psf_h//2)\n",
    "    if not slice_rec:\n",
    "        cond*= (z > psf_d//2) & (z < vol_d - psf_d)   \n",
    "        \n",
    "    if min_dist:\n",
    "        return np.setdiff1d(inds[cond], pair_inds, assume_unique=True)\n",
    "    else:\n",
    "        return inds[cond]\n",
    "    \n",
    "def mic_inp_apply_inds(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, inds):\n",
    "    \n",
    "    locations = [l[inds] for l in locations]\n",
    "    return locations, x_os_ch[inds], y_os_ch[inds], z_os_ch[inds], i_val[inds], output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@script\n",
    "def _extract_psf_roi(x_vol, batch, ch, z, y, x, roi_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract rois. We assume that border conditions are dealt with already. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    psf_b, psf_ch, psf_d, psf_h, psf_w = roi_shape[0], roi_shape[1], roi_shape[2], roi_shape[3], roi_shape[4]\n",
    "    roi_vol = torch.empty(psf_b, psf_ch, psf_d, psf_h, psf_w).to(x_vol.device)    \n",
    "    pad_zyx = [psf_d//2, psf_h//2, psf_w//2]\n",
    "    \n",
    "    z_l = z - pad_zyx[0]\n",
    "    y_l = y - pad_zyx[1]\n",
    "    x_l = x - pad_zyx[2]\n",
    "    \n",
    "    z_h = z + pad_zyx[0] + 1\n",
    "    y_h = y + pad_zyx[1] + 1\n",
    "    x_h = x + pad_zyx[2] + 1\n",
    "    \n",
    "    for idx in range(x.shape[0]):\n",
    "\n",
    "        roi_vol[idx] = x_vol[batch[idx], ch[idx],\n",
    "                         z_l[idx] : z_h[idx],\n",
    "                         y_l[idx] : y_h[idx],\n",
    "                         x_l[idx] : x_h[idx]]\n",
    "        \n",
    "    return roi_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/torch/cuda/__init__.py:120: UserWarning: \n",
      "    Found GPU%d %s which is of cuda capability %d.%d.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is %d.%d.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn.format(d, name, major, minor, min_arch // 10, min_arch % 10))\n"
     ]
    }
   ],
   "source": [
    "from decode_fish.engine.psf import LinearInterpolatedPSF\n",
    "from decode_fish.engine.noise import sCMOS\n",
    "from decode_fish.engine.point_process import PointProcessUniform\n",
    "from decode_fish.funcs.file_io import get_gaussian_psf\n",
    "from decode_fish.funcs.file_io import get_vol_psf\n",
    "from decode_fish.funcs.output_trafo import sample_to_df\n",
    "\n",
    "# psf = get_gaussian_psf([3,13,13],[.1,1.7,1.7], pred_z=True, n_cols=2).cuda()\n",
    "psf = get_vol_psf('../figures/MF_psf2.tif', n_cols=2)\n",
    "\n",
    "noise = sCMOS(channels=22)\n",
    "\n",
    "# micro = Microscope(psf=psf, noise=noise, scale=100, norm='sum', sum_fac=psf.psf_volume.sum().item()).cuda()\n",
    "micro = Microscope(psf=psf, noise=noise, scale=100, norm='sum',  psf_noise=0.0, pos_noise_xy=0.7, pos_noise_z=0.3, slice_rec=True).cuda()\n",
    "micro.ch_cols = [0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = OmegaConf.load('../config/experiment/MERFISH_mop_4a.yaml')\n",
    "# from decode_fish.funcs.file_io import load_psf_noise_micro\n",
    "# psf, noise, micro = load_psf_noise_micro(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_shifts True\n",
      "color_shifts True\n",
      "channel_facs True\n",
      "theta_par True\n",
      "psf_vol True\n"
     ]
    }
   ],
   "source": [
    "for name, p in micro.named_parameters():\n",
    "    print(name, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.funcs.exp_specific import *\n",
    "bench_df, code_ref, targets = get_merfish_mop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/ipykernel_launcher.py:117: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
     ]
    }
   ],
   "source": [
    "point_process = PointProcessUniform(local_rate = torch.ones([3,7,48,48]).cuda()*.01, int_conc=3, int_rate=1, int_loc=1, sim_iters=5, channels=22, n_bits=4, sim_z=True, codebook=torch.tensor(code_ref, dtype=torch.bool), int_option=2)\n",
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, codes = point_process.sample(from_code_book=True)\n",
    "locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape = micro.get_single_ch_inputs(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, torch.tensor([50,200,1500]),torch.tensor([50,200,1500]))\n",
    "# df = sample_to_df(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, codes, px_size_zyx=[1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro.color_shifts[c_inds].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psfs = micro(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, add_noise=False, ret_psfs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/ipykernel_launcher.py:160: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "xsim = micro(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, add_noise=True, add_pos_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([1.0440,  0.7444, -1.0476,  0.2227])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsim2 = micro(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, add_noise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_inds = get_roi_filt_inds(*locations, micro.psf.psf_volume.shape, xsim.shape, slice_rec=True, min_dist=10)\n",
    "ch_out_inp = mic_inp_apply_inds(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, filt_inds)\n",
    "rois = extract_psf_roi(ch_out_inp[0], xsim, torch.tensor(psfs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# rois = extract_psf_roi(ch_out_inp[0], xsim, torch.tensor(psfs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_channels(xsim[0]-xsim2[0],2, proj_func=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cpu(torch.sqrt(torch.distributions.Normal(loc=0, scale=0.3).sample([1000])**2 +\n",
    "torch.distributions.Normal(loc=0, scale=0.3).sample([1000])**2 +\n",
    "torch.distributions.Normal(loc=0, scale=0.3).sample([1000])**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check that 2D Z reconstruction is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_rate = torch.zeros([100,7,11,11]).cuda()\n",
    "local_rate[:,0,5,5] = 1.\n",
    "\n",
    "point_process = PointProcessUniform(local_rate =local_rate, int_conc=3, int_rate=1, sim_iters=1, int_loc=1, channels=22, n_bits=4, codebook=torch.tensor(code_ref)[:1], sim_z=True)\n",
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, codes = point_process.sample(from_code_book=True)\n",
    "df = sample_to_df(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, codes, px_size_zyx=[1,1,1])\n",
    "\n",
    "x_os_3d *= 0 \n",
    "y_os_3d *= 0 \n",
    "ints_3d *= 0 \n",
    "ints_3d += 1\n",
    "z_os_3d = torch.linspace(-0.7,0.7,100).cuda()\n",
    "\n",
    "ch_inp = micro.get_single_ch_inputs(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape)\n",
    "\n",
    "psf_s = micro(*ch_inp, add_noise=False, ret_psfs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cpu(psf_s)[::22,0,0,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_micro_inp(res_dict, code_ref, p_si=None, n_bits=4, channels=16):\n",
    "\n",
    "    res_dict['Samples_si'] = torch.where(torch.sigmoid(res_dict['logits']) > 0.0091, 1, 0)\n",
    "    # remove dump inds. Wont get reconstructed. \n",
    "    locations = res_dict['Samples_si'][:,:-1].nonzero(as_tuple=True)\n",
    "\n",
    "    xyzi_ix = [locations[0],locations[2],locations[3], locations[4]]\n",
    "    x_os_3d = res_dict['xyzi_mu'][:,0][xyzi_ix]\n",
    "    y_os_3d = res_dict['xyzi_mu'][:,1][xyzi_ix]\n",
    "    z_os_3d = res_dict['xyzi_mu'][:,2][xyzi_ix]\n",
    "    ints_3d = res_dict['xyzi_mu'][:,3][xyzi_ix]\n",
    "    # output_shape  = res_dict['Samples_si'].shape\n",
    "    ints_3d = ints_3d/n_bits+1\n",
    "\n",
    "    ints_ret = ints_3d[:,None].repeat_interleave(channels, 1)\n",
    "#     ch_bin = torch.zeros(ints_ret.shape).to(ints_ret.device)\n",
    "#     ch_bin.scatter_(index=torch.tensor(code_inds).to(ints_ret.device)[locations[1]], dim=1, value=1)\n",
    "    ch_bin = torch.tensor(code_ref)[locations[1]]\n",
    "    ints_ret = ints_ret*ch_bin.to(ints_ret.device)\n",
    "\n",
    "    output_shape  = res_dict['Samples_si'].shape\n",
    "    output_shape  = torch.Size([output_shape[0],channels,output_shape[2],output_shape[3],output_shape[4]])\n",
    "\n",
    "    return xyzi_ix, x_os_3d, y_os_3d, z_os_3d, ints_ret, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape = get_micro_inp(res_dict, torch.tensor(code_ref), p_si=None, n_bits = 4, channels=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 20_MERFISH_visualization.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode_fish_dev2]",
   "language": "python",
   "name": "conda-env-decode_fish_dev2-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
