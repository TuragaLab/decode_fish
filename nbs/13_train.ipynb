{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.train_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop simulator learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from decode_fish.funcs.evaluation import *\n",
    "from decode_fish.funcs.file_io import *\n",
    "from decode_fish.funcs.emitter_io import *\n",
    "from decode_fish.funcs.utils import *\n",
    "from decode_fish.funcs.dataset import *\n",
    "from decode_fish.funcs.output_trafo import *\n",
    "from decode_fish.funcs.plotting import *\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as D\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from decode_fish.engine.microscope import Microscope\n",
    "from decode_fish.engine.model import UnetDecodeNoBn\n",
    "import shutil\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from decode_fish.engine.point_process import PointProcessUniform\n",
    "from decode_fish.engine.gmm_loss import PointProcessGaussian\n",
    "import wandb\n",
    "from madgrad import MADGRAD\n",
    "# from decode_fish.funcs.visualization vimport get_simulation_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_logger(pred_df, target_df, iteration, data_str='Sim. '):\n",
    "    \n",
    "    perf_dict,_,shift = matching(target_df, pred_df, print_res=False)\n",
    "    if 'Inp' in data_str:\n",
    "        pred_corr = shift_df(pred_df, shift)\n",
    "        perf_dict, _, _ = matching(target_df, pred_corr, print_res=False)\n",
    "\n",
    "    wandb.log({data_str +'Metrics/eff_3d': perf_dict['eff_3d']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/jaccard': perf_dict['jaccard']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/rmse_vol': perf_dict['rmse_vol']}, step=iteration)\n",
    "\n",
    "    wandb.log({data_str +'Metrics/precision': perf_dict['precision']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/recall': perf_dict['recall']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/rmse_x': perf_dict['rmse_x']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/rmse_y': perf_dict['rmse_y']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/rmse_z': perf_dict['rmse_z']}, step=iteration)   \n",
    "    \n",
    "def load_from_eval_dict(eval_dict):\n",
    "    \n",
    "    eval_img = load_tiff_image(sorted(glob.glob(eval_dict['image_path']))[eval_dict['img_ind']])\n",
    "    eval_img = eval_img[eval_dict['crop_sl']]\n",
    "    eval_df = None\n",
    "    eval_psf = None\n",
    "    if eval_dict['txt_path'] is not None:\n",
    "        txt_path = sorted(glob.glob(eval_dict['txt_path']))[eval_dict['img_ind']]\n",
    "        eval_df = simfish_to_df(txt_path)\n",
    "        eval_df = crop_df(eval_df, eval_dict['crop_sl'], px_size_zyx=eval_dict['px_size_zyx'])\n",
    "\n",
    "    if eval_dict['psf_path'] is not None:\n",
    "        eval_psf = load_tiff_image(eval_dict['psf_path'])\n",
    "        \n",
    "    return eval_img, eval_df, eval_psf\n",
    "\n",
    "def save_train_state(save_dir, model, microscope, optim_net, psf, optim_psf):\n",
    "    \n",
    "        torch.save({'state_dict':model.state_dict(), 'scaling':[model.unet.inp_scale, model.unet.inp_offset]}, save_dir/'model.pkl')\n",
    "        torch.save(microscope.state_dict(), save_dir/'microscope.pkl')\n",
    "        torch.save(optim_net.state_dict(), save_dir/'opt_net.pkl')\n",
    "        torch.save(psf.state_dict(), save_dir/'psf.pkl' )\n",
    "        torch.save(optim_psf.state_dict(), save_dir/'opt_psf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train(cfg,\n",
    "          model, \n",
    "          dl, \n",
    "          optim_net, \n",
    "          optim_psf, \n",
    "          optim_mic,\n",
    "          sched_net, \n",
    "          sched_psf, \n",
    "          sched_mic,\n",
    "          microscope,\n",
    "          psf,\n",
    "          post_proc,\n",
    "          eval_dict=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Training loop for autoencoder learning. Alternates between a simulator training step to train the inference network\n",
    "    and an autoencoder step to train the PSF (and microscope) parameters.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): DECODE 3D UNet.\n",
    "        num_iter (int): Number of training iterations for pure sl learning(batches).\n",
    "        num_iter (int): Total number of training iterations (batches).\n",
    "        dl  (torch.utils.data.dataloader.DataLoader): Dataloader that returns a random sub volume from the real volume, an estiamted emitter density and background.\n",
    "        optim_net  (torch.optim.Optimizer): Optimizer for the network parameters.\n",
    "        optim_psf  (torch.optim.Optimizer): Optimizer for the PSF parameters.\n",
    "        sched_net  (torch.optim.lr_scheduler): LR scheduler for the network parameters.\n",
    "        sched_psf  (torch.optim.lr_scheduler): LR scheduler for the PSF parameters.\n",
    "        min_int  (float): Minimal fraction of the max intensity used when sampling emitters. \n",
    "        microscope (torch.nn.Module): Microscope class that transforms emitter locations into simulated images.\n",
    "        log_interval  (int): Number of iterations between performance evaluations.\n",
    "        save_dir  (str, PosixPath): Output path where the trained model is stored.\n",
    "        log_dir  (str, PosixPath, optional): Output path where log files for Tensorboard are stored.\n",
    "        psf (torch.nn.Module): Parametric PSF.\n",
    "        bl_loss_scale  (float): The background loss gets scaled by this factor when added to the GMM loss.\n",
    "        grad_clip  (float): Gradient clipping threshold. \n",
    "        eval_dict  (dict, optional): Dictionary with evaluation parameters\n",
    "        \n",
    "    \"\"\" \n",
    "    \n",
    "    save_dir = Path(cfg.output.save_dir)\n",
    "    \n",
    "    if eval_dict is not None:\n",
    "        eval_img, eval_df, eval_psf = load_from_eval_dict(eval_dict)\n",
    "\n",
    "    model.cuda().train()\n",
    "    torch.save(psf.state_dict(), str(save_dir) + '/psf_init.pkl' )\n",
    "\n",
    "    for batch_idx in range(cfg.training.num_iters):\n",
    "\n",
    "        x, local_rate, background = next(iter(dl))\n",
    "        \n",
    "        optim_net.zero_grad()\n",
    "        \n",
    "        sim_vars = PointProcessUniform(local_rate, int_conc=model.int_dist.int_conc.detach(), int_rate=model.int_dist.int_rate.detach(), int_loc=model.int_dist.int_loc.detach(), sim_iters=5).sample()  \n",
    "        # sim_vars = locs_sl, x_os_sl, y_os_sl, z_os_sl, ints_sl, output_shape\n",
    "        xsim = microscope(*sim_vars)\n",
    "        xsim_noise = microscope.noise(xsim, background).sample()\n",
    "\n",
    "        out_sim = model(xsim_noise)\n",
    "\n",
    "        count_prob, spatial_prob = PointProcessGaussian(**out_sim).log_prob(*sim_vars[:5])\n",
    "        gmm_loss = -(spatial_prob + cfg.training.net.cnt_loss_scale*count_prob).mean()\n",
    "        \n",
    "        background_loss = F.mse_loss(out_sim['background'], background) * cfg.training.net.bl_loss_scale\n",
    "\n",
    "        loss = gmm_loss + background_loss\n",
    "        \n",
    "        # Update network parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        if cfg.training.net.grad_clip: torch.nn.utils.clip_grad_norm_(model.unet.parameters(), max_norm=cfg.training.net.grad_clip, norm_type=2)\n",
    "\n",
    "        optim_net.step()\n",
    "        if sched_net:\n",
    "            sched_net.step()\n",
    "            \n",
    "        if batch_idx > cfg.training.start_micro:\n",
    "            \n",
    "            out_inp = model(x)\n",
    "            proc_out_inp = post_proc(out_inp, ret='micro') # locations, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, comb_sig\n",
    "            \n",
    "            if batch_idx > cfg.training.start_psf:\n",
    "                \n",
    "                optim_psf.zero_grad()\n",
    "\n",
    "                # Get autoencoder loss\n",
    "                ae_img = microscope(*proc_out_inp[:6])\n",
    "                log_p_x_given_z = -microscope.noise(ae_img,out_inp['background']).log_prob(x).mean()\n",
    "                if cfg.training.psf.norm_reg:\n",
    "#                     log_p_x_given_z += cfg.training.psf.norm_reg * (psf.sum_loss() + psf.com_loss() + psf.clip_loss())\n",
    "                    log_p_x_given_z += cfg.training.psf.norm_reg * (psf.com_loss())\n",
    "\n",
    "                log_p_x_given_z.backward()\n",
    "                if cfg.training.psf.grad_clip:\n",
    "                    torch.nn.utils.clip_grad_norm_(optim_psf.param_groups[0]['params'], max_norm=cfg.training.psf.grad_clip, norm_type=2)\n",
    "                \n",
    "                optim_psf.step()\n",
    "                if sched_psf:\n",
    "                    sched_psf.step()\n",
    "            \n",
    "            if len(proc_out_inp[4]):\n",
    "                \n",
    "                optim_mic.zero_grad()\n",
    "                if cfg.training.isi_filt == True:\n",
    "                    good_ints = proc_out_inp[4][proc_out_inp[7] == 1.]\n",
    "                else:\n",
    "                    good_ints = proc_out_inp[4]\n",
    "                #   good_ints = proc_out_inp[4][proc_out_inp[6] < torch.quantile(proc_out_inp[6], cfg.training.micro.int_quantile)]\n",
    "\n",
    "                gamma_int = D.Gamma(model.int_dist.int_conc, model.int_dist.int_rate)\n",
    "                loc_trafo = [D.AffineTransform(loc=model.int_dist.int_loc, scale=1, event_dim=1)]\n",
    "                int_loss = -D.TransformedDistribution(gamma_int, loc_trafo).log_prob(good_ints.detach()).mean()\n",
    "                \n",
    "#                 print('Pars:', model.int_dist.int_conc.detach(), model.int_dist.int_rate.detach(),model.int_dist.int_loc.detach())\n",
    "#                 print('Ints:', good_ints.detach())\n",
    "#                 print('Loss:', int_loss)\n",
    "                \n",
    "                int_loss.backward()\n",
    "                optim_mic.step()\n",
    "                if sched_mic:\n",
    "                    sched_mic.step()\n",
    "\n",
    "        # Logging\n",
    "        if batch_idx % 10 == 0:\n",
    "            wandb.log({'SL Losses/gmm_loss': gmm_loss.detach().cpu()}, step=batch_idx)\n",
    "            wandb.log({'SL Losses/count_loss': (-count_prob.mean()).detach().cpu()}, step=batch_idx)\n",
    "            wandb.log({'SL Losses/bg_loss': background_loss.detach().cpu()}, step=batch_idx)\n",
    "            wandb.log({'AE Losses/int_mu': model.int_dist.int_conc.item()/model.int_dist.int_rate.item() + model.int_dist.int_loc.item()}, step=batch_idx)\n",
    "            wandb.log({'AE Losses/int_rate': model.int_dist.int_rate.item()}, step=batch_idx)\n",
    "            wandb.log({'AE Losses/int_loc': model.int_dist.int_loc.item()}, step=batch_idx)\n",
    "            wandb.log({'AE Losses/theta': microscope.noise.theta.item()}, step=batch_idx)\n",
    "\n",
    "            if batch_idx > cfg.training.start_psf: \n",
    "                wandb.log({'AE Losses/p_x_given_z': log_p_x_given_z.detach().cpu()}, step=batch_idx)\n",
    "                wandb.log({'AE Losses/RMSE(rec)': torch.sqrt(((x-(ae_img+out_inp['background']))**2).mean()).detach().cpu()}, step=batch_idx)\n",
    "                wandb.log({'AE Losses/sum(psf)': F.relu(psf.psf_volume/psf.psf_volume.max())[0].sum().detach().cpu()}, step=batch_idx)\n",
    "#                     wandb.log({'AE Losses/theta': microscope.theta.item()}, step=batch_idx)\n",
    "        \n",
    "        if batch_idx % cfg.output.log_interval == 0:\n",
    "            print(batch_idx)\n",
    "            with torch.no_grad():\n",
    "                pred_df = post_proc(out_sim, ret='df')\n",
    "                px_size = cfg.evaluation.px_size_zyx\n",
    "                target_df = sample_to_df(*sim_vars[:5], px_size_zyx=px_size)\n",
    "                eval_logger(pred_df, target_df, batch_idx, data_str='Sim. ')\n",
    "                wandb.log({'Sim. Metrics/prob_fac': torch.sigmoid(out_sim['logits']).sum().item()/len(target_df)}, step=batch_idx)\n",
    "                wandb.log({'Sim. Metrics/n_em_fac': len(pred_df)/len(target_df)}, step=batch_idx)\n",
    "#                 wandb.log({'Prob hist': wandb.Image(plot_prob_hist(out_sim))}, step=batch_idx)\n",
    "\n",
    "                if cfg.output.log_figs:\n",
    "                    sl_fig = sl_plot(x, xsim_noise, nm_to_px(pred_df, px_size), nm_to_px(target_df, px_size), background, out_sim)\n",
    "                    plt.show()\n",
    "                    wandb.log({'SL summary': sl_fig}, step=batch_idx)\n",
    "\n",
    "                if eval_dict is not None:\n",
    "                    res_eval = model(eval_img[None].cuda())\n",
    "                    ae_img = microscope(*post_proc(res_eval, ret='micro')[:6])\n",
    "                    pred_eval_df = post_proc(res_eval, ret='df')\n",
    "                    wandb.log({'AE Losses/N preds(eval)': len(pred_eval_df)}, step=batch_idx)\n",
    "                    \n",
    "                    if eval_df is not None:\n",
    "                        eval_logger(pred_eval_df, eval_df, batch_idx, data_str='Inp. ')\n",
    "                        \n",
    "                    if eval_psf is not None:\n",
    "#                         wandb.log({'AE Losses/Corr(psf)': cpu(torch.sqrt(torch.mean(((eval_psf-psf.psf_volume.detach().cpu()))**2)))}, step=batch_idx)\n",
    "                        wandb.log({'AE Losses/Corr(psf)': np.corrcoef(cpu(eval_psf).reshape(-1), cpu(psf.psf_volume).reshape(-1))[0,1]}, step=batch_idx)\n",
    "                        wandb.log({'AE Losses/RMSE(psf)': np.sqrt(np.mean((cpu(eval_psf/eval_psf.max())-cpu(psf.psf_volume/psf.psf_volume.max()))**2))}, step=batch_idx)\n",
    "        \n",
    "                    if cfg.output.log_figs:\n",
    "                        eval_fig = gt_plot(eval_img, nm_to_px(pred_eval_df, px_size), nm_to_px(eval_df, px_size), px_size,ae_img[0]+res_eval['background'][0], psf)\n",
    "                        plt.show()\n",
    "                        wandb.log({'GT': eval_fig}, step=batch_idx)\n",
    "\n",
    "            # storing\n",
    "            if batch_idx > 0 and abs(cfg.training.start_psf - batch_idx)<cfg.output.log_interval:\n",
    "                Path.mkdir(save_dir/'sl_save', exist_ok=True)\n",
    "                save_train_state(save_dir/'sl_save', model, microscope, optim_net, psf, optim_psf)     \n",
    "            \n",
    "            save_train_state(save_dir, model, microscope, optim_net, psf, optim_psf) \n",
    "            \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('../config/experiment/covid_early_smFISH_4.yaml')\n",
    "# cfg.run_name = 'rab11_nb'\n",
    "# cfg.training.start_micro = 1000\n",
    "# cfg.training.start_psf = 1000\n",
    "# cfg.microscope.int_conc = 2.\n",
    "\n",
    "psf, noise, micro = load_psf_noise_micro(cfg)\n",
    "post_proc = hydra.utils.instantiate(cfg.post_proc_isi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/models/fishcod/covid_early/nb_run/covid_early_smFISH_4'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.output.save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.training.start_micro = 0\n",
    "cfg.training.start_psf = 0\n",
    "\n",
    "# cfg.data_path.model_init = '/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/models/fishcod/Fig_sim_density/sweep_ff21/int_conc:2.0/sl_save'\n",
    "cfg.data_path.model_init = cfg.output.save_dir + '/sl_save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop size larger than volume in at least one dimension. Crop size changed to (25, 48, 48)\n",
      "1 volumes\n"
     ]
    }
   ],
   "source": [
    "img_3d, decode_dl = get_dataloader(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_3d_projections(torch.exp(psf.psf_volume[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from decode_fish.funcs.visualization import get_simulation_statistics\n",
    "# get_simulation_statistics(decode_dl, micro, int_threshold=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Microscope(\n",
       "  (noise): sCMOS()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_offset, inp_scale = get_forward_scaling(img_3d[0])\n",
    "model = hydra.utils.instantiate(cfg.model, inp_scale=float(inp_scale), inp_offset=float(inp_offset))\n",
    "\n",
    "psf  .to('cuda')\n",
    "model.to('cuda')\n",
    "micro.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_net = hydra.utils.instantiate(cfg.training.net.opt, params=model.unet.parameters())\n",
    "opt_psf = hydra.utils.instantiate(cfg.training.psf.opt, params=list(psf.parameters()))\n",
    "opt_mic = hydra.utils.instantiate(cfg.training.micro.opt, params=list(model.int_dist.parameters())[:3])\n",
    "\n",
    "scheduler_net = hydra.utils.instantiate(cfg.training.net.sched, optimizer=opt_net)\n",
    "scheduler_psf = hydra.utils.instantiate(cfg.training.psf.sched, optimizer=opt_psf)\n",
    "scheduler_mic = hydra.utils.instantiate(cfg.training.psf.sched, optimizer=opt_mic)\n",
    "\n",
    "if cfg.evaluation is not None:\n",
    "    eval_dict = dict(cfg.evaluation)\n",
    "    eval_dict['crop_sl'] = eval(eval_dict['crop_sl'],{'__builtins__': None},{'s_': np.s_})\n",
    "    eval_dict['px_size_zyx'] = list(eval_dict['px_size_zyx'])\n",
    "else:\n",
    "    eval_dict = None\n",
    "    \n",
    "save_dir = Path(cfg.output.save_dir)\n",
    "save_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading\n"
     ]
    }
   ],
   "source": [
    "if cfg.data_path.model_init is not None:\n",
    "    print('loading')\n",
    "    model = load_model_state(model, cfg.data_path.model_init).cuda()\n",
    "    micro.load_state_dict(torch.load(Path(cfg.data_path.model_init)/'microscope.pkl'))\n",
    "    opt_net.load_state_dict(torch.load(Path(cfg.data_path.model_init)/'opt_net.pkl'))\n",
    "#     opt_psf.load_state_dict(torch.load(Path(cfg.data_path.model_init)/'opt_psf.pkl'))\n",
    "#     psf.load_state_dict(torch.load(Path(cfg.data_path.model_init)/'psf.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point_process = PointProcessUniform(local_rate = torch.ones([2,1,48,48,48]).cuda()*.0001, min_int = 0.5, sim_iters=5)\n",
    "# locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape = point_process.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xsim = micro(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape)\n",
    "# plot_3d_projections(xsim[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maspeiser\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">covid_early_smFISH_4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/aspeiser/covid_early\" target=\"_blank\">https://wandb.ai/aspeiser/covid_early</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/aspeiser/covid_early/runs/1q48tq6r\" target=\"_blank\">https://wandb.ai/aspeiser/covid_early/runs/1q48tq6r</a><br/>\n",
       "                Run data is saved locally in <code>/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/decode_fish/runs/wandb/run-20210512_030818-1q48tq6r</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = wandb.init(project=cfg.output.project, \n",
    "               config=OmegaConf.to_container(cfg, resolve=True),\n",
    "               dir=cfg.output.log_dir,\n",
    "               group=cfg.output.group,\n",
    "               name=cfg.run_name\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(cfg=cfg,\n",
    "#      model=model, \n",
    "#      dl=decode_dl, \n",
    "#      optim_net=opt_net, \n",
    "#      optim_psf=opt_psf, \n",
    "#      optim_mic=opt_mic, \n",
    "#      sched_net=scheduler_net, \n",
    "#      sched_psf=scheduler_psf, \n",
    "#      sched_mic=scheduler_mic, \n",
    "#      psf=psf,\n",
    "#      post_proc=post_proc,\n",
    "#      microscope=micro, \n",
    "#      eval_dict=eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode2_dev]",
   "language": "python",
   "name": "conda-env-decode2_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
