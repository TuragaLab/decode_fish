{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp engine.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECODE Network\n",
    "\n",
    "> Definition of the classes and modules we use to build our DECODE network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "import torch.nn as nn\n",
    "import types\n",
    "from functools import partial\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def number_of_features_per_level(init_channel_number, num_levels):\n",
    "    return [init_channel_number * 2 ** k for k in range(num_levels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding):\n",
    "    \"\"\"\n",
    "    Create a list of modules with together constitute a single conv layer with non-linearity\n",
    "    and optional batchnorm/groupnorm.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size(int or tuple): size of the convolving kernel\n",
    "        order (string): order of things, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'gcr' -> groupnorm + conv + ReLU\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "            'bcr' -> batchnorm + conv + ReLU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    Return:\n",
    "        list of tuple (name, module)\n",
    "    \"\"\"\n",
    "    assert 'c' in order, \"Conv layer MUST be present\"\n",
    "    assert order[0] not in 'rle', 'Non-linearity cannot be the first operation in the layer'\n",
    "\n",
    "    modules = []\n",
    "    for i, char in enumerate(order):\n",
    "        if char == 'r':\n",
    "            modules.append(('ReLU', nn.ReLU(inplace=True)))\n",
    "        elif char == 'l':\n",
    "            modules.append(('LeakyReLU', nn.LeakyReLU(negative_slope=0.1, inplace=True)))\n",
    "        elif char == 'e':\n",
    "            modules.append(('ELU', nn.ELU(inplace=True)))\n",
    "        elif char == 'c':\n",
    "            # add learnable bias only in the absence of batchnorm/groupnorm\n",
    "            bias = not ('g' in order or 'b' in order)\n",
    "            modules.append(('conv', nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding, bias=bias, padding_mode='replicate')))\n",
    "        elif char == 'g':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                num_channels = in_channels\n",
    "            else:\n",
    "                num_channels = out_channels\n",
    "\n",
    "            # use only one group if the given number of groups is greater than the number of channels\n",
    "            if num_channels < num_groups:\n",
    "                num_groups = 1\n",
    "\n",
    "            assert num_channels % num_groups == 0, f'Expected number of channels in input to be divisible by num_groups. num_channels={num_channels}, num_groups={num_groups}'\n",
    "            modules.append(('groupnorm', nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)))\n",
    "        elif char == 'b':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(in_channels)))\n",
    "            else:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(out_channels)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported layer type '{char}'. MUST be one of ['b', 'g', 'r', 'l', 'e', 'c']\")\n",
    "\n",
    "    return modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SingleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Basic convolutional module consisting of a Conv3d, non-linearity and optional batchnorm/groupnorm. The order\n",
    "    of operations can be specified via the `order` parameter\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple):\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
    "        super(SingleConv, self).__init__()\n",
    "\n",
    "        for name, module in create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding=padding):\n",
    "            self.add_module(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DoubleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A module consisting of two consecutive convolution layers (e.g. BatchNorm3d+ReLU+Conv3d).\n",
    "    We use (Conv3d+ReLU+GroupNorm3d) by default.\n",
    "    This can be changed however by providing the 'order' argument, e.g. in order\n",
    "    to change to Conv3d+BatchNorm3d+ELU use order='cbe'.\n",
    "    Use padded convolutions to make sure that the output (H_out, W_out) is the same\n",
    "    as (H_in, W_in), so that you don't have to crop in the decoder path.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        encoder (bool): if True we're in the encoder path, otherwise we're in the decoder\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, encoder, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        if encoder:\n",
    "            # we're in the encoder path\n",
    "            conv1_in_channels = in_channels\n",
    "            conv1_out_channels = out_channels // 2\n",
    "            if conv1_out_channels < in_channels:\n",
    "                conv1_out_channels = in_channels\n",
    "            conv2_in_channels, conv2_out_channels = conv1_out_channels, out_channels\n",
    "        else:\n",
    "            # we're in the decoder path, decrease the number of channels in the 1st convolution\n",
    "            conv1_in_channels, conv1_out_channels = in_channels, out_channels\n",
    "            conv2_in_channels, conv2_out_channels = out_channels, out_channels\n",
    "\n",
    "        # conv1\n",
    "        self.add_module('SingleConv1',\n",
    "                        SingleConv(conv1_in_channels, conv1_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding))\n",
    "        # conv2\n",
    "        self.add_module('SingleConv2',\n",
    "                        SingleConv(conv2_in_channels, conv2_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Upsampling(nn.Module):\n",
    "    \"\"\"\n",
    "    Upsamples a given multi-channel 3D data using either interpolation or learned transposed convolution.\n",
    "    Args:\n",
    "        transposed_conv (bool): if True uses ConvTranspose3d for upsampling, otherwise uses interpolation\n",
    "        in_channels (int): number of input channels for transposed conv\n",
    "            used only if transposed_conv is True\n",
    "        out_channels (int): number of output channels for transpose conv\n",
    "            used only if transposed_conv is True\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "            used only if transposed_conv is True\n",
    "        scale_factor (int or tuple): stride of the convolution\n",
    "            used only if transposed_conv is True\n",
    "        mode (str): algorithm used for upsampling:\n",
    "            'nearest' | 'linear' | 'bilinear' | 'trilinear' | 'area'. Default: 'nearest'\n",
    "            used only if transposed_conv is False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transposed_conv, in_channels=None, out_channels=None, kernel_size=3,\n",
    "                 scale_factor=(2, 2, 2), mode='nearest'):\n",
    "        super(Upsampling, self).__init__()\n",
    "\n",
    "        if transposed_conv:\n",
    "            # make sure that the output size reverses the MaxPool3d from the corresponding encoder\n",
    "            # (D_out = (D_in − 1) ×  stride[0] − 2 ×  padding[0] +  kernel_size[0] +  output_padding[0])\n",
    "            self.upsample = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=kernel_size, stride=scale_factor,\n",
    "                                               padding=1)\n",
    "        else:\n",
    "            self.upsample = partial(self._interpolate, mode=mode)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        output_size = encoder_features.size()[2:]\n",
    "        return self.upsample(x, output_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def _interpolate(x, size, mode):\n",
    "        return F.interpolate(x, size=size, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module from the encoder path consisting of the optional max\n",
    "    pooling layer (one may specify the MaxPool kernel_size to be different\n",
    "    than the standard (2,2,2), e.g. if the volumetric data is anisotropic\n",
    "    (make sure to use complementary scale_factor in the decoder path) followed by\n",
    "    a DoubleConv module.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        apply_pooling (bool): if True use MaxPool3d before DoubleConv\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        pool_type (str): pooling layer: 'max' or 'avg'\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, apply_pooling=True,\n",
    "                 pool_kernel_size=2, pool_type='max', basic_module=DoubleConv, conv_layer_order='gcr',\n",
    "                 num_groups=8, padding=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        assert pool_type in ['max', 'avg']\n",
    "        if apply_pooling:\n",
    "            if pool_type == 'max':\n",
    "                self.pooling = nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
    "            else:\n",
    "                self.pooling = nn.AvgPool3d(kernel_size=pool_kernel_size)\n",
    "        else:\n",
    "            self.pooling = None\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=True,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.pooling is not None:\n",
    "            x = self.pooling(x)\n",
    "        x = self.basic_module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module for decoder path consisting of the upsampling layer\n",
    "    (either learned ConvTranspose3d or nearest neighbor interpolation) followed by a basic module (DoubleConv or ExtResNetBlock).\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        scale_factor (tuple): used as the multiplier for the image H/W/D in\n",
    "            case of nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation\n",
    "            from the corresponding encoder\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, scale_factor=(2, 2, 2), basic_module=DoubleConv,\n",
    "                 conv_layer_order='gcr', num_groups=8, mode='nearest', padding=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        if basic_module == DoubleConv:\n",
    "            # if DoubleConv is the basic_module use interpolation for upsampling and concatenation joining\n",
    "            self.upsampling = Upsampling(transposed_conv=False, in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=conv_kernel_size, scale_factor=scale_factor, mode=mode)\n",
    "            # concat joining\n",
    "            self.joining = partial(self._joining, concat=True)\n",
    "        else:\n",
    "            # if basic_module=ExtResNetBlock use transposed convolution upsampling and summation joining\n",
    "            self.upsampling = Upsampling(transposed_conv=True, in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=conv_kernel_size, scale_factor=scale_factor, mode=mode)\n",
    "            # sum joining\n",
    "            self.joining = partial(self._joining, concat=False)\n",
    "            # adapt the number of in_channels for the ExtResNetBlock\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=False,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        x = self.upsampling(encoder_features=encoder_features, x=x)\n",
    "        x = self.joining(encoder_features, x)\n",
    "        x = self.basic_module(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _joining(encoder_features, x, concat):\n",
    "        if concat:\n",
    "            return torch.cat((encoder_features, x), dim=1)\n",
    "        else:\n",
    "            return encoder_features + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Abstract3DUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for standard and residual UNet.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        final_sigmoid (bool): if True apply element-wise nn.Sigmoid after the\n",
    "            final 1x1 convolution, otherwise apply nn.Softmax. MUST be True if nn.BCELoss (two-class) is used\n",
    "            to train the model. MUST be False if nn.CrossEntropyLoss (multi-class) is used to train the model.\n",
    "        basic_module: basic model for the encoder/decoder (DoubleConv, ExtResNetBlock, ....)\n",
    "        layer_order (string): determines the order of layers\n",
    "            in `SingleConv` module. e.g. 'crg' stands for Conv3d+ReLU+GroupNorm3d.\n",
    "            See `SingleConv` for more info\n",
    "        f_maps (int, tuple): if int: number of feature maps in the first conv layer of the encoder (default: 64);\n",
    "            if tuple: number of feature maps at each level\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        num_levels (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
    "        is_segmentation (bool): if True (semantic segmentation problem) Sigmoid/Softmax normalization is applied\n",
    "            after the final convolution; if False (regression problem) the normalization layer is skipped at the end\n",
    "        testing (bool): if True (testing mode) the `final_activation` (if present, i.e. `is_segmentation=true`)\n",
    "            will be applied as the last operation during the forward pass; if False the model is in training mode\n",
    "            and the `final_activation` (even if present) won't be applied; default: False\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel in the basic_module\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        conv_padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, final_sigmoid, basic_module, f_maps=64, is_2D=False, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, testing=False,\n",
    "                 conv_kernel_size=3, pool_kernel_size=2, conv_padding=1, **kwargs):\n",
    "        super(Abstract3DUNet, self).__init__()\n",
    "\n",
    "        self.testing = testing\n",
    "        if is_2D:\n",
    "            conv_kernel_size = [1, conv_kernel_size, conv_kernel_size]\n",
    "            pool_kernel_size = [1, pool_kernel_size, pool_kernel_size]\n",
    "            conv_padding = [0, conv_padding, conv_padding]\n",
    "\n",
    "        if isinstance(f_maps, int):\n",
    "            f_maps = number_of_features_per_level(f_maps, num_levels=num_levels)\n",
    "\n",
    "        # create encoder path consisting of Encoder modules. Depth of the encoder is equal to `len(f_maps)`\n",
    "        encoders = []\n",
    "        for i, out_feature_num in enumerate(f_maps):\n",
    "            if i == 0:\n",
    "                encoder = Encoder(in_channels, out_feature_num,\n",
    "                                  apply_pooling=False,  # skip pooling in the firs encoder\n",
    "                                  basic_module=basic_module,\n",
    "                                  conv_layer_order=layer_order,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  num_groups=num_groups,\n",
    "                                  padding=conv_padding)\n",
    "            else:\n",
    "                # TODO: adapt for anisotropy in the data, i.e. use proper pooling kernel to make the data isotropic after 1-2 pooling operations\n",
    "                encoder = Encoder(f_maps[i - 1], out_feature_num,\n",
    "                                  basic_module=basic_module,\n",
    "                                  conv_layer_order=layer_order,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  num_groups=num_groups,\n",
    "                                  pool_kernel_size=pool_kernel_size,\n",
    "                                  padding=conv_padding)\n",
    "\n",
    "            encoders.append(encoder)\n",
    "\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "\n",
    "        # create decoder path consisting of the Decoder modules. The length of the decoder is equal to `len(f_maps) - 1`\n",
    "        decoders = []\n",
    "        reversed_f_maps = list(reversed(f_maps))\n",
    "        for i in range(len(reversed_f_maps) - 1):\n",
    "            if basic_module == DoubleConv:\n",
    "                in_feature_num = reversed_f_maps[i] + reversed_f_maps[i + 1]\n",
    "            else:\n",
    "                in_feature_num = reversed_f_maps[i]\n",
    "\n",
    "            out_feature_num = reversed_f_maps[i + 1]\n",
    "            # TODO: if non-standard pooling was used, make sure to use correct striding for transpose conv\n",
    "            # currently strides with a constant stride: (2, 2, 2)\n",
    "            decoder = Decoder(in_feature_num, out_feature_num,\n",
    "                              basic_module=basic_module,\n",
    "                              conv_layer_order=layer_order,\n",
    "                              conv_kernel_size=conv_kernel_size,\n",
    "                              num_groups=num_groups,\n",
    "                              padding=conv_padding)\n",
    "            decoders.append(decoder)\n",
    "\n",
    "        self.decoders = nn.ModuleList(decoders)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder part\n",
    "        encoders_features = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            # reverse the encoder outputs to be aligned with the decoder\n",
    "            encoders_features.insert(0, x)\n",
    "\n",
    "        # remove the last encoder's output from the list\n",
    "        # !!remember: it's the 1st in the list\n",
    "        encoders_features = encoders_features[1:]\n",
    "\n",
    "        # decoder part\n",
    "        for decoder, encoder_features in zip(self.decoders, encoders_features):\n",
    "            # pass the output from the corresponding encoder and the output\n",
    "            # of the previous decoder\n",
    "            x = decoder(encoder_features, x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UNet3D(Abstract3DUNet):\n",
    "    \"\"\"\n",
    "    3DUnet model from\n",
    "    `\"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation\"\n",
    "        <https://arxiv.org/pdf/1606.06650.pdf>`.\n",
    "    Uses `DoubleConv` as a basic_module and nearest neighbor upsampling in the decoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, final_sigmoid=True, f_maps=64, is_2D=False, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1,  **kwargs):\n",
    "        super(UNet3D, self).__init__(in_channels=in_channels, final_sigmoid=final_sigmoid,\n",
    "                                     basic_module=DoubleConv, f_maps=f_maps, is_2D=is_2D, layer_order=layer_order,\n",
    "                                     num_groups=num_groups, num_levels=num_levels, is_segmentation=is_segmentation,\n",
    "                                     conv_padding=conv_padding, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IntensityDist(nn.Module):\n",
    "    \"\"\"\n",
    "    Stores the three parameters that determine the distribution of intensities for simulator learning (and which are optimized during autoencoder learning)\n",
    "    Args:\n",
    "        int_conc, int_rate: parameters of the torch.distributions.gamma class.\n",
    "        int_loc: shift parameter. \n",
    "    \"\"\"\n",
    "    def __init__(self, int_conc, int_rate, int_loc):\n",
    "        super().__init__()\n",
    "        self.int_conc = torch.nn.Parameter(torch.tensor(float(int_conc)))\n",
    "        self.int_rate = torch.nn.Parameter(torch.tensor(float(int_rate)))\n",
    "        self.int_loc = torch.nn.Parameter(torch.tensor(float(int_loc)))  \n",
    "        \n",
    "class OutputNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes the output maps from the U-net and processes them seperately, using two conv3D layers for each group (xyzi_mean, xyzi_sigma, probability, background)\n",
    "    Args:\n",
    "        f_maps: number of channels of the U-net output\n",
    "        p_offset: probability channel bias \n",
    "    \"\"\"\n",
    "    def __init__(self, f_maps=64, p_offset=-5., is_2D=False, n_p_ch=1, n_bg_ch=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.is_2D = is_2D\n",
    "        self.n_p_ch = n_p_ch\n",
    "        self.n_bg_ch = n_bg_ch\n",
    "        \n",
    "        xyzi_dim = 4\n",
    "        \n",
    "        kernel_size = [1,3,3] if is_2D else [3,3,3]\n",
    "        padding = [0,1,1] if is_2D else [1,1,1]\n",
    "\n",
    "        self.p_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.p_out2 = nn.Conv3d(f_maps, n_p_ch, kernel_size=1, padding=0)\n",
    "        nn.init.constant_(self.p_out2.bias,p_offset)\n",
    "        \n",
    "        self.xyzi_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.xyzi_out2 = nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.xyzis_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.xyzis_out2 = nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.bg_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.bg_out2 = nn.Conv3d(f_maps, n_bg_ch, kernel_size=1, padding=0)\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.p_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.p_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.xyzi_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.xyzi_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.xyzis_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.xyzis_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.bg_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.bg_out2.weight, mode='fan_in', nonlinearity='linear')    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        logit    = F.elu(self.p_out1(x))\n",
    "        logit    = self.p_out2(logit)\n",
    "        logit    = torch.clamp(logit, -20., 20)\n",
    "        \n",
    "        xyzi = F.elu(self.xyzi_out1(x))\n",
    "        xyzi = self.xyzi_out2(xyzi)\n",
    "\n",
    "        xyz_mu   = torch.tanh(xyzi[:, :3])\n",
    "\n",
    "        i_mu     = F.softplus(xyzi[:, 3:])\n",
    "        xyzi_mu = torch.cat((xyz_mu, i_mu), dim=1)\n",
    "        \n",
    "        xyzis = F.elu(self.xyzis_out1(x))\n",
    "        xyzis = self.xyzis_out2(xyzis)\n",
    "        xyzi_sig = F.softplus(xyzis) + 0.01\n",
    "        \n",
    "        background = F.elu(self.bg_out1(x))\n",
    "        background = self.bg_out2(background)\n",
    "        background = F.softplus(background)\n",
    "        return torch.cat([logit,xyzi_mu,xyzi_sig,background],1)\n",
    "            \n",
    "\n",
    "class UnetDecodeNoBn(nn.Module):\n",
    "    \"\"\"\n",
    "    Our DECODE network consists of a 3D U-net, and an output net module.\n",
    "    The network parameters can accessed through model.network\n",
    "    \n",
    "    We also store the parameters of the intensity distribution here for easier access. (model.int_dist)\n",
    "    \n",
    "    The forward function returns a tensor batch_size x 10 tensor to make it compatible with the monai.inferers.sliding_window_inference function.\n",
    "    \n",
    "    To get the final output dictionary one has to also apply the tensor_to_dict function.\n",
    "    \n",
    "    Args:\n",
    "        ch_in (int): number of input channels\n",
    "            Multiple input channels are currently not supported\n",
    "        depth (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
    "        inp_offset, inp_scale (float): Values used for normalizing the input. \n",
    "        order (string): determines the order of layers\n",
    "            in `SingleConv` module. e.g. 'ce' stands for Conv3d+ELU.\n",
    "            See `SingleConv` for more info\n",
    "            Before the input is given to the network is is normalized using these variables.\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        p_offset (float):\n",
    "            bias of the probabilty channel. The negative value avoids very high rates at the start of the training which might cause memory issues.\n",
    "        int_conc, int_rate (float): parameters of the torch.distributions.gamma class.\n",
    "        int_loc (float): shift parameter. \n",
    "        \n",
    "    ToDo:\n",
    "        Support for multiple channels?\n",
    "            \n",
    "            \n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in=1, depth=3, inp_scale=1., inp_offset=0., order='ce', f_maps=64, \n",
    "                 is_2D=False, pred_z=True, p_offset=-5., int_conc=4., int_rate=1., int_loc=1., n_p_ch=1, n_bg_ch=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.inp_scale = inp_scale\n",
    "        self.inp_offset = inp_offset\n",
    "        \n",
    "        self.ch_in = ch_in\n",
    "        self.is_2D = is_2D\n",
    "        self.pred_z = pred_z\n",
    "        self.n_p_ch = n_p_ch\n",
    "        self.n_bg_ch = n_bg_ch\n",
    "        \n",
    "        self.unet = UNet3D(ch_in, final_sigmoid=False, num_levels=depth, is_2D=is_2D,\n",
    "                           layer_order = order, f_maps=f_maps)\n",
    "        self.outnet = OutputNet(f_maps=f_maps, p_offset=p_offset, is_2D=is_2D, n_p_ch=n_p_ch, n_bg_ch=n_bg_ch)\n",
    "        \n",
    "        self.network = nn.ModuleList([self.unet, self.outnet])\n",
    "        self.int_dist = IntensityDist(int_conc, int_rate, int_loc)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = (x-self.inp_offset) / self.inp_scale\n",
    "        \n",
    "        for net in self.network:\n",
    "            x = net(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "    def tensor_to_dict(self, x):\n",
    "        \n",
    "        logits = x[:, 0:self.n_p_ch]\n",
    "        xyzi_mu = x[:, self.n_p_ch:self.n_p_ch+4]\n",
    "        xyzi_sig = x[:, self.n_p_ch+4:self.n_p_ch+8]\n",
    "        bg = x[:, self.n_p_ch+8:self.n_p_ch+8+self.n_bg_ch]\n",
    "        \n",
    "        # Scale bg output\n",
    "        bg = bg * self.inp_scale #[None,:,None,None,None].to(bg.device)\n",
    "    \n",
    "        if not self.pred_z:\n",
    "        \n",
    "            xyzi_mu[:,3] *= 0\n",
    "            xyzi_sig[:,3] *= 0\n",
    "            xyzi_sig[:,3] += 1\n",
    "\n",
    "        ret_dict = {'logits': logits, \n",
    "                    'xyzi_mu': xyzi_mu, \n",
    "                    'xyzi_sigma': xyzi_sig, \n",
    "                    'background': bg}\n",
    "        \n",
    "        return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.funcs.utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1)\n",
    "inp = torch.randn([2,9,37,48,48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([7, 140, 7, 48, 48])\n",
      "xyzi_mu torch.Size([7, 4, 7, 48, 48])\n",
      "xyzi_sigma torch.Size([7, 4, 7, 48, 48])\n",
      "background torch.Size([7, 16, 7, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "model = UnetDecodeNoBn(order= 'ce', ch_in=16, f_maps=256, depth=2, is_2D=True, pred_z=False, n_p_ch=140, n_bg_ch=16)\n",
    "output = model.tensor_to_dict(model(torch.randn([7,16,7,48,48])+1000))\n",
    "# output = model.tensor_to_dict(model(torch.randn([7,16,1,48,48]), shuffle_ch=True))\n",
    "\n",
    "for k in output.keys():\n",
    "    print(k, output[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f3532def8d0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((output['logits'])[0,0,0].detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(output, '../data/model_batch_output_class2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = OmegaConf.load('../config/experiment/msp300_n2.yaml')\n",
    "# model = hydra.utils.instantiate(cfg.model, inp_scale=float(5), inp_offset=float(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6846244"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7436324"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9206564"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578542"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.unet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85831"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.outnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85831"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.outnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 20_MERFISH_visualization.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode2_dev]",
   "language": "python",
   "name": "conda-env-decode2_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
