# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/18_predict_funcs.ipynb (unless otherwise specified).

__all__ = ['predict', 'merfish_predict', 'selective_predict']

# Cell
from ..imports import *
from .file_io import *
from .emitter_io import *
from .utils import *
from monai.inferers import sliding_window_inference
from .plotting import *

# Cell
def predict(model, post_proc, image_paths, sm_fish_ch=0, window_size=[None,128,128], device='cuda'):
    pred_df = DF()
    with torch.no_grad():
        for p in tqdm(image_paths):
            print(p.split('/')[-1])
            img = load_tiff_image(p)[sm_fish_ch]
            z, y, x = img.shape[-3:]
            img = img.reshape(-1,z,y,x)
            for i in range(len(img)):
                print(img[i][None,None].shape)
                output = sliding_window_inference(img[i][None,None], window_size, 1, model.to(device), overlap=0.2, sw_device=device, device='cpu', mode='gaussian')
                # output = model.cpu()(img[i][None,None])
                output = model.tensor_to_dict(output)
                p_si = sliding_window_inference(output['logits'], window_size, 1, post_proc, overlap=0.2, sw_device=device, device='cpu', mode='gaussian')
                i_df = post_proc.get_df(output, p_si)
                print('N. emitters: ', len(i_df))
                pred_df = append_emitter_df(pred_df, i_df)
                free_mem()
        return pred_df

def merfish_predict(model, post_proc, image_paths, window_size=[None,256,256], device='cuda'):
    pred_df = DF()
    with torch.no_grad():
        for p in image_paths:
            print(p.split('/')[-1])
            img = load_tiff_image(p)[None]

            n_chans = img.shape[1]
            print(img.shape)
            z, y, x = img.shape[-3:]

            inp = img
            output = sliding_window_inference(inp, window_size, 1, model.to(device), overlap=0.2, sw_device=device, device='cpu', mode='gaussian')
            output = model.tensor_to_dict(output)
            p_si = sliding_window_inference(output['logits'], window_size, 1, post_proc, overlap=0.2, sw_device=device, device='cpu', mode='gaussian')
            i_df = post_proc.get_df(output, p_si)
            print('N. emitters: ', len(i_df))
            i_df.loc[:,'frame_idx'] = 0
            pred_df = append_emitter_df(pred_df, i_df)
            free_mem()
        return pred_df

# Cell
def selective_predict(model, post_proc, image_paths, window_size=[None, 128, 128], threshold=-1e6, device='cuda'):
    pred_df = DF()
    with torch.no_grad():
        for p in tqdm(image_paths):
            print(p.split('/')[-1])
            img = load_tiff_image(p)
            z,y,x = img.shape[-3:]
            img = img.reshape(-1,z,y,x)
            for i in range(len(img)):
                print(img[i][None,None].shape)
                output = sliding_window_inference(img[i][None,None], window_size, sw_batch_size=1, predictor=model.to(device), overlap=0.2, threshold=threshold, sw_device=device, device='cpu', mode='gaussian')
                # output = model.cpu()(img[i][None,None])
                output = model.tensor_to_dict(output)
                p_si = sliding_window_inference(output['logits'], window_size, sw_batch_size=1, predictor=post_proc, overlap=0.2, threshold=-5, sw_device=device, device='cpu', mode='gaussian')
                i_df = post_proc.get_df(output, p_si)
                print('N. emitters: ', len(i_df))
                pred_df = append_emitter_df(pred_df, i_df)
                free_mem()
        return pred_df