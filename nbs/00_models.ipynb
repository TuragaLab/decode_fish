{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp engine.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECODE Network\n",
    "\n",
    "> Definition of the classes and modules we use to build our DECODE network\n",
    "\n",
    "ToDo: Lots of bloat. Different normalizations aren't needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "import torch.nn as nn\n",
    "import types\n",
    "from functools import partial\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def number_of_features_per_level(init_channel_number, num_levels):\n",
    "    return [init_channel_number * 2 ** k for k in range(num_levels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding):\n",
    "    \"\"\"\n",
    "    Create a list of modules with together constitute a single conv layer with non-linearity\n",
    "    and optional batchnorm/groupnorm.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size(int or tuple): size of the convolving kernel\n",
    "        order (string): order of things, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'gcr' -> groupnorm + conv + ReLU\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "            'bcr' -> batchnorm + conv + ReLU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    Return:\n",
    "        list of tuple (name, module)\n",
    "    \"\"\"\n",
    "    assert 'c' in order, \"Conv layer MUST be present\"\n",
    "    assert order[0] not in 'rle', 'Non-linearity cannot be the first operation in the layer'\n",
    "\n",
    "    modules = []\n",
    "    for i, char in enumerate(order):\n",
    "        if char == 'r':\n",
    "            modules.append(('ReLU', nn.ReLU(inplace=True)))\n",
    "        elif char == 'l':\n",
    "            modules.append(('LeakyReLU', nn.LeakyReLU(negative_slope=0.1, inplace=True)))\n",
    "        elif char == 'e':\n",
    "            modules.append(('ELU', nn.ELU(inplace=True)))\n",
    "        elif char == 'c':\n",
    "            # add learnable bias only in the absence of batchnorm/groupnorm\n",
    "            bias = not ('g' in order or 'b' in order)\n",
    "            modules.append(('conv', nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding, bias=bias, padding_mode='replicate')))\n",
    "        elif char == 'g':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                num_channels = in_channels\n",
    "            else:\n",
    "                num_channels = out_channels\n",
    "\n",
    "            # use only one group if the given number of groups is greater than the number of channels\n",
    "            if num_channels < num_groups:\n",
    "                num_groups = 1\n",
    "\n",
    "            assert num_channels % num_groups == 0, f'Expected number of channels in input to be divisible by num_groups. num_channels={num_channels}, num_groups={num_groups}'\n",
    "            modules.append(('groupnorm', nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)))\n",
    "        elif char == 'b':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(in_channels)))\n",
    "            else:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(out_channels)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported layer type '{char}'. MUST be one of ['b', 'g', 'r', 'l', 'e', 'c']\")\n",
    "\n",
    "    return modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SingleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Basic convolutional module consisting of a Conv3d, non-linearity and optional batchnorm/groupnorm. The order\n",
    "    of operations can be specified via the `order` parameter\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple):\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
    "        super(SingleConv, self).__init__()\n",
    "\n",
    "        for name, module in create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding=padding):\n",
    "            self.add_module(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DoubleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A module consisting of two consecutive convolution layers (e.g. BatchNorm3d+ReLU+Conv3d).\n",
    "    We use (Conv3d+ReLU+GroupNorm3d) by default.\n",
    "    This can be changed however by providing the 'order' argument, e.g. in order\n",
    "    to change to Conv3d+BatchNorm3d+ELU use order='cbe'.\n",
    "    Use padded convolutions to make sure that the output (H_out, W_out) is the same\n",
    "    as (H_in, W_in), so that you don't have to crop in the decoder path.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        encoder (bool): if True we're in the encoder path, otherwise we're in the decoder\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, encoder, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        if encoder:\n",
    "            # we're in the encoder path\n",
    "            conv1_in_channels = in_channels\n",
    "            conv1_out_channels = out_channels // 2\n",
    "            if conv1_out_channels < in_channels:\n",
    "                conv1_out_channels = in_channels\n",
    "            conv2_in_channels, conv2_out_channels = conv1_out_channels, out_channels\n",
    "        else:\n",
    "            # we're in the decoder path, decrease the number of channels in the 1st convolution\n",
    "            conv1_in_channels, conv1_out_channels = in_channels, out_channels\n",
    "            conv2_in_channels, conv2_out_channels = out_channels, out_channels\n",
    "\n",
    "        # conv1\n",
    "        self.add_module('SingleConv1',\n",
    "                        SingleConv(conv1_in_channels, conv1_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding))\n",
    "        # conv2\n",
    "        self.add_module('SingleConv2',\n",
    "                        SingleConv(conv2_in_channels, conv2_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Upsampling(nn.Module):\n",
    "    \"\"\"\n",
    "    Upsamples a given multi-channel 3D data using either interpolation or learned transposed convolution.\n",
    "    Args:\n",
    "        transposed_conv (bool): if True uses ConvTranspose3d for upsampling, otherwise uses interpolation\n",
    "        in_channels (int): number of input channels for transposed conv\n",
    "            used only if transposed_conv is True\n",
    "        out_channels (int): number of output channels for transpose conv\n",
    "            used only if transposed_conv is True\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "            used only if transposed_conv is True\n",
    "        scale_factor (int or tuple): stride of the convolution\n",
    "            used only if transposed_conv is True\n",
    "        mode (str): algorithm used for upsampling:\n",
    "            'nearest' | 'linear' | 'bilinear' | 'trilinear' | 'area'. Default: 'nearest'\n",
    "            used only if transposed_conv is False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transposed_conv, in_channels=None, out_channels=None, kernel_size=3,\n",
    "                 scale_factor=(2, 2, 2), mode='nearest'):\n",
    "        super(Upsampling, self).__init__()\n",
    "\n",
    "        if transposed_conv:\n",
    "            # make sure that the output size reverses the MaxPool3d from the corresponding encoder\n",
    "            # (D_out = (D_in − 1) ×  stride[0] − 2 ×  padding[0] +  kernel_size[0] +  output_padding[0])\n",
    "            self.upsample = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=kernel_size, stride=scale_factor,\n",
    "                                               padding=1)\n",
    "        else:\n",
    "            self.upsample = partial(self._interpolate, mode=mode)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        output_size = encoder_features.size()[2:]\n",
    "        return self.upsample(x, output_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def _interpolate(x, size, mode):\n",
    "        return F.interpolate(x, size=size, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module from the encoder path consisting of the optional max\n",
    "    pooling layer (one may specify the MaxPool kernel_size to be different\n",
    "    than the standard (2,2,2), e.g. if the volumetric data is anisotropic\n",
    "    (make sure to use complementary scale_factor in the decoder path) followed by\n",
    "    a DoubleConv module.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        apply_pooling (bool): if True use MaxPool3d before DoubleConv\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        pool_type (str): pooling layer: 'max' or 'avg'\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, apply_pooling=True,\n",
    "                 pool_kernel_size=2, pool_type='max', basic_module=DoubleConv, conv_layer_order='gcr',\n",
    "                 num_groups=8, padding=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        assert pool_type in ['max', 'avg']\n",
    "        if apply_pooling:\n",
    "            if pool_type == 'max':\n",
    "                self.pooling = nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
    "            else:\n",
    "                self.pooling = nn.AvgPool3d(kernel_size=pool_kernel_size)\n",
    "        else:\n",
    "            self.pooling = None\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=True,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.pooling is not None:\n",
    "            x = self.pooling(x)\n",
    "        x = self.basic_module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module for decoder path consisting of the upsampling layer\n",
    "    (either learned ConvTranspose3d or nearest neighbor interpolation) followed by a basic module (DoubleConv or ExtResNetBlock).\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        scale_factor (tuple): used as the multiplier for the image H/W/D in\n",
    "            case of nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation\n",
    "            from the corresponding encoder\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, scale_factor=(2, 2, 2), basic_module=DoubleConv,\n",
    "                 conv_layer_order='gcr', num_groups=8, mode='nearest', padding=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        if basic_module == DoubleConv:\n",
    "            # if DoubleConv is the basic_module use interpolation for upsampling and concatenation joining\n",
    "            self.upsampling = Upsampling(transposed_conv=False, in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=conv_kernel_size, scale_factor=scale_factor, mode=mode)\n",
    "            # concat joining\n",
    "            self.joining = partial(self._joining, concat=True)\n",
    "        else:\n",
    "            # if basic_module=ExtResNetBlock use transposed convolution upsampling and summation joining\n",
    "            self.upsampling = Upsampling(transposed_conv=True, in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=conv_kernel_size, scale_factor=scale_factor, mode=mode)\n",
    "            # sum joining\n",
    "            self.joining = partial(self._joining, concat=False)\n",
    "            # adapt the number of in_channels for the ExtResNetBlock\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=False,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        x = self.upsampling(encoder_features=encoder_features, x=x)\n",
    "        x = self.joining(encoder_features, x)\n",
    "        x = self.basic_module(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _joining(encoder_features, x, concat):\n",
    "        if concat:\n",
    "            return torch.cat((encoder_features, x), dim=1)\n",
    "        else:\n",
    "            return encoder_features + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Abstract3DUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for standard and residual UNet.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        final_sigmoid (bool): if True apply element-wise nn.Sigmoid after the\n",
    "            final 1x1 convolution, otherwise apply nn.Softmax. MUST be True if nn.BCELoss (two-class) is used\n",
    "            to train the model. MUST be False if nn.CrossEntropyLoss (multi-class) is used to train the model.\n",
    "        basic_module: basic model for the encoder/decoder (DoubleConv, ExtResNetBlock, ....)\n",
    "        layer_order (string): determines the order of layers\n",
    "            in `SingleConv` module. e.g. 'crg' stands for Conv3d+ReLU+GroupNorm3d.\n",
    "            See `SingleConv` for more info\n",
    "        f_maps (int, tuple): if int: number of feature maps in the first conv layer of the encoder (default: 64);\n",
    "            if tuple: number of feature maps at each level\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        num_levels (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
    "        is_segmentation (bool): if True (semantic segmentation problem) Sigmoid/Softmax normalization is applied\n",
    "            after the final convolution; if False (regression problem) the normalization layer is skipped at the end\n",
    "        testing (bool): if True (testing mode) the `final_activation` (if present, i.e. `is_segmentation=true`)\n",
    "            will be applied as the last operation during the forward pass; if False the model is in training mode\n",
    "            and the `final_activation` (even if present) won't be applied; default: False\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel in the basic_module\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        conv_padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, final_sigmoid, basic_module, f_maps=64, is_2D=False, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, testing=False,\n",
    "                 conv_kernel_size=3, pool_kernel_size=2, conv_padding=1, **kwargs):\n",
    "        super(Abstract3DUNet, self).__init__()\n",
    "\n",
    "        self.testing = testing\n",
    "        if is_2D:\n",
    "            conv_kernel_size = [1, conv_kernel_size, conv_kernel_size]\n",
    "            pool_kernel_size = [1, pool_kernel_size, pool_kernel_size]\n",
    "            conv_padding = [0, conv_padding, conv_padding]\n",
    "\n",
    "        if isinstance(f_maps, int):\n",
    "            f_maps = number_of_features_per_level(f_maps, num_levels=num_levels)\n",
    "\n",
    "        # create encoder path consisting of Encoder modules. Depth of the encoder is equal to `len(f_maps)`\n",
    "        encoders = []\n",
    "        for i, out_feature_num in enumerate(f_maps):\n",
    "            if i == 0:\n",
    "                encoder = Encoder(in_channels, out_feature_num,\n",
    "                                  apply_pooling=False,  # skip pooling in the firs encoder\n",
    "                                  basic_module=basic_module,\n",
    "                                  conv_layer_order=layer_order,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  num_groups=num_groups,\n",
    "                                  padding=conv_padding)\n",
    "            else:\n",
    "                # TODO: adapt for anisotropy in the data, i.e. use proper pooling kernel to make the data isotropic after 1-2 pooling operations\n",
    "                encoder = Encoder(f_maps[i - 1], out_feature_num,\n",
    "                                  basic_module=basic_module,\n",
    "                                  conv_layer_order=layer_order,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  num_groups=num_groups,\n",
    "                                  pool_kernel_size=pool_kernel_size,\n",
    "                                  padding=conv_padding)\n",
    "\n",
    "            encoders.append(encoder)\n",
    "\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "\n",
    "        # create decoder path consisting of the Decoder modules. The length of the decoder is equal to `len(f_maps) - 1`\n",
    "        decoders = []\n",
    "        reversed_f_maps = list(reversed(f_maps))\n",
    "        for i in range(len(reversed_f_maps) - 1):\n",
    "            if basic_module == DoubleConv:\n",
    "                in_feature_num = reversed_f_maps[i] + reversed_f_maps[i + 1]\n",
    "            else:\n",
    "                in_feature_num = reversed_f_maps[i]\n",
    "\n",
    "            out_feature_num = reversed_f_maps[i + 1]\n",
    "            # TODO: if non-standard pooling was used, make sure to use correct striding for transpose conv\n",
    "            # currently strides with a constant stride: (2, 2, 2)\n",
    "            decoder = Decoder(in_feature_num, out_feature_num,\n",
    "                              basic_module=basic_module,\n",
    "                              conv_layer_order=layer_order,\n",
    "                              conv_kernel_size=conv_kernel_size,\n",
    "                              num_groups=num_groups,\n",
    "                              padding=conv_padding)\n",
    "            decoders.append(decoder)\n",
    "\n",
    "        self.decoders = nn.ModuleList(decoders)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder part\n",
    "        encoders_features = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            # reverse the encoder outputs to be aligned with the decoder\n",
    "            encoders_features.insert(0, x)\n",
    "\n",
    "        # remove the last encoder's output from the list\n",
    "        # !!remember: it's the 1st in the list\n",
    "        encoders_features = encoders_features[1:]\n",
    "\n",
    "        # decoder part\n",
    "        for decoder, encoder_features in zip(self.decoders, encoders_features):\n",
    "            # pass the output from the corresponding encoder and the output\n",
    "            # of the previous decoder\n",
    "            x = decoder(encoder_features, x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UNet3D(Abstract3DUNet):\n",
    "    \"\"\"\n",
    "    3DUnet model from\n",
    "    `\"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation\"\n",
    "        <https://arxiv.org/pdf/1606.06650.pdf>`.\n",
    "    Uses `DoubleConv` as a basic_module and nearest neighbor upsampling in the decoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, final_sigmoid=True, f_maps=64, is_2D=False, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1,  **kwargs):\n",
    "        super(UNet3D, self).__init__(in_channels=in_channels, final_sigmoid=final_sigmoid,\n",
    "                                     basic_module=DoubleConv, f_maps=f_maps, is_2D=is_2D, layer_order=layer_order,\n",
    "                                     num_groups=num_groups, num_levels=num_levels, is_segmentation=is_segmentation,\n",
    "                                     conv_padding=conv_padding, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export  \n",
    "class OutputNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes the output maps from the U-net and processes them seperately, using two conv3D layers for each group (xyzi_mean, xyzi_sigma, probability, background)\n",
    "    Args:\n",
    "        f_maps: number of channels of the U-net output\n",
    "        p_offset: probability channel bias \n",
    "        is_2D: whether the input is 1D in the z dimension\n",
    "        n_p_ch: Number probability channels (number of genes + number of channels)\n",
    "        n_bg_ch: Number background channels (number of channels or 1)\n",
    "        n_int_ch: Number intensity channels (number of channels)\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, f_maps=64, p_offset=-5., is_2D=False, n_p_ch=1, n_bg_ch=1, n_int_ch=1.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.is_2D = is_2D\n",
    "        self.n_p_ch = n_p_ch\n",
    "        self.n_bg_ch = n_bg_ch\n",
    "        self.n_int_ch = n_int_ch\n",
    "        self.p_offset = p_offset\n",
    "        \n",
    "        xyzi_dim = 3 + n_int_ch\n",
    "        \n",
    "        kernel_size = [1,3,3] if is_2D else [3,3,3]\n",
    "        padding = [0,1,1] if is_2D else [1,1,1]\n",
    "        \n",
    "        \n",
    "        self.p_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.p_out2 = nn.Conv3d(f_maps, n_p_ch, kernel_size=1, padding=0)\n",
    "        nn.init.constant_(self.p_out2.bias,p_offset)\n",
    "        \n",
    "        self.xyzi_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.xyzi_out2 = nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.xyzis_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.xyzis_out2 = nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.bg_out1 = nn.Conv3d(f_maps + n_int_ch, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.bg_out2 = nn.Conv3d(f_maps, n_bg_ch, kernel_size=1, padding=0)\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.p_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.p_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.xyzi_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.xyzi_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.xyzis_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.xyzis_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.bg_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.bg_out2.weight, mode='fan_in', nonlinearity='linear')    \n",
    "        \n",
    "    def forward(self, u_net_out, resid_x):\n",
    "        \n",
    "        # Sigmoid is applied later\n",
    "        logit    = F.elu(self.p_out1(u_net_out))\n",
    "        logit    = self.p_out2(logit)\n",
    "        logit    = torch.clamp(logit, -20., 20)\n",
    "        \n",
    "        xyzi = F.elu(self.xyzi_out1(u_net_out))\n",
    "        xyzi = self.xyzi_out2(xyzi)\n",
    "        \n",
    "        # xyz [-1, 1]\n",
    "        xyz_mu   = torch.tanh(xyzi[:, :3])\n",
    "\n",
    "        # xyz [0, :]\n",
    "        i_mu     = F.softplus(xyzi[:, 3:])\n",
    "        xyzi_mu = torch.cat((xyz_mu, i_mu), dim=1)\n",
    "        \n",
    "        xyzis = F.elu(self.xyzis_out1(u_net_out))\n",
    "        xyzis = self.xyzis_out2(xyzis)\n",
    "        # sigmas [0.01, :]\n",
    "        xyzi_sig = F.softplus(xyzis) + 0.01\n",
    "        \n",
    "        # We use a residual connection from input to facilitate background prediction\n",
    "        bg_inp = torch.cat([u_net_out, resid_x], 1)\n",
    "        \n",
    "        background = F.elu(self.bg_out1(bg_inp))\n",
    "        background = self.bg_out2(background)\n",
    "        # sigmas [0., :]\n",
    "        background = F.softplus(background)\n",
    "        \n",
    "        return torch.cat([logit,xyzi_mu,xyzi_sig,background],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class UnetDecodeNoBn_2S(nn.Module):\n",
    "    \"\"\"\n",
    "    Our DECODE network consists of two 3D U-nets, and an output net module.\n",
    "    The first (small) network runs over each input channel seperately (shared parameters), the second combines information from all channels.\n",
    "    The network parameters can be accessed through model.network\n",
    "    \n",
    "    The forward function returns a tensor batch_size x n_output_channel tensor to make it compatible with the monai.inferers.sliding_window_inference function.\n",
    "    \n",
    "    To get the final output dictionary one has to also apply the tensor_to_dict function.\n",
    "    \n",
    "    Args:\n",
    "        ch_in (int): number of input channels (i.e. n_rounds * n_colors)\n",
    "        depth (int): number of levels in the encoder/decoder path of the second U-net\n",
    "        inp_offset, inp_scale (float): Values used for scaling the input. \n",
    "        order (string): determines the order of layers\n",
    "            in `SingleConv` module. e.g. 'ce' stands for Conv3d+ELU.\n",
    "            See `SingleConv` for more info\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        is_2D: whether the input is 1D in the z dimension (i.e. slice data)\n",
    "        pred_z: setting to false will disable inference of the z position\n",
    "        p_offset (float): bias of the probabilty channel. The negative value avoids very high rates at the start of the training which might cause memory issues.\n",
    "        n_p_ch: Number probability channels (number of genes + number of channels)\n",
    "        n_bg_ch: Number background channels (number of channels or 1)\n",
    "        n_int_ch: Number intensity channels (number of channels)\n",
    "        n_chrom_map_ch: number of colors of. If you dont want to use chromatic abberation map as an additional input set to 0   \n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in=1, depth=3, inp_scale=1., inp_offset=0., order='ce', f_maps=64, \n",
    "                 is_2D=False, pred_z=True, p_offset=-5., int_conc=4., int_rate=1., int_loc=1., n_p_ch=1, n_bg_ch=1, n_int_ch=1, n_chrom_map_ch=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.inp_scale = inp_scale\n",
    "        self.inp_offset = inp_offset\n",
    "        \n",
    "        self.n_chrom_map_ch = n_chrom_map_ch\n",
    "\n",
    "        self.n_ch = ch_in\n",
    "        self.is_2D = is_2D\n",
    "        self.pred_z = pred_z\n",
    "        self.n_p_ch = n_p_ch\n",
    "        self.n_bg_ch = n_bg_ch\n",
    "        self.n_int_ch = n_int_ch\n",
    "            \n",
    "        self.single_n_ch = 12\n",
    "        ch_in = self.n_ch * self.single_n_ch\n",
    "        ch_in = ch_in + self.n_chrom_map_ch\n",
    "\n",
    "        self.single_ch_unet = UNet3D(1, final_sigmoid=False, num_levels=1, is_2D=is_2D, layer_order = order, f_maps=self.single_n_ch)\n",
    "        self.unet = UNet3D(ch_in, final_sigmoid=False, num_levels=depth, is_2D=is_2D, layer_order = order, f_maps=f_maps)\n",
    "        self.outnet = OutputNet(f_maps=f_maps, p_offset=p_offset, is_2D=is_2D, n_p_ch=n_p_ch, n_bg_ch=n_bg_ch, n_int_ch=n_int_ch)  \n",
    "            \n",
    "        self.network = nn.ModuleList([self.single_ch_unet, self.unet, self.outnet])\n",
    "            \n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.n_chrom_map_ch:\n",
    "            # Don't scale chrom. map input\n",
    "            x[:,:-self.n_chrom_map_ch] = (x[:,:-self.n_chrom_map_ch]-self.inp_offset) / self.inp_scale\n",
    "        else:\n",
    "            x = (x-self.inp_offset) / self.inp_scale\n",
    "            \n",
    "        s_x = x[:,:-self.n_chrom_map_ch] if self.n_chrom_map_ch else x\n",
    "        single_ch_out = self.network[0](s_x.flatten(0,1)[:,None]).reshape(s_x.shape[0],-1,*s_x.shape[2:])\n",
    "        m_x = torch.cat([single_ch_out, x[:,-self.n_chrom_map_ch:]], 1) if self.n_chrom_map_ch else single_ch_out\n",
    "        unet_out = self.network[1](m_x)\n",
    "\n",
    "        res_x = x[:,:-self.n_chrom_map_ch] if self.n_chrom_map_ch else x\n",
    "        net_out = self.network[-1](unet_out, res_x)\n",
    "            \n",
    "        return net_out\n",
    "        \n",
    "    def tensor_to_dict(self, x):\n",
    "        \n",
    "        logits = x[:, 0:self.n_p_ch]\n",
    "        xyzi_mu = x[:, self.n_p_ch:self.n_p_ch+3+self.n_int_ch]\n",
    "        xyzi_sig = x[:, self.n_p_ch+3+self.n_int_ch:self.n_p_ch+2*(3+self.n_int_ch)]\n",
    "        bg = x[:, self.n_p_ch+2*(3+self.n_int_ch):self.n_p_ch+2*(3+self.n_int_ch)+self.n_bg_ch]\n",
    "        \n",
    "        # Scale bg output\n",
    "        bg = bg * self.inp_scale\n",
    "    \n",
    "        if not self.pred_z:\n",
    "            # If we don't want to predict z, set mu to 0 and sigma to 1\n",
    "            xyzi_mu[:,2] *= 0\n",
    "            xyzi_sig[:,2] *= 0\n",
    "            xyzi_sig[:,2] += 1\n",
    "\n",
    "        ret_dict = {'logits': logits, \n",
    "                    'xyzi_mu': xyzi_mu, \n",
    "                    'xyzi_sigma': xyzi_sig, \n",
    "                    'background': bg}\n",
    "        \n",
    "        return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn([2,9,1,48,48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([3, 274, 1, 48, 48])\n",
      "xyzi_mu torch.Size([3, 25, 1, 48, 48])\n",
      "xyzi_sigma torch.Size([3, 25, 1, 48, 48])\n",
      "background torch.Size([3, 22, 1, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "model = UnetDecodeNoBn_2S(order= 'ce', ch_in=22, f_maps=256, depth=2, is_2D=True, pred_z=False, n_p_ch=252 + 22, n_bg_ch=22, n_int_ch=22, n_chrom_map_ch=0)\n",
    "output = model.tensor_to_dict(model(torch.randn([3,22,1,48,48])))\n",
    "\n",
    "for k in output.keys():\n",
    "    print(k, output[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f376e6c6a90>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((output['logits'])[0,0,0].detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/torch/cuda/__init__.py:122: UserWarning: \n",
      "    Found GPU2 NVS 510 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is 3.7.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, minor, min_arch // 10, min_arch % 10))\n"
     ]
    }
   ],
   "source": [
    "output = model.tensor_to_dict(model.cuda()(torch.randn([2,22,3,48,48]).cuda()))\n",
    "torch.save(output, '../data/model_batch_output_class5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7866738"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted 25_ensembling.ipynb.\n",
      "Converted 26_gen_train.ipynb.\n",
      "Converted 27_testtime_rescale.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decode_fish_dev2",
   "language": "python",
   "name": "decode_fish_dev2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
