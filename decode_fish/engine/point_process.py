# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/04_pointsource.ipynb (unless otherwise specified).

__all__ = ['PointProcessUniform', 'list_to_locations']

# Cell
from ..imports import *
from torch import distributions as D, Tensor
from torch.distributions import Distribution
from ..funcs.utils import *

# Cell
class PointProcessUniform(Distribution):
    """
    This class is part of the generative model and uses the probability local_rate to generate sample locations on the voxel grid.
    For each emitter we then sample x-,y- and z-offsets uniformly in the range [-0.5,0.5] to get continuous locations.
    Intensities are sampled from a gamma distribution torch.distirubtions.gamma(int_conc, int_rate) which is shifted by int_loc.
    Together with the microscope.scale and the PSF this results in the overall brightness of an emitter.

    Args:
        local_rate torch.tensor . shape(BS, C, H, W, D): Local rate
        int_conc=0., int_rate=1., int_loc (float): parameters of the intensity gamma distribution
        sim_iters (int): instead of sampling once from local_rate, we sample sim_iters times from local_rate/sim_iters.
            This results in the same average number of sampled emitters but allows us to sample multiple emitters within one voxel.

    """
    def __init__(self, local_rate: torch.tensor, int_conc=0., int_rate=1., int_loc=1., sim_iters: int = 5, channels=1, n_bits=1, sim_z=True, codebook=None, int_option=1):

        assert sim_iters >= 1
        self.local_rate = local_rate
        self.device = self._get_device(self.local_rate)
        self.sim_iters = sim_iters
        self.int_conc = int_conc
        self.int_rate = int_rate
        self.int_loc = int_loc
        self.channels = channels
        self.n_bits = n_bits
        self.sim_z=sim_z
        self.codebook=codebook
        self.int_option = int_option

    def sample(self, from_code_book=False, phasing=False):

        res_ = [self._sample(self.local_rate/self.sim_iters, from_code_book, phasing) for i in range(self.sim_iters)]
        locations = torch.cat([i[0] for i in res_], dim=0)
        x_offset = torch.cat([i[1] for i in res_], dim=0)
        y_offset = torch.cat([i[2] for i in res_], dim=0)
        z_offset = torch.cat([i[3] for i in res_], dim=0)
        intensities = torch.cat([i[4] for i in res_], dim=0)
        codes = torch.cat([i[6] for i in res_], dim=0) if from_code_book else None

        return list(locations.T), x_offset, y_offset, z_offset, intensities, res_[0][5], codes

    def _sample(self, local_rate, from_code_book, phasing):

        output_shape = list(local_rate.shape)
        local_rate = torch.clamp(local_rate,0.,1.)
        locations = D.Bernoulli(local_rate).sample()
        n_emitter = int(locations.sum().item())
        x_offset = D.Uniform(low=-0.5, high=0.5).sample(sample_shape=[n_emitter]).to(self.device)
        y_offset = D.Uniform(low=-0.5, high=0.5).sample(sample_shape=[n_emitter]).to(self.device)
        z_offset = D.Uniform(low=-0.5, high=0.5).sample(sample_shape=[n_emitter]).to(self.device)

#         intensities = torch.zeros([n_emitter, self.channels]).to(self.device)
        if self.int_option == 1:
            intensities = D.Gamma(self.int_conc, self.int_rate).sample(sample_shape=[n_emitter, self.channels]).to(self.device) + self.int_loc
        elif self.int_option == 2:
            intensities = D.Gamma(self.int_conc, self.int_rate).sample(sample_shape=[n_emitter, 1]).to(self.device) + self.int_loc
            intensities = intensities.repeat_interleave(self.channels, 1)
        elif self.int_option == 3:
            intensities = D.Gamma(self.int_conc, self.int_rate).sample(sample_shape=[n_emitter, 1]).to(self.device) + self.int_loc
            intensities = intensities.repeat_interleave(self.channels, 1)
            int_noise = D.Uniform(low=.7, high=1.5).sample(sample_shape=intensities.shape).to(self.device)
            intensities *= int_noise

        # If 2D data z-offset is 0
        if not self.sim_z:
            z_offset *= 0

        locations = locations.nonzero(as_tuple=False)

        if self.channels > 1:
            code_draw = None
            if from_code_book:
                code_draw = torch.randint(0, len(self.codebook), size=[n_emitter])
                ch_draw = self.codebook[code_draw]
#                 code_draw = torch.randint(0, len(self.codebook) + self.n_dump_codes,size=[n_emitter])

#                 ch_draw = torch.zeros([n_emitter, self.channels], dtype=torch.bool).to(self.device)
#                 code_inds = code_draw<len(self.codebook)
#                 dump_inds = code_draw>=len(self.codebook)
#                 # All draws lower than the codebook length get a code from it
#                 ch_draw[code_inds] = self.codebook[code_draw[code_inds]].to(self.device)
#                 # All draws higher than the codebook length get a random code with an average length of n_bits, but at least 1
#                 # There is a certain probability that dump codes are in the codebook. We ignore it for now.
#                 ch_draw[dump_inds, torch.randint(0, self.channels, size=[sum(dump_inds)])] = 1
#                 ch_draw[dump_inds] += torch.distributions.Binomial(total_count=1, probs=torch.ones([sum(dump_inds),self.channels])/self.channels*(self.n_bits - 1)).sample().type(torch.bool).to(self.device)

#                 # n_dump_codes controsl the rate of out-of-code book codes, but they all get assigned to the code_index len(codebook)+1
#                 code_draw = torch.clamp_max(code_draw, len(self.codebook))

            else:

                m_draw = torch.multinomial(torch.ones([n_emitter,self.channels])/self.channels, self.n_bits, replacement=False)
                ch_draw = torch.zeros(intensities.shape).to(intensities.device)
                ch_draw.scatter_(index=m_draw.to(intensities.device), dim=1, value=1)

            intensities = intensities.to(self.device) * ch_draw.to(self.device)
            output_shape.insert(1, self.channels)

        return locations, x_offset, y_offset, z_offset, intensities, tuple(output_shape), code_draw

    @staticmethod
    def _get_device(x):
        return getattr(x, 'device')


def list_to_locations(locations, output_shape):
    tmp =torch.zeros(output_shape, device=locations[0].device)
    coord = torch.stack(locations).T
    #incase you have multiple emitter present
    for i in coord: tmp[tuple(i)] += 1
    return tmp