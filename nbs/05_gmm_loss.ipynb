{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp engine.gmm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from torch import distributions as D, Tensor\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions.utils import _sum_rightmost\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ext_log_prob(mix, x):\n",
    "    \n",
    "    x = mix._pad(x)\n",
    "    log_prob_x = mix.component_distribution.base_dist.log_prob(x) \n",
    "    log_prob_x = _sum_rightmost(log_prob_x, 1)\n",
    "    \n",
    "    log_mix_prob = torch.log_softmax(mix.mixture_distribution.logits, dim=-1)  \n",
    "    return log_prob_x, log_mix_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PointProcessGaussian(Distribution):\n",
    "    def __init__(self, logits, xyzi_mu, xyzi_sigma, int_logits=None, **kwargs):\n",
    "        \"\"\" Defines our loss function. Given logits, xyzi_mu and xyzi_sigma \n",
    "        \n",
    "        The count loss first constructs a Gaussian approximation to the predicted number of emitters by summing the mean and the variance of the Bernoulli detection probability map,\n",
    "        and then maximizes the probability of the true number of emitters under this distribution. \n",
    "        The localization loss models the distribution of sub-pixel localizations with a coordinate-wise independent Gaussian probability distribution  with a 3D standard deviation. \n",
    "        For imprecise localizations, this probability is maximized for large sigmas, for precise localizations for small sigmas. \n",
    "        The distribution of all localizations over the entire image is approximated as a weighted average of individual localization distributions, where the weights correspond to the probability of detection.\n",
    "        \n",
    "        Args:\n",
    "            logits: shape (B,1,D,H,W)\n",
    "            xyzi_mu: shape (B,4,D,H,W)\n",
    "            xyzi_sigma: shape (B,4,D,H,W)\n",
    "        \"\"\"\n",
    "        self.logits = logits\n",
    "        self.xyzi_mu = xyzi_mu\n",
    "        self.xyzi_sigma = xyzi_sigma\n",
    "        self.int_logits = int_logits\n",
    "        \n",
    "    def log_prob(self, locations, x_offset, y_offset, z_offset, intensities, n_bits, channels, min_int_sig, int_fac=1):\n",
    "        \n",
    "        gauss_dim = 3 + channels\n",
    "        batch_size = self.logits.shape[0]\n",
    "        if channels == 1:\n",
    "            xyzi, s_mask = get_true_labels(batch_size, locations, x_offset, y_offset, z_offset, intensities)\n",
    "        else:\n",
    "            xyzi, s_mask = get_true_labels_mf(batch_size, n_bits, channels, \n",
    "                                              locations, x_offset, y_offset, z_offset, intensities)\n",
    "        counts = s_mask.sum(-1)\n",
    "\n",
    "        P = torch.sigmoid(self.logits) \n",
    "        count_mean = P.sum(dim=[2, 3, 4]).squeeze(-1)\n",
    "        count_var = (P - P ** 2).sum(dim=[2, 3, 4]).squeeze(-1) \n",
    "        count_dist = D.Normal(count_mean, torch.sqrt(count_var))\n",
    "\n",
    "        count_prob =  count_dist.log_prob(counts) # * counts\n",
    "\n",
    "        pix_inds = torch.nonzero(P,as_tuple=True)\n",
    "\n",
    "        xyzi_mu = self.xyzi_mu[pix_inds[0],:,pix_inds[2],pix_inds[3],pix_inds[4]]\n",
    "        xyzi_mu[:,:3] += torch.stack([pix_inds[4],pix_inds[3],pix_inds[2]], 1) + 0.5\n",
    "        xyzi_mu = xyzi_mu.reshape(batch_size,-1,gauss_dim)\n",
    "        xyzi_sig = self.xyzi_sigma[pix_inds[0],:,pix_inds[2],pix_inds[3],pix_inds[4]].reshape(batch_size,-1,gauss_dim)\n",
    "\n",
    "        \n",
    "        int_P = torch.sigmoid(self.int_logits)[:,:channels]\n",
    "\n",
    "        int_mean = int_P.sum(dim=[1])\n",
    "        int_var = (int_P - int_P ** 2).sum(dim=[1])\n",
    "        int_dist = D.Normal(int_mean, torch.sqrt(int_var))\n",
    "\n",
    "        int_count_prob = (P[:,0].detach() * int_dist.log_prob(torch.ones_like(int_mean).cuda() * n_bits)).sum(dim=[1,2,3])\n",
    "\n",
    "        mix_logits = self.logits[pix_inds].reshape(batch_size,-1)\n",
    "        int_logits = rearrange(self.int_logits[pix_inds[0],:,pix_inds[2],pix_inds[3],pix_inds[4]], '(b p) ch -> b p ch', b=batch_size)\n",
    "\n",
    "        '''split int 2'''\n",
    "        xyz_sl = np.s_[:,:,:3]\n",
    "        int_sl = np.s_[:,:,3:3+channels]\n",
    "\n",
    "        comp_xyz = D.Independent(D.Normal(xyzi_mu[xyz_sl], xyzi_sig[xyz_sl] + 0.00001), 1)\n",
    "        comp_int = D.Independent(D.Normal(xyzi_mu[int_sl], xyzi_sig[int_sl] + min_int_sig), 1)\n",
    "\n",
    "        xyz = xyzi[xyz_sl].transpose(0, 1)[:,:,None,:]\n",
    "        log_prob_xyz = comp_xyz.base_dist.log_prob(xyz) \n",
    "        log_prob_xyz = _sum_rightmost(log_prob_xyz, 1)\n",
    "\n",
    "        log_mix_prob_xyz = torch.log_softmax(mix_logits, -1)\n",
    "\n",
    "        ''' '''\n",
    "        int_ch = xyzi[int_sl].transpose(0, 1)[:,:,None,:]\n",
    "        int_bin = torch.where(int_ch > 0, torch.ones_like(int_ch), torch.zeros_like(int_ch))\n",
    "        log_prob_int = comp_int.base_dist.log_prob(int_ch)\n",
    "\n",
    "        log_mix_prob_int = torch.log_softmax(int_logits, dim=-1) + torch.log(4*torch.ones(1)).cuda()\n",
    "\n",
    "        total_prob_int = torch.logsumexp(torch.gather((log_prob_int + log_mix_prob_int), -1, int_bin.argsort(-1, descending=True).expand(-1,-1,log_prob_int.shape[2],-1))[...,:4] ,-1)\n",
    "        total_prob_xyz = torch.logsumexp(log_prob_xyz + log_mix_prob_xyz + total_prob_int,-1).transpose(0, 1)\n",
    "        \n",
    "#         total_prob_xyz = torch.logsumexp(log_prob_xyz + log_mix_prob_xyz + _sum_rightmost(log_prob_int, 1),-1).transpose(0, 1) # old loss new format\n",
    "\n",
    "        total_prob = ((total_prob_xyz) * s_mask).sum(-1)\n",
    "\n",
    "        return count_prob + 0.0*int_count_prob, total_prob\n",
    "    \n",
    "    def log_prob_old(self, locations, x_offset, y_offset, z_offset, intensities, n_bits, channels, min_int_sig, int_fac=1):\n",
    "        \"\"\" Creates the distributions for the count and localization loss and evaluates the log probability for the given set of localizations under those distriubtions.\n",
    "        \n",
    "            Args:\n",
    "                locations: tuple with voxel locations of inferred emitters\n",
    "                x_offset, y_offset,z_offset: continuous within pixel offsets. Has lenght of number of emitters in the whole batch.\n",
    "                intensties: brightness of emitters. Has lenght of number of emitters in the whole batch.\n",
    "                \n",
    "            Returns:\n",
    "                count_prob: count loss. Has langth of batch_size\n",
    "                spatial_prob: localizations loss. Has langth of batch_size\n",
    "        \"\"\"     \n",
    "        \n",
    "        gauss_dim = 3 + channels\n",
    "        batch_size = self.logits.shape[0]\n",
    "        if channels == 1:\n",
    "            xyzi, s_mask = get_true_labels(batch_size, locations, x_offset, y_offset, z_offset, intensities)\n",
    "        else:\n",
    "            xyzi, s_mask = get_true_labels_mf(batch_size, n_bits, channels, \n",
    "                                              locations, x_offset, y_offset, z_offset, intensities)\n",
    "        counts = s_mask.sum(-1)\n",
    "        \n",
    "        P = torch.sigmoid(self.logits) \n",
    "        count_mean = P.sum(dim=[2, 3, 4]).squeeze(-1)\n",
    "        count_var = (P - P ** 2).sum(dim=[2, 3, 4]).squeeze(-1) \n",
    "        count_dist = D.Normal(count_mean, torch.sqrt(count_var))\n",
    "                \n",
    "        count_prob =  count_dist.log_prob(counts) # * counts\n",
    "        \n",
    "        mixture_probs = P / P.sum(dim=[2, 3, 4], keepdim=True)\n",
    "        \n",
    "        pix_inds = torch.nonzero(P,as_tuple=True)\n",
    "\n",
    "        xyzi_mu = self.xyzi_mu[pix_inds[0],:,pix_inds[2],pix_inds[3],pix_inds[4]]\n",
    "        xyzi_mu[:,:3] += torch.stack([pix_inds[4],pix_inds[3],pix_inds[2]], 1) + 0.5\n",
    "        xyzi_mu = xyzi_mu.reshape(batch_size,-1,gauss_dim)\n",
    "        xyzi_sig = self.xyzi_sigma[pix_inds[0],:,pix_inds[2],pix_inds[3],pix_inds[4]].reshape(batch_size,-1,gauss_dim)\n",
    "\n",
    "#         print(xyzi_mu.shape, xyzi.shape)\n",
    "        \n",
    "        mix = D.Categorical(mixture_probs[pix_inds].reshape(batch_size,-1))\n",
    "        \n",
    "        '''base 19 dim'''\n",
    "#         xyzi_sig[:,:,3:] = xyzi_sig[:,:,3:] + min_int_sig\n",
    "#         comp = D.Independent(D.Normal(xyzi_mu, xyzi_sig + 0.00001), 1)\n",
    "#         spatial_gmm = D.MixtureSameFamily(mix, comp)\n",
    "#         spatial_prob = spatial_gmm.log_prob(xyzi.transpose(0, 1)).transpose(0,1)\n",
    "#         total_prob = (spatial_prob * s_mask).sum(-1)\n",
    "        '''split int'''\n",
    "        xyz_sl = np.s_[:,:,:3]\n",
    "        int_sl = np.s_[:,:,3:]\n",
    "        \n",
    "        xyzi_sig[int_sl] = xyzi_sig[int_sl] + min_int_sig\n",
    "        \n",
    "        comp_xyz = D.Independent(D.Normal(xyzi_mu[xyz_sl], xyzi_sig[xyz_sl] + 0.00001), 1)\n",
    "        comp_int = D.Independent(D.Normal(xyzi_mu[int_sl], xyzi_sig[int_sl] + 0.00001), 1)\n",
    "        \n",
    "        spatial_gmm = D.MixtureSameFamily(mix, comp_xyz)\n",
    "        int_gmm = D.MixtureSameFamily(mix, comp_int)\n",
    "        \n",
    "        spatial_prob, log_mix_prob = ext_log_prob(spatial_gmm, xyzi[xyz_sl].transpose(0, 1))\n",
    "        int_prob, _                = ext_log_prob(int_gmm, xyzi[int_sl].transpose(0, 1))\n",
    "\n",
    "        total_prob = torch.logsumexp(spatial_prob + 0*int_prob + log_mix_prob,-1).transpose(0, 1)\n",
    "        total_prob = (total_prob * s_mask).sum(-1)\n",
    "        \n",
    "        return count_prob, total_prob\n",
    "\n",
    "def get_sample_mask(bs, locations):\n",
    "    \n",
    "    counts_ = torch.unique(locations[0], return_counts=True)[1]\n",
    "    batch_loc = torch.unique(locations[0])\n",
    "    \n",
    "    counts = torch.cuda.LongTensor(bs).fill_(0)\n",
    "    counts[batch_loc] = counts_\n",
    "    \n",
    "    max_counts = counts.max()\n",
    "    if max_counts==0: max_counts = 1 #if all 0 will return empty matrix of correct size\n",
    "    s_arr = cum_count_per_group(locations[0])\n",
    "    s_mask   = torch.cuda.FloatTensor(bs,max_counts).fill_(0)\n",
    "    s_mask[locations[0],s_arr] = 1   \n",
    "    \n",
    "    return s_mask, s_arr\n",
    "    \n",
    "def get_true_labels(bs, locations, x_os, y_os, z_os, *args):\n",
    "    \n",
    "    s_mask, s_arr = get_sample_mask(bs, locations)\n",
    "    max_counts = s_mask.shape[1]\n",
    "    \n",
    "    x =  x_os + locations[4].type(torch.cuda.FloatTensor) + 0.5 \n",
    "    y =  y_os + locations[3].type(torch.cuda.FloatTensor) + 0.5 \n",
    "    z =  z_os + locations[2].type(torch.cuda.FloatTensor) + 0.5 \n",
    "    \n",
    "    gt_vars = torch.stack([x, y, z] + [item for item in args], dim=1)\n",
    "    gt_list = torch.cuda.FloatTensor(bs,max_counts,gt_vars.shape[1]).fill_(0)\n",
    "    \n",
    "    gt_list[locations[0],s_arr] = gt_vars\n",
    "    return gt_list, s_mask    \n",
    "\n",
    "def get_true_labels_mf(bs, n_bits, channels, locations, x_os, y_os, z_os, int_ch):\n",
    "    \n",
    "    b_inds = torch.cat([torch.tensor([0], device=x_os.device),((x_os[1:] - x_os[:-1]).nonzero() + 1)[:,0], \n",
    "                        torch.tensor([len(x_os)], device=x_os.device)])\n",
    "    n_gt = len(b_inds) - 1\n",
    "    \n",
    "    xyz_locs = [l[b_inds[:-1]] for l in locations]\n",
    "    x_os = x_os[b_inds[:-1]]\n",
    "    y_os = y_os[b_inds[:-1]]\n",
    "    z_os = z_os[b_inds[:-1]]\n",
    "    \n",
    "    s_mask, s_arr = get_sample_mask(bs, xyz_locs)\n",
    "    max_counts = s_mask.shape[1]\n",
    "    \n",
    "    x =  x_os + xyz_locs[4].type(torch.cuda.FloatTensor) + 0.5 \n",
    "    y =  y_os + xyz_locs[3].type(torch.cuda.FloatTensor) + 0.5 \n",
    "    z =  z_os + xyz_locs[2].type(torch.cuda.FloatTensor) + 0.5 \n",
    "    \n",
    "    loc_idx = []\n",
    "    for i in range(n_gt):\n",
    "        loc_idx += [i] * (b_inds[i+1] - b_inds[i])\n",
    "    \n",
    "    intensity = torch.zeros([n_gt, channels]).to(x.device)\n",
    "    intensity[loc_idx, locations[1]] = int_ch\n",
    "    \n",
    "    gt_vars = torch.stack([x, y, z], dim=1)\n",
    "    gt_vars = torch.cat([gt_vars, intensity], dim=1)\n",
    "    gt_list = torch.cuda.FloatTensor(bs,max_counts,gt_vars.shape[1]).fill_(0)\n",
    "    \n",
    "    gt_list[xyz_locs[0],s_arr] = gt_vars\n",
    "    return gt_list, s_mask  \n",
    "\n",
    "def grp_range(counts: torch.Tensor):\n",
    "    assert counts.dim() == 1\n",
    "\n",
    "    idx = counts.cumsum(0)\n",
    "    id_arr = torch.ones(idx[-1], dtype=int, device=counts.device)\n",
    "    id_arr[0] = 0\n",
    "    id_arr[idx[:-1]] = -counts[:-1] + 1\n",
    "    return id_arr.cumsum(0)\n",
    "\n",
    "def cum_count_per_group(arr):\n",
    "    \"\"\"\n",
    "    Helper function that returns the cumulative sum per group.\n",
    "    Example:\n",
    "        [0, 0, 0, 1, 2, 2, 0] --> [0, 1, 2, 0, 0, 1, 3]\n",
    "    \"\"\"\n",
    "\n",
    "    if arr.numel() == 0:\n",
    "        return arr\n",
    "\n",
    "    _, cnt = torch.unique(arr, return_counts=True)\n",
    "    return grp_range(cnt)[np.argsort(np.argsort(arr.cpu().numpy(), kind='mergesort'), kind='mergesort')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = torch.load('../data/model_batch_output_code_int_p.pt')\n",
    "sim_vars = torch.load('../data/sim_var_code_int_p.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1864515.7500, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-0.4427, -0.6439,  0.8149,  1.5036,  1.7690,  1.2149, -1.6208],\n",
       "        device='cuda:0'),\n",
       " tensor([  0.0000, -10.8937,   0.0000,  -1.5160,  -1.5397,   0.0000,   0.0000],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppg = PointProcessGaussian(**model_out)\n",
    "ppg.log_prob(*sim_vars[:5], n_bits=4, channels=16, min_int_sig=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4242107.5000, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-0.4427, -0.6439,  0.8149,  1.5036,  1.7690,  1.2149, -1.6208],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0000, -9.4015,  0.0000, -1.1146, -1.3592,  0.0000,  0.0000],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppg.log_prob(*sim_vars[:5], n_bits=4, channels=16, min_int_sig=-.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations, x_offset, y_offset, z_offset, intensities = sim_vars[:5]\n",
    "n_bits=4; channels=16; min_int_sig=1.; int_fac=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_dim = 3 + channels\n",
    "batch_size = ppg.logits.shape[0]\n",
    "if channels == 1:\n",
    "    xyzi, s_mask = get_true_labels(batch_size, locations, x_offset, y_offset, z_offset, intensities)\n",
    "else:\n",
    "    xyzi, s_mask = get_true_labels_mf(batch_size, n_bits, channels, \n",
    "                                      locations, x_offset, y_offset, z_offset, intensities)\n",
    "counts = s_mask.sum(-1)\n",
    "\n",
    "P = torch.sigmoid(ppg.logits) \n",
    "count_mean = P.sum(dim=[2, 3, 4]).squeeze(-1)\n",
    "count_var = (P - P ** 2).sum(dim=[2, 3, 4]).squeeze(-1) \n",
    "count_dist = D.Normal(count_mean, torch.sqrt(count_var))\n",
    "\n",
    "count_prob =  count_dist.log_prob(counts) # * counts\n",
    "\n",
    "pix_inds = torch.nonzero(P,as_tuple=True)\n",
    "\n",
    "xyzi_mu = ppg.xyzi_mu[pix_inds[0],:,pix_inds[2],pix_inds[3],pix_inds[4]]\n",
    "xyzi_mu[:,:3] += torch.stack([pix_inds[4],pix_inds[3],pix_inds[2]], 1) + 0.5\n",
    "xyzi_mu = xyzi_mu.reshape(batch_size,-1,gauss_dim)\n",
    "xyzi_sig = ppg.xyzi_sigma[pix_inds[0],:,pix_inds[2],pix_inds[3],pix_inds[4]].reshape(batch_size,-1,gauss_dim)\n",
    "\n",
    "mix_logits = ppg.logits[pix_inds].reshape(batch_size,-1)\n",
    "\n",
    "int_P = torch.sigmoid(ppg.int_logits)[:,:channels]\n",
    "\n",
    "int_mean = int_P.sum(dim=[1])\n",
    "int_var = (int_P - int_P ** 2).sum(dim=[1])\n",
    "int_dist = D.Normal(int_mean, torch.sqrt(int_var))\n",
    "\n",
    "int_count_prob = (P[:,0].detach() * int_dist.log_prob(torch.ones_like(int_mean).cuda() * n_bits)).sum(dim=[1,2,3])\n",
    "\n",
    "int_logits = rearrange(ppg.int_logits[pix_inds[0],:,pix_inds[2],pix_inds[3],pix_inds[4]], '(b p) ch -> b p ch', b=batch_size)\n",
    "\n",
    "'''split int 2'''\n",
    "xyz_sl = np.s_[:,:,:3]\n",
    "int_sl = np.s_[:,:,3:3+channels]\n",
    "\n",
    "comp_xyz = D.Independent(D.Normal(xyzi_mu[xyz_sl], xyzi_sig[xyz_sl] + 0.00001), 1)\n",
    "comp_int = D.Independent(D.Normal(xyzi_mu[int_sl], xyzi_sig[int_sl] + 0.5), 1)\n",
    "\n",
    "xyz = xyzi[xyz_sl].transpose(0, 1)[:,:,None,:]\n",
    "log_prob_xyz = comp_xyz.base_dist.log_prob(xyz) \n",
    "log_prob_xyz = _sum_rightmost(log_prob_xyz, 1)\n",
    "\n",
    "log_mix_prob_xyz = torch.log_softmax(mix_logits, -1)\n",
    "\n",
    "''' '''\n",
    "int_ch = xyzi[int_sl].transpose(0, 1)[:,:,None,:]\n",
    "int_bin = torch.where(int_ch > 0, torch.ones_like(int_ch), torch.zeros_like(int_ch))\n",
    "log_prob_int = comp_int.base_dist.log_prob(int_ch)\n",
    "\n",
    "log_mix_prob_int = torch.log_softmax(int_logits, dim=-1) + torch.log(4*torch.ones(1)).cuda()\n",
    "\n",
    "total_prob_int = torch.logsumexp(torch.gather((log_prob_int + log_mix_prob_int), -1, int_bin.argsort(-1, descending=True).expand(-1,-1,log_prob_int.shape[2],-1))[...,:4] ,-1)\n",
    "total_prob_xyz = torch.logsumexp(log_prob_xyz + total_prob_int + log_mix_prob_xyz,-1).transpose(0, 1)\n",
    "    \n",
    "total_prob = ((total_prob_xyz) * s_mask).sum(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_prob_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[2.2004, 3.3153, 3.5250, 3.0570]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[5.2921, 2.1371, 4.3546, 4.3649]],\n",
       "\n",
       "         [[5.3260, 5.9417, 2.6763, 1.4460]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[3.8238, 5.2879, 3.3923, 4.3409]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[3.8967, 4.2183, 3.4798, 4.0483]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000]]]], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(int_ch, -1, int_bin.argsort(-1, descending=True))[...,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 1, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_bin.expand(-1,-,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3239441., device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-168510.2344, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-351.2671, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(tra, -1, int_bin.argsort(-1, descending=True))[...,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob_int.sort(-1).values - torch.gather(log_prob_int, -1, log_prob_int.argsort(-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'as_tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35474/4129594098.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mint_inds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'as_tuple'"
     ]
    }
   ],
   "source": [
    "int_inds.as_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_inds = int_bin.nonzero(as_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.]],\n",
       "\n",
       "         [[1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_int.base_dist.log_prob(int_ch)[int_bin.nonzero(as_tuple=True)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 2304, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_mix_prob_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f340e6601c0>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_prob_int[0,1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 2304])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob_xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3205, -6.7991, -0.3170, -1.9641, -2.3155, -0.1513, -5.6953],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_count_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(log_mix_prob_xyz.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0000, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(log_mix_prob_int_x_p).sum(-1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_probs = P #/ P.sum(dim=[2, 3, 4], keepdim=True)\n",
    "mix = D.Categorical(probs=mixture_probs[pix_inds].reshape(batch_size,-1))\n",
    "\n",
    "mix_logits = ppg.logits[pix_inds].reshape(batch_size,-1)\n",
    "\n",
    "mix_logits = mix.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7046, 0.7743, 0.9607, 0.5040, 0.5034, 0.9645, 0.8619],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(mix.logits).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.logit(mixture_probs.reshape(7,-1))).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixture_probs.reshape(7,-1).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix.probs.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7046, 0.7743, 0.9607, 0.5040, 0.5034, 0.9645, 0.8619],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(mix.logits).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0000, 4.0000, 4.0000, 4.0000, 4.0000, 4.0000, 4.0000],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(spatial_gmm.mixture_distribution.logits + torch.log(torch.ones(1).cuda()*4)).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5.5903,  -8.4780,  -9.4026,  ..., -11.3734, -10.2057,  -6.4693],\n",
       "        [ -9.8069, -13.7562, -13.2726,  ..., -12.6984, -12.7982,  -9.4775],\n",
       "        [ -4.3763,  -7.3635,  -6.6908,  ...,  -7.2632,  -3.1791,  -2.5495],\n",
       "        ...,\n",
       "        [ -7.5141, -10.9540, -11.2139,  ..., -11.7508, -12.0796,  -8.9566],\n",
       "        [ -3.8025,  -6.7223,  -6.2076,  ...,  -6.1614,  -6.7067,  -4.2940],\n",
       "        [ -6.5509, -10.1974, -10.3095,  ..., -13.1061,  -5.4175,  -3.8014]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_mix_prob_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5.5903,  -8.4780,  -9.4026,  ..., -11.3734, -10.2057,  -6.4693],\n",
       "        [ -9.8069, -13.7562, -13.2726,  ..., -12.6984, -12.7982,  -9.4775],\n",
       "        [ -4.3763,  -7.3635,  -6.6908,  ...,  -7.2632,  -3.1791,  -2.5495],\n",
       "        ...,\n",
       "        [ -7.5141, -10.9540, -11.2139,  ..., -11.7508, -12.0796,  -8.9566],\n",
       "        [ -3.8025,  -6.7223,  -6.2076,  ...,  -6.1614,  -6.7067,  -4.2940],\n",
       "        [ -6.5509, -10.1974, -10.3095,  ..., -13.1061,  -5.4175,  -3.8014]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_mix_prob_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7, 2304])\n",
      "torch.Size([7, 2304])\n",
      "torch.Size([3, 7, 2304])\n",
      "torch.Size([3, 7])\n"
     ]
    }
   ],
   "source": [
    "print(log_prob_xyz.shape)\n",
    "print(log_mix_prob_xyz.shape)\n",
    "print((log_prob_xyz + log_mix_prob_xyz).shape)\n",
    "print(torch.logsumexp(log_prob_xyz + log_mix_prob_xyz,-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7, 2304, 16])\n",
      "torch.Size([7, 2304, 16])\n",
      "torch.Size([3, 7, 2304, 16])\n",
      "torch.Size([3, 7, 2304])\n"
     ]
    }
   ],
   "source": [
    "print(log_prob_int.shape)\n",
    "print(log_mix_prob_int_x_p.shape)\n",
    "print((log_prob_int + log_mix_prob_int_x_p).shape)\n",
    "print(torch.logsumexp(log_prob_int + log_mix_prob_int_x_p,-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-30149.2031, -30149.2031, -30149.2031],\n",
       "        [-36184.4805, -36311.1953, -36365.1406],\n",
       "        [-24744.4707, -24744.4707, -24744.4707],\n",
       "        [-33971.2578, -33420.4922, -33420.4922],\n",
       "        [-34393.4453, -33823.4766, -33823.4766],\n",
       "        [-23325.5508, -23325.5508, -23325.5508],\n",
       "        [-31364.9023, -31364.9023, -31364.9023]], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_prob_int.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_prob_xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 3, 2304])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_prob_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logsumexp(log_prob_xyz + log_mix_prob_xyz,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 2304])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logsumexp(log_mix_prob_int + log_mix_prob_int_x_p,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2304, 7])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_prob_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_prob_xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000, -1.8633,  0.0000,  0.4107,  0.5226,  0.0000,  0.0000],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 2304, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_mix.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.engine.point_process import PointProcessUniform\n",
    "point_process = PointProcessUniform(local_rate = torch.ones([2,1,48,48,48])*.001, int_conc=1.0, sim_iters=5, channels=16, n_bits=4)\n",
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape = point_process.sample(phasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1782\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n",
      "tensor([112., 119.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "locs_3d = [l.cuda() for l in locs_3d]\n",
    "# xyzi_true, s_mask = get_true_labels(2, locs_3d, x_os_3d.cuda(), y_os_3d.cuda(), z_os_3d.cuda(), ints_3d.cuda())\n",
    "xyzi_true, s_mask = get_true_labels_mf(2, 4, 16, locs_3d, x_os_3d.cuda(), y_os_3d.cuda(), z_os_3d.cuda(), ints_3d.cuda())\n",
    "print(len(locs_3d[0]))\n",
    "print(s_mask)\n",
    "print(s_mask.sum(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-272.8184, -314.4428], device='cuda:0', grad_fn=<SubBackward0>),\n",
       " tensor([-48894.6641, -45920.2773], device='cuda:0', grad_fn=<SumBackward1>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppg = PointProcessGaussian(**model_out)\n",
    "gmm_loss = ppg.log_prob(locs_3d, x_os_3d.cuda(), y_os_3d.cuda(), z_os_3d.cuda(), ints_3d.cuda(), n_bits=4, channels=16, min_int_sig=0.1)\n",
    "gmm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([119, 2, 2304, 3])\n",
      "torch.Size([119, 2, 2304, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-272.8184, -314.4428], device='cuda:0', grad_fn=<SubBackward0>),\n",
       " tensor([-48895.4141, -45920.4023], device='cuda:0', grad_fn=<SumBackward1>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppg = PointProcessGaussian(**model_out)\n",
    "gmm_loss = ppg.log_prob(locs_3d, x_os_3d.cuda(), y_os_3d.cuda(), z_os_3d.cuda(), ints_3d.cuda(), n_bits=4, channels=16, min_int_sig=0.1)\n",
    "gmm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -6410.5063, -12788.6523], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1000):\n",
    "#     gmm_loss = PointProcessGaussian(**model_out).log_prob(locs_3d, x_os_3d.cuda(), y_os_3d.cuda(), z_os_3d.cuda(), ints_3d.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 20_MERFISH_visualization.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode_fish_dev]",
   "language": "python",
   "name": "conda-env-decode_fish_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
