# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02_microscope.ipynb (unless otherwise specified).

__all__ = ['Microscope', 'place_psf', 'extract_psf_roi', 'get_roi_filt_inds', 'mic_inp_apply_inds']

# Cell
from ..imports import *
import torch.nn as nn
from ..funcs.utils import *
from torch.jit import script
from typing import Union, List
import torch.nn.functional as F
from .place_psfs import _place_psf, CudaPlaceROI
# import elasticdeform.torch as etorch
import kornia

# Cell
class Microscope(nn.Module):
    """
    The Mircoscope module takes  5 vectors 'locations', 'x_os', 'y_os', 'z_os',
    'ints_3d' turns them into 3D data through the following steps:
    1) Apply continuous shifts to the PSF according to x_os, y_os, z_os
    2) Clamping the PSF (retaining only positive values)
    3) Normalize the PSF dividing it by it's max value
    6) Place point spread function according to locations  to
    generate 'x_sim'
    7) Multiplies x_sim with scale

    Args:
        psf (torch.nn.Module): Parametric PSF
        noise (torch.nn.Module): Camera noise model
        scale(float): Constant for scaling

    Shape:
        -Input: locations: Tuple(torch.Tensor)
                x_os_val: (N_emitters,)
                y_os_val: (N_emitters,)
                z_os_val: (N_emitters,)
                ints_val: (N_emitters,C)
                output_shape: Shape Tuple(BS, C, H, W, D)

        -Output: xsim: (BS, C, H, W, D)
    """


    def __init__(self, psf, noise, scale = 10000., norm='none', psf_noise=0, pos_noise_xy=0, pos_noise_z=0, slice_rec=False, ch_facs=None, ch_cols=None, col_shifts_enabled=False, col_shifts_yxds=None):

        super().__init__()
        self.psf = psf
        self.psf_init_vol = psf.psf_volume.detach().to('cuda')
        self.scale = scale
        self.noise = noise
        self.norm = norm
        self.col_shifts_enabled = col_shifts_enabled
        if col_shifts_enabled:
            self.col_shifts_yx = col_shifts_yxds[:2]
            self.col_shift_ds = col_shifts_yxds[2]

        self.psf_norm_init = 1.
        if slice_rec:
            if norm == 'sum':
                self.psf_norm_init = self.psf.psf_volume.detach().sum(2, keepdim=True).sum(3, keepdim=True).to('cuda')
            if norm == 'max':
                self.psf_norm_init = self.psf.psf_volume.detach().amax(2, keepdim=True).amax(3, keepdim=True).to('cuda')
        else:
            if norm == 'sum':
                self.psf_norm_init = self.psf.psf_volume.detach().sum().to('cuda')
            if norm == 'max':
                self.psf_norm_init = self.psf.psf_volume.detach().amax().to('cuda')

        self.theta = self.noise.theta_scale * self.noise.theta_par

        self.psf_noise = psf_noise
        self.pos_noise_xy = pos_noise_xy
        self.pos_noise_z = pos_noise_z

        self.slice_rec = slice_rec
        self.psf_z_size = self.psf.psf_volume.shape[-3]
        self.ch_cols = ch_cols

        self.register_parameter(name='channel_shifts', param=self.noise.channel_shifts)

        ###
        if self.col_shifts_enabled:
            xs = int(np.ceil(self.col_shifts_yx[0]/self.col_shift_ds))
            ys = int(np.ceil(self.col_shifts_yx[1]/self.col_shift_ds))
            self.register_parameter(name='color_shifts', param=torch.nn.Parameter(torch.zeros([self.psf.n_cols, ys, xs])))
        ###

        self.ch_scale = 1. if ch_facs is None else torch.tensor(ch_facs).cuda()
        self.register_parameter(name='channel_facs', param=torch.nn.Parameter(torch.ones(len(self.channel_shifts)).cuda()))

        self.register_parameter(name='theta_par', param=self.noise.theta_par)
        self.register_parameter(name='psf_vol', param=self.psf.psf_volume)

    def get_ch_mult(self):
        return (self.channel_facs * self.ch_scale)[None,:,None,None,None]

    def add_psf_noise(self, psf_stack):

        '''Gaussian noise'''
        noise = torch.distributions.Normal(loc=0, scale=self.psf_noise).sample(psf_stack.shape).to(psf_stack.device)
        noise *= torch.sqrt(psf_stack)

        return psf_stack + noise

        '''Individual elastic deformation for each PSF (to slow)'''
#         psf_deformed = torch.cat([etorch.deform_grid(psf, torch.distributions.Normal(loc=0, scale=self.psf_noise).sample([3,3,3,3]).to(psf_stack.device), order=3)[None]
#                                   for psf in psf_stack[:,0]])
        '''Single deformation for all PSF in batch (kinda stupid)'''
#         psf_deformed = etorch.deform_grid(psf_stack[:,0], torch.distributions.Normal(loc=0, scale=self.psf_noise).sample([3,3,3,3]).to(psf_stack.device), axis=(1,2,3),order=3)
#         return psf_deformed[:,None]

    def add_pos_noise(self, x_os, y_os, z_os):

        x_n = torch.distributions.Normal(loc=0, scale=self.pos_noise_xy).sample(x_os.shape).to(x_os.device).reshape(-1,4)
        x_n -= x_n.mean(-1, keepdim=True)
        x_os = x_os + x_n.reshape(-1)
        y_n = torch.distributions.Normal(loc=0, scale=self.pos_noise_xy).sample(y_os.shape).to(y_os.device).reshape(-1,4)
        y_n -= y_n.mean(-1, keepdim=True)
        y_os = y_os + y_n.reshape(-1)
        z_n = torch.distributions.Normal(loc=0, scale=self.pos_noise_z).sample(z_os.shape).to(z_os.device).reshape(-1,4)
        z_n -= z_n.mean(-1, keepdim=True)
        z_os = z_os + z_n.reshape(-1)

        return x_os, y_os, z_os

    def get_single_ch_inputs(self, locations, x_os_val, y_os_val, z_os_val, i_val, output_shape=None, ycrop=None, xcrop=None):

        ch_inds = i_val.nonzero(as_tuple=True)

        if len(ch_inds[1]):
            if ch_inds[1].max() > 0:

                locations = [l[ch_inds[0]] for l in locations]
                locations.insert(1,ch_inds[1])

                shifts = self.channel_shifts - self.channel_shifts.mean(0)[None]

                x_os_val = x_os_val[ch_inds[0]] + shifts[ch_inds[1], 0]
                y_os_val = y_os_val[ch_inds[0]] + shifts[ch_inds[1], 1]
                z_os_val = z_os_val[ch_inds[0]] + shifts[ch_inds[1], 2]
                i_val = i_val[ch_inds]

                if self.col_shifts_enabled and ycrop is not None:
                    c_inds = torch.tensor(self.ch_cols)[ch_inds[1]]
                    blurred_col_shift = kornia.filters.gaussian_blur2d(self.color_shifts[None],  (9,9), (3,3))[0]

                    col_shifts = blurred_col_shift[:, torch.div(locations[2][ch_inds[0]] + ycrop.cuda()[locations[0]], self.col_shift_ds, rounding_mode='trunc'),
                                                      torch.div(locations[3][ch_inds[0]] + xcrop.cuda()[locations[0]], self.col_shift_ds, rounding_mode='trunc')]

                    x_os_val[c_inds==1] = x_os_val[c_inds==1] + col_shifts[0, c_inds==1]
                    y_os_val[c_inds==1] = y_os_val[c_inds==1] + col_shifts[1, c_inds==1]

        else:
            locations.insert(1,locations[0])

        return locations, x_os_val, y_os_val, z_os_val, i_val, output_shape

    def get_psf_norm(self, c_inds = None, z_inds=None):

        if self.norm != 'max' and self.norm != 'sum':
            return 1.
        if not self.slice_rec:
            if self.norm == 'max': psf_norm = self.psf.psf_volume.max()
            if self.norm == 'sum': psf_norm = torch.clamp_min(self.psf.psf_volume, 0).sum()
            init = self.psf_norm_init
        else:
            if self.norm == 'max':
                psf_norm = self.psf.psf_volume.amax(2, keepdim=True).amax(3, keepdim=True)
            if self.norm == 'sum':
                psf_norm = torch.clamp_min(self.psf.psf_volume, 0).sum(2, keepdim=True).sum(3, keepdim=True)
            if c_inds is not None:
                psf_norm = psf_norm[c_inds, z_inds][:,:,None,None]
                init = self.psf_norm_init[c_inds, z_inds][:,:,None,None]
            else:
                psf_norm = psf_norm[0,z_inds][:,None,None]
                init = self.psf_norm_init[0,z_inds][:,None,None]

        return psf_norm/init

    def forward(self, locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, ret_psfs=False, add_noise=False, add_pos_noise=False):

        if len(locations[0]):
            c_inds=torch.tensor(self.ch_cols)[locations[1]] if self.ch_cols is not None else None

            # Apply continuous shift
            if self.slice_rec and self.psf_z_size > 1:
                z_os_ch = torch.clamp(z_os_ch,-0.49999,0.49999) + 0.5 # transform to [0,1]
                z_scaled = z_os_ch * (self.psf_z_size - 2) # [0, z_size]
                z_inds = (torch.div(z_scaled, 1, rounding_mode='trunc')).type(torch.cuda.LongTensor) + 1
                z_os = -(z_scaled%1.) + 0.5

                if self.pos_noise_xy and add_pos_noise:
                    x_os_ch, y_os_ch, z_os = self.add_pos_noise(x_os_ch, y_os_ch, z_os)

                psf = self.psf(x_os_ch, y_os_ch, z_os, z_inds, c_inds=c_inds)
#                 psf = psf[torch.arange(len(z_os_ch)),:,z_inds][:,:,None]
            else:
                if self.pos_noise_xy and add_noise:
                    x_os_ch, y_os_ch, z_os_ch = self.add_pos_noise(x_os_ch, y_os_ch, z_os_ch)

                psf = self.psf(x_os_ch, y_os_ch, z_os_ch, c_inds=c_inds)
                z_inds = None

#             torch.clamp_min_(psf,0)
#             psf = psf/self.get_psf_norm(c_inds, z_inds)
#             psf = torch.nn.Softmax(-1)(psf.flatten(-2,-1)).reshape(psf.shape)

            if self.norm != 'none':
                psf = torch.abs(psf)
                psf = psf/psf.flatten(-2,-1).sum(-1)[...,None,None]
            else:
                torch.clamp_min_(psf,0)
                psf /= self.psf.psf_fac

            if self.psf_noise and add_noise:
                psf = self.add_psf_noise(psf)

            # applying intenseties
#             tot_intensity = torch.clamp_min(i_val, 0)  * self.channel_facs[locations[1]]
            tot_intensity = torch.clamp_min(i_val, 0)  #* (self.ch_scale * self.channel_facs)[locations[1]] * (self.ch_norm/self.channel_facs.sum())

            psf = psf * tot_intensity[:,None,None,None,None]

            if ret_psfs:
                return self.scale * psf

            # place psf according to locations
            xsim = place_psf(locations, psf, output_shape)

            # scale (not learnable)
            xsim = self.scale * xsim

            return xsim

        else:

            return torch.zeros(output_shape).cuda()

# Cell
def place_psf(locations, psf_volume, output_shape):
    """
    Places point spread functions (psf_volume) in to corresponding locations.

    Args:
        locations: tuple with the 5D voxel coordinates
        psf_volume: torch.Tensor
        output_shape: Shape Tuple(BS, C, H, W, D)

    Returns:
        placed_psf: torch.Tensor with shape (BS, C, H, W, D)
    """

    b, c, z, y, x = locations
    # Deprecated python loop
#     placed_psf = _place_psf(psf_volume, b, c, z, y, x, torch.tensor(output_shape))

    # New fancy cuda loop
    N_psfs, _, psf_s_z, psf_s_y, psf_s_x = psf_volume.shape
    placed_psf = CudaPlaceROI.apply(psf_volume[:,0], output_shape[0], output_shape[1], output_shape[2], output_shape[3], output_shape[4], N_psfs, psf_s_z, psf_s_y, psf_s_x, b, c, z-psf_s_z//2, y-psf_s_y//2, x-psf_s_x//2)

    assert placed_psf.shape == output_shape
    return placed_psf

def extract_psf_roi(locations, x_vol, roi_shape):
    """
    Extract ROIs from a given volume
    """

    batch, ch, z, y, x = locations
    rois = _extract_psf_roi(x_vol, batch, ch, z, y, x, roi_shape)

    return rois

from scipy.spatial.distance import cdist
from scipy.spatial import KDTree

def get_roi_filt_inds(batch, ch, z, y, x, psf_shape, vol_shape, min_dist=None, slice_rec=False):
    """
    Filter locations that are used for gen. model training.
    Returns remaining indices.
    """

    inds = torch.arange(len(x))

    if min_dist:
        # scale z if slice_rec ??
        bczyx = np.stack([cpu(batch)*1000,cpu(ch)*1000,cpu(z),cpu(y),cpu(x)]).T
        tree = KDTree(bczyx)
        pairs = tree.query_pairs(r=min_dist, output_type='ndarray')
        pair_inds = np.unique(pairs.reshape(-1))

    psf_d, psf_h, psf_w = psf_shape[-3:]
    vol_d, vol_h, vol_w = vol_shape[-3:]
    # Filter locs at the edges
    cond = (x > psf_w//2) & (x < vol_w - psf_w//2)
    cond*= (y > psf_h//2) & (y < vol_h - psf_h//2)
    if not slice_rec:
        cond*= (z > psf_d//2) & (z < vol_d - psf_d)

    if min_dist:
        return np.setdiff1d(inds[cond], pair_inds, assume_unique=True)
    else:
        return inds[cond]

def mic_inp_apply_inds(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, inds):

    locations = [l[inds] for l in locations]
    return locations, x_os_ch[inds], y_os_ch[inds], z_os_ch[inds], i_val[inds], output_shape

# Cell
@script
def _extract_psf_roi(x_vol, batch, ch, z, y, x, roi_shape):

    """
    Extract rois. We assume that border conditions are dealt with already.

    """

    psf_b, psf_ch, psf_d, psf_h, psf_w = roi_shape[0], roi_shape[1], roi_shape[2], roi_shape[3], roi_shape[4]
    roi_vol = torch.empty(psf_b, psf_ch, psf_d, psf_h, psf_w).to(x_vol.device)
    pad_zyx = [torch.div(psf_d, 2, rounding_mode='trunc'), torch.div(psf_h, 2, rounding_mode='trunc'), torch.div(psf_w, 2, rounding_mode='trunc')]

    z_l = z - pad_zyx[0]
    y_l = y - pad_zyx[1]
    x_l = x - pad_zyx[2]

    z_h = z + pad_zyx[0] + 1
    y_h = y + pad_zyx[1] + 1
    x_h = x + pad_zyx[2] + 1

    for idx in range(x.shape[0]):

        roi_vol[idx] = x_vol[batch[idx], ch[idx],
                         z_l[idx] : z_h[idx],
                         y_l[idx] : y_h[idx],
                         x_l[idx] : x_h[idx]]

    return roi_vol