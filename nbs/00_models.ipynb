{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp engine.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECODE Network\n",
    "\n",
    "> Definition of the classes and modules we use to build our DECODE network\n",
    "\n",
    "ToDo: Lots of bloat. Different normalizations aren't needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "import torch.nn as nn\n",
    "import types\n",
    "from functools import partial\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def number_of_features_per_level(init_channel_number, num_levels):\n",
    "    return [init_channel_number * 2 ** k for k in range(num_levels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding):\n",
    "    \"\"\"\n",
    "    Create a list of modules with together constitute a single conv layer with non-linearity\n",
    "    and optional batchnorm/groupnorm.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size(int or tuple): size of the convolving kernel\n",
    "        order (string): order of things, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'gcr' -> groupnorm + conv + ReLU\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "            'bcr' -> batchnorm + conv + ReLU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    Return:\n",
    "        list of tuple (name, module)\n",
    "    \"\"\"\n",
    "    assert 'c' in order, \"Conv layer MUST be present\"\n",
    "    assert order[0] not in 'rle', 'Non-linearity cannot be the first operation in the layer'\n",
    "\n",
    "    modules = []\n",
    "    for i, char in enumerate(order):\n",
    "        if char == 'r':\n",
    "            modules.append(('ReLU', nn.ReLU(inplace=True)))\n",
    "        elif char == 'l':\n",
    "            modules.append(('LeakyReLU', nn.LeakyReLU(negative_slope=0.1, inplace=True)))\n",
    "        elif char == 'e':\n",
    "            modules.append(('ELU', nn.ELU(inplace=True)))\n",
    "        elif char == 'c':\n",
    "            # add learnable bias only in the absence of batchnorm/groupnorm\n",
    "            bias = not ('g' in order or 'b' in order)\n",
    "            modules.append(('conv', nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding, bias=bias, padding_mode='replicate')))\n",
    "        elif char == 'g':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                num_channels = in_channels\n",
    "            else:\n",
    "                num_channels = out_channels\n",
    "\n",
    "            # use only one group if the given number of groups is greater than the number of channels\n",
    "            if num_channels < num_groups:\n",
    "                num_groups = 1\n",
    "\n",
    "            assert num_channels % num_groups == 0, f'Expected number of channels in input to be divisible by num_groups. num_channels={num_channels}, num_groups={num_groups}'\n",
    "            modules.append(('groupnorm', nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)))\n",
    "        elif char == 'b':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(in_channels)))\n",
    "            else:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(out_channels)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported layer type '{char}'. MUST be one of ['b', 'g', 'r', 'l', 'e', 'c']\")\n",
    "\n",
    "    return modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SingleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Basic convolutional module consisting of a Conv3d, non-linearity and optional batchnorm/groupnorm. The order\n",
    "    of operations can be specified via the `order` parameter\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple):\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
    "        super(SingleConv, self).__init__()\n",
    "\n",
    "        for name, module in create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding=padding):\n",
    "            self.add_module(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DoubleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A module consisting of two consecutive convolution layers (e.g. BatchNorm3d+ReLU+Conv3d).\n",
    "    We use (Conv3d+ReLU+GroupNorm3d) by default.\n",
    "    This can be changed however by providing the 'order' argument, e.g. in order\n",
    "    to change to Conv3d+BatchNorm3d+ELU use order='cbe'.\n",
    "    Use padded convolutions to make sure that the output (H_out, W_out) is the same\n",
    "    as (H_in, W_in), so that you don't have to crop in the decoder path.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        encoder (bool): if True we're in the encoder path, otherwise we're in the decoder\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, encoder, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        if encoder:\n",
    "            # we're in the encoder path\n",
    "            conv1_in_channels = in_channels\n",
    "            conv1_out_channels = out_channels // 2\n",
    "            if conv1_out_channels < in_channels:\n",
    "                conv1_out_channels = in_channels\n",
    "            conv2_in_channels, conv2_out_channels = conv1_out_channels, out_channels\n",
    "        else:\n",
    "            # we're in the decoder path, decrease the number of channels in the 1st convolution\n",
    "            conv1_in_channels, conv1_out_channels = in_channels, out_channels\n",
    "            conv2_in_channels, conv2_out_channels = out_channels, out_channels\n",
    "\n",
    "        # conv1\n",
    "        self.add_module('SingleConv1',\n",
    "                        SingleConv(conv1_in_channels, conv1_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding))\n",
    "        # conv2\n",
    "        self.add_module('SingleConv2',\n",
    "                        SingleConv(conv2_in_channels, conv2_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Upsampling(nn.Module):\n",
    "    \"\"\"\n",
    "    Upsamples a given multi-channel 3D data using either interpolation or learned transposed convolution.\n",
    "    Args:\n",
    "        transposed_conv (bool): if True uses ConvTranspose3d for upsampling, otherwise uses interpolation\n",
    "        in_channels (int): number of input channels for transposed conv\n",
    "            used only if transposed_conv is True\n",
    "        out_channels (int): number of output channels for transpose conv\n",
    "            used only if transposed_conv is True\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "            used only if transposed_conv is True\n",
    "        scale_factor (int or tuple): stride of the convolution\n",
    "            used only if transposed_conv is True\n",
    "        mode (str): algorithm used for upsampling:\n",
    "            'nearest' | 'linear' | 'bilinear' | 'trilinear' | 'area'. Default: 'nearest'\n",
    "            used only if transposed_conv is False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transposed_conv, in_channels=None, out_channels=None, kernel_size=3,\n",
    "                 scale_factor=(2, 2, 2), mode='nearest'):\n",
    "        super(Upsampling, self).__init__()\n",
    "\n",
    "        if transposed_conv:\n",
    "            # make sure that the output size reverses the MaxPool3d from the corresponding encoder\n",
    "            # (D_out = (D_in − 1) ×  stride[0] − 2 ×  padding[0] +  kernel_size[0] +  output_padding[0])\n",
    "            self.upsample = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=kernel_size, stride=scale_factor,\n",
    "                                               padding=1)\n",
    "        else:\n",
    "            self.upsample = partial(self._interpolate, mode=mode)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        output_size = encoder_features.size()[2:]\n",
    "        return self.upsample(x, output_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def _interpolate(x, size, mode):\n",
    "        return F.interpolate(x, size=size, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module from the encoder path consisting of the optional max\n",
    "    pooling layer (one may specify the MaxPool kernel_size to be different\n",
    "    than the standard (2,2,2), e.g. if the volumetric data is anisotropic\n",
    "    (make sure to use complementary scale_factor in the decoder path) followed by\n",
    "    a DoubleConv module.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        apply_pooling (bool): if True use MaxPool3d before DoubleConv\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        pool_type (str): pooling layer: 'max' or 'avg'\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, apply_pooling=True,\n",
    "                 pool_kernel_size=2, pool_type='max', basic_module=DoubleConv, conv_layer_order='gcr',\n",
    "                 num_groups=8, padding=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        assert pool_type in ['max', 'avg']\n",
    "        if apply_pooling:\n",
    "            if pool_type == 'max':\n",
    "                self.pooling = nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
    "            else:\n",
    "                self.pooling = nn.AvgPool3d(kernel_size=pool_kernel_size)\n",
    "        else:\n",
    "            self.pooling = None\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=True,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.pooling is not None:\n",
    "            x = self.pooling(x)\n",
    "        x = self.basic_module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module for decoder path consisting of the upsampling layer\n",
    "    (either learned ConvTranspose3d or nearest neighbor interpolation) followed by a basic module (DoubleConv or ExtResNetBlock).\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        scale_factor (tuple): used as the multiplier for the image H/W/D in\n",
    "            case of nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation\n",
    "            from the corresponding encoder\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, scale_factor=(2, 2, 2), basic_module=DoubleConv,\n",
    "                 conv_layer_order='gcr', num_groups=8, mode='nearest', padding=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        if basic_module == DoubleConv:\n",
    "            # if DoubleConv is the basic_module use interpolation for upsampling and concatenation joining\n",
    "            self.upsampling = Upsampling(transposed_conv=False, in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=conv_kernel_size, scale_factor=scale_factor, mode=mode)\n",
    "            # concat joining\n",
    "            self.joining = partial(self._joining, concat=True)\n",
    "        else:\n",
    "            # if basic_module=ExtResNetBlock use transposed convolution upsampling and summation joining\n",
    "            self.upsampling = Upsampling(transposed_conv=True, in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=conv_kernel_size, scale_factor=scale_factor, mode=mode)\n",
    "            # sum joining\n",
    "            self.joining = partial(self._joining, concat=False)\n",
    "            # adapt the number of in_channels for the ExtResNetBlock\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=False,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        x = self.upsampling(encoder_features=encoder_features, x=x)\n",
    "        x = self.joining(encoder_features, x)\n",
    "        x = self.basic_module(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _joining(encoder_features, x, concat):\n",
    "        if concat:\n",
    "            return torch.cat((encoder_features, x), dim=1)\n",
    "        else:\n",
    "            return encoder_features + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Abstract3DUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for standard and residual UNet.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        final_sigmoid (bool): if True apply element-wise nn.Sigmoid after the\n",
    "            final 1x1 convolution, otherwise apply nn.Softmax. MUST be True if nn.BCELoss (two-class) is used\n",
    "            to train the model. MUST be False if nn.CrossEntropyLoss (multi-class) is used to train the model.\n",
    "        basic_module: basic model for the encoder/decoder (DoubleConv, ExtResNetBlock, ....)\n",
    "        layer_order (string): determines the order of layers\n",
    "            in `SingleConv` module. e.g. 'crg' stands for Conv3d+ReLU+GroupNorm3d.\n",
    "            See `SingleConv` for more info\n",
    "        f_maps (int, tuple): if int: number of feature maps in the first conv layer of the encoder (default: 64);\n",
    "            if tuple: number of feature maps at each level\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        num_levels (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
    "        is_segmentation (bool): if True (semantic segmentation problem) Sigmoid/Softmax normalization is applied\n",
    "            after the final convolution; if False (regression problem) the normalization layer is skipped at the end\n",
    "        testing (bool): if True (testing mode) the `final_activation` (if present, i.e. `is_segmentation=true`)\n",
    "            will be applied as the last operation during the forward pass; if False the model is in training mode\n",
    "            and the `final_activation` (even if present) won't be applied; default: False\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel in the basic_module\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        conv_padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, final_sigmoid, basic_module, f_maps=64, is_2D=False, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, testing=False,\n",
    "                 conv_kernel_size=3, pool_kernel_size=2, conv_padding=1, **kwargs):\n",
    "        super(Abstract3DUNet, self).__init__()\n",
    "\n",
    "        self.testing = testing\n",
    "        if is_2D:\n",
    "            conv_kernel_size = [1, conv_kernel_size, conv_kernel_size]\n",
    "            pool_kernel_size = [1, pool_kernel_size, pool_kernel_size]\n",
    "            conv_padding = [0, conv_padding, conv_padding]\n",
    "\n",
    "        if isinstance(f_maps, int):\n",
    "            f_maps = number_of_features_per_level(f_maps, num_levels=num_levels)\n",
    "\n",
    "        # create encoder path consisting of Encoder modules. Depth of the encoder is equal to `len(f_maps)`\n",
    "        encoders = []\n",
    "        for i, out_feature_num in enumerate(f_maps):\n",
    "            if i == 0:\n",
    "                encoder = Encoder(in_channels, out_feature_num,\n",
    "                                  apply_pooling=False,  # skip pooling in the firs encoder\n",
    "                                  basic_module=basic_module,\n",
    "                                  conv_layer_order=layer_order,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  num_groups=num_groups,\n",
    "                                  padding=conv_padding)\n",
    "            else:\n",
    "                # TODO: adapt for anisotropy in the data, i.e. use proper pooling kernel to make the data isotropic after 1-2 pooling operations\n",
    "                encoder = Encoder(f_maps[i - 1], out_feature_num,\n",
    "                                  basic_module=basic_module,\n",
    "                                  conv_layer_order=layer_order,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  num_groups=num_groups,\n",
    "                                  pool_kernel_size=pool_kernel_size,\n",
    "                                  padding=conv_padding)\n",
    "\n",
    "            encoders.append(encoder)\n",
    "\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "\n",
    "        # create decoder path consisting of the Decoder modules. The length of the decoder is equal to `len(f_maps) - 1`\n",
    "        decoders = []\n",
    "        reversed_f_maps = list(reversed(f_maps))\n",
    "        for i in range(len(reversed_f_maps) - 1):\n",
    "            if basic_module == DoubleConv:\n",
    "                in_feature_num = reversed_f_maps[i] + reversed_f_maps[i + 1]\n",
    "            else:\n",
    "                in_feature_num = reversed_f_maps[i]\n",
    "\n",
    "            out_feature_num = reversed_f_maps[i + 1]\n",
    "            # TODO: if non-standard pooling was used, make sure to use correct striding for transpose conv\n",
    "            # currently strides with a constant stride: (2, 2, 2)\n",
    "            decoder = Decoder(in_feature_num, out_feature_num,\n",
    "                              basic_module=basic_module,\n",
    "                              conv_layer_order=layer_order,\n",
    "                              conv_kernel_size=conv_kernel_size,\n",
    "                              num_groups=num_groups,\n",
    "                              padding=conv_padding)\n",
    "            decoders.append(decoder)\n",
    "\n",
    "        self.decoders = nn.ModuleList(decoders)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder part\n",
    "        encoders_features = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            # reverse the encoder outputs to be aligned with the decoder\n",
    "            encoders_features.insert(0, x)\n",
    "\n",
    "        # remove the last encoder's output from the list\n",
    "        # !!remember: it's the 1st in the list\n",
    "        encoders_features = encoders_features[1:]\n",
    "\n",
    "        # decoder part\n",
    "        for decoder, encoder_features in zip(self.decoders, encoders_features):\n",
    "            # pass the output from the corresponding encoder and the output\n",
    "            # of the previous decoder\n",
    "            x = decoder(encoder_features, x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UNet3D(Abstract3DUNet):\n",
    "    \"\"\"\n",
    "    3DUnet model from\n",
    "    `\"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation\"\n",
    "        <https://arxiv.org/pdf/1606.06650.pdf>`.\n",
    "    Uses `DoubleConv` as a basic_module and nearest neighbor upsampling in the decoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, final_sigmoid=True, f_maps=64, is_2D=False, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1,  **kwargs):\n",
    "        super(UNet3D, self).__init__(in_channels=in_channels, final_sigmoid=final_sigmoid,\n",
    "                                     basic_module=DoubleConv, f_maps=f_maps, is_2D=is_2D, layer_order=layer_order,\n",
    "                                     num_groups=num_groups, num_levels=num_levels, is_segmentation=is_segmentation,\n",
    "                                     conv_padding=conv_padding, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IntensityDist(nn.Module):\n",
    "    \"\"\"\n",
    "    Stores the three parameters that determine the distribution of intensities for simulator learning (and which are optimized during autoencoder learning)\n",
    "    Args:\n",
    "        int_conc, int_rate: parameters of the torch.distributions.gamma class.\n",
    "        int_loc: shift parameter. \n",
    "    \"\"\"\n",
    "    def __init__(self, int_conc, int_rate, int_loc):\n",
    "        super().__init__()\n",
    "        self.int_conc = torch.nn.Parameter(torch.tensor(float(int_conc)))\n",
    "        self.int_rate = torch.nn.Parameter(torch.tensor(float(int_rate)))\n",
    "        self.int_loc = torch.nn.Parameter(torch.tensor(float(int_loc)))  \n",
    "        \n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv3d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "class OutputNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes the output maps from the U-net and processes them seperately, using two conv3D layers for each group (xyzi_mean, xyzi_sigma, probability, background)\n",
    "    Args:\n",
    "        f_maps: number of channels of the U-net output\n",
    "        p_offset: probability channel bias \n",
    "        is_2D: whether the input is 1D in the z dimension\n",
    "        n_p_ch: Number probability channels (number of genes)\n",
    "        n_bg_ch: Number background channels (number of channels or 1)\n",
    "        n_int_ch: Number intensity channels (number of channels)\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, f_maps=64, p_offset=-5., is_2D=False, n_p_ch=1, n_bg_ch=1, n_int_ch=1., n_out_l=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.is_2D = is_2D\n",
    "        self.n_p_ch = n_p_ch\n",
    "        self.n_bg_ch = n_bg_ch\n",
    "        self.n_int_ch = n_int_ch\n",
    "        self.p_offset = p_offset\n",
    "        \n",
    "        xyzi_dim = 3 + n_int_ch\n",
    "        \n",
    "        kernel_size = [1,3,3] if is_2D else [3,3,3]\n",
    "        padding = [0,1,1] if is_2D else [1,1,1]\n",
    "        \n",
    "#         self.p_out_l = []\n",
    "        \n",
    "#         for i in range(n_out_l):\n",
    "#             self.p_out_l.append(nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate'))\n",
    "#             self.p_out_l.append(nn.ELU())\n",
    "#         self.p_out_l.append(nn.Conv3d(f_maps, n_p_ch, kernel_size=1, padding=0))\n",
    "#         self.p_out_l = nn.Sequential(*self.p_out_l)\n",
    "        \n",
    "#         self.xyzi_out_l = []\n",
    "        \n",
    "#         for i in range(n_out_l):\n",
    "#             self.xyzi_out_l.append(nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate'))\n",
    "#             self.xyzi_out_l.append(nn.ELU())\n",
    "#         self.xyzi_out_l.append(nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0))\n",
    "#         self.xyzi_out_l = nn.Sequential(*self.xyzi_out_l)\n",
    "        \n",
    "#         self.xyzis_out_l = []\n",
    "        \n",
    "#         for i in range(n_out_l):\n",
    "#             self.xyzis_out_l.append(nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate'))\n",
    "#             self.xyzis_out_l.append(nn.ELU())\n",
    "#         self.xyzis_out_l.append(nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0))\n",
    "#         self.xyzis_out_l = nn.Sequential(*self.xyzis_out_l)\n",
    "        \n",
    "#         self.bg_out_l = []\n",
    "        \n",
    "#         for i in range(n_out_l):\n",
    "#             self.bg_out_l.append(nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate'))\n",
    "#             self.bg_out_l.append(nn.ELU())\n",
    "#         self.bg_out_l.append(nn.Conv3d(f_maps, n_bg_ch, kernel_size=1, padding=0))\n",
    "#         self.bg_out_l = nn.Sequential(*self.bg_out_l)\n",
    "        \n",
    "#         for net in [self.p_out_l, self.xyzi_out_l, self.xyzis_out_l, self.bg_out_l]:\n",
    "#             net.apply(init_weights)\n",
    "        \n",
    "        \n",
    "        self.p_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.p_out2 = nn.Conv3d(f_maps, n_p_ch, kernel_size=1, padding=0)\n",
    "        nn.init.constant_(self.p_out2.bias,p_offset)\n",
    "        \n",
    "        self.xyzi_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.xyzi_out2 = nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.xyzis_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.xyzis_out2 = nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.bg_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.bg_out2 = nn.Conv3d(f_maps, n_bg_ch, kernel_size=1, padding=0)\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.p_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.p_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.xyzi_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.xyzi_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.xyzis_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.xyzis_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.bg_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.bg_out2.weight, mode='fan_in', nonlinearity='linear')    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "#         logit = self.p_out_l(x) + self.p_offset\n",
    "#         logit = torch.clamp(logit, -20., 20)\n",
    "        \n",
    "#         xyzi = self.xyzi_out_l(x)\n",
    "        \n",
    "#         xyz_mu   = torch.tanh(xyzi[:, :3])\n",
    "#         i_mu     = F.softplus(xyzi[:, 3:])\n",
    "        \n",
    "#         xyzi_mu = torch.cat((xyz_mu, i_mu), dim=1)\n",
    "        \n",
    "#         xyzis = self.xyzis_out_l(x)\n",
    "#         xyzi_sig = F.softplus(xyzis) + 0.01\n",
    "        \n",
    "#         background = self.bg_out_l(x)\n",
    "#         background = F.softplus(background)\n",
    "        \n",
    "        logit    = F.elu(self.p_out1(x))\n",
    "        logit    = self.p_out2(logit)\n",
    "        logit    = torch.clamp(logit, -20., 20)\n",
    "        \n",
    "        xyzi = F.elu(self.xyzi_out1(x))\n",
    "        xyzi = self.xyzi_out2(xyzi)\n",
    "\n",
    "        xyz_mu   = torch.tanh(xyzi[:, :3])\n",
    "\n",
    "        i_mu     = F.softplus(xyzi[:, 3:])\n",
    "        xyzi_mu = torch.cat((xyz_mu, i_mu), dim=1)\n",
    "        \n",
    "        xyzis = F.elu(self.xyzis_out1(x))\n",
    "        xyzis = self.xyzis_out2(xyzis)\n",
    "        xyzi_sig = F.softplus(xyzis) + 0.01\n",
    "        \n",
    "        background = F.elu(self.bg_out1(x))\n",
    "        background = self.bg_out2(background)\n",
    "        background = F.softplus(background)\n",
    "        \n",
    "        return torch.cat([logit,xyzi_mu,xyzi_sig,background],1)\n",
    "            \n",
    "\n",
    "class UnetDecodeNoBn(nn.Module):\n",
    "    \"\"\"\n",
    "    Our DECODE network consists of a 3D U-net, and an output net module.\n",
    "    The network parameters can be accessed through model.network\n",
    "    \n",
    "    We also store the parameters of the intensity distribution here for easier access. (model.int_dist)\n",
    "    \n",
    "    The forward function returns a tensor batch_size x n_output_channel tensor to make it compatible with the monai.inferers.sliding_window_inference function.\n",
    "    \n",
    "    To get the final output dictionary one has to also apply the tensor_to_dict function.\n",
    "    \n",
    "    Args:\n",
    "        ch_in (int): number of input channels (i.e. n_rounds * n_colors)\n",
    "        depth (int): number of levels in the encoder/decoder path\n",
    "        inp_offset, inp_scale (float): Values used for normalizing the input. \n",
    "        order (string): determines the order of layers\n",
    "            in `SingleConv` module. e.g. 'ce' stands for Conv3d+ELU.\n",
    "            See `SingleConv` for more info\n",
    "            Before the input is given to the network is is normalized using these variables.\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        is_2D: whether the input is 1D in the z dimension\n",
    "        pred_z: setting to false will disable inference of the z position\n",
    "        p_offset (float):\n",
    "            bias of the probabilty channel. The negative value avoids very high rates at the start of the training which might cause memory issues.\n",
    "        int_conc, int_rate (float): parameters of the torch.distributions.gamma class.\n",
    "        int_loc (float): shift parameter. \n",
    "        p_offset: probability channel bias \n",
    "        n_p_ch: Number probability channels (number of genes)\n",
    "        n_bg_ch: Number background channels (number of channels or 1)\n",
    "        n_int_ch: Number intensity channels (number of channels)\n",
    "        chrom_map: whether the network using the chromatic abberation map as an additional input    \n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in=1, depth=3, inp_scale=1., inp_offset=0., order='ce', f_maps=64, \n",
    "                 is_2D=False, pred_z=True, p_offset=-5., int_conc=4., int_rate=1., int_loc=1., n_p_ch=1, n_bg_ch=1, n_int_ch=1, n_out_l=1, chrom_map=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.inp_scale = inp_scale\n",
    "        self.inp_offset = inp_offset\n",
    "        \n",
    "        self.chrom_map = chrom_map\n",
    "        if chrom_map:\n",
    "            ch_in = ch_in + 2\n",
    "        \n",
    "        self.ch_in = ch_in\n",
    "        self.is_2D = is_2D\n",
    "        self.pred_z = pred_z\n",
    "        self.n_p_ch = n_p_ch\n",
    "        self.n_bg_ch = n_bg_ch\n",
    "        self.n_int_ch = n_int_ch\n",
    "        \n",
    "        self.unet = UNet3D(ch_in, final_sigmoid=False, num_levels=depth, is_2D=is_2D,\n",
    "                           layer_order = order, f_maps=f_maps)\n",
    "        self.outnet = OutputNet(f_maps=f_maps, p_offset=p_offset, is_2D=is_2D, n_p_ch=n_p_ch, n_bg_ch=n_bg_ch, n_int_ch=n_int_ch, n_out_l=n_out_l)\n",
    "        \n",
    "        self.network = nn.ModuleList([self.unet, self.outnet])\n",
    "        self.int_dist = IntensityDist(int_conc, int_rate, int_loc)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.chrom_map:\n",
    "            # Don't scale chrom. map input\n",
    "            x[:,:-2] = (x[:,:-2]-self.inp_offset) / self.inp_scale\n",
    "        else:\n",
    "            x = (x-self.inp_offset) / self.inp_scale\n",
    "        \n",
    "        for net in self.network:\n",
    "            x = net(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "    def tensor_to_dict(self, x):\n",
    "        \n",
    "        logits = x[:, 0:self.n_p_ch]\n",
    "        xyzi_mu = x[:, self.n_p_ch:self.n_p_ch+3+self.n_int_ch]\n",
    "        xyzi_sig = x[:, self.n_p_ch+3+self.n_int_ch:self.n_p_ch+2*(3+self.n_int_ch)]\n",
    "        bg = x[:, self.n_p_ch+2*(3+self.n_int_ch):self.n_p_ch+2*(3+self.n_int_ch)+self.n_bg_ch]\n",
    "        \n",
    "        # Scale bg output\n",
    "        bg = bg * self.inp_scale #[None,:,None,None,None].to(bg.device)\n",
    "    \n",
    "        if not self.pred_z:\n",
    "        \n",
    "            xyzi_mu[:,3] *= 0\n",
    "            xyzi_sig[:,3] *= 0\n",
    "            xyzi_sig[:,3] += 1\n",
    "\n",
    "        ret_dict = {'logits': logits, \n",
    "                    'xyzi_mu': xyzi_mu, \n",
    "                    'xyzi_sigma': xyzi_sig, \n",
    "                    'background': bg}\n",
    "        \n",
    "        return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn([2,9,37,48,48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([3, 252, 7, 48, 48])\n",
      "xyzi_mu torch.Size([3, 25, 7, 48, 48])\n",
      "xyzi_sigma torch.Size([3, 25, 7, 48, 48])\n",
      "background torch.Size([3, 22, 7, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "model = UnetDecodeNoBn(order= 'ce', ch_in=22, f_maps=256, depth=2, is_2D=False, pred_z=False, n_p_ch=252, n_bg_ch=22, n_int_ch=22, n_out_l=1)\n",
    "output = model.tensor_to_dict(model(torch.randn([3,22,7,48,48])))\n",
    "# output = model.tensor_to_dict(model(torch.randn([7,16,1,48,48]), shuffle_ch=True))\n",
    "\n",
    "for k in output.keys():\n",
    "    print(k, output[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tensor_to_dict(model(torch.randn([3,22,7,48,48]).cuda()))['logits'].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fe9cf5890d0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((output['logits'])[0,0,0].detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(output, '../data/model_batch_output_class2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = OmegaConf.load('../config/experiment/msp300_n2.yaml')\n",
    "# model = hydra.utils.instantiate(cfg.model, inp_scale=float(5), inp_offset=float(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13432004"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20510916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted 25_ensembling.ipynb.\n",
      "Converted 25_gen_train.ipynb.\n",
      "Converted 26_testtime_rescale.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decode_fish_dev2",
   "language": "python",
   "name": "decode_fish_dev2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
