{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp engine.microscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microscope model\n",
    "\n",
    "> Definition of the classes and functions we use to generate recordings given network outputs or simulations\n",
    "\n",
    "ToDo: Might want to delete psf_noise functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from decode_fish.funcs.utils import *\n",
    "import torch.nn as nn\n",
    "from torch.jit import script\n",
    "from typing import Union, List\n",
    "import torch.nn.functional as F\n",
    "from decode_fish.engine.place_psfs import _place_psf, CudaPlaceROI\n",
    "# import elasticdeform.torch as etorch\n",
    "import kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of decode_fish.engine.place_psfs failed: Traceback (most recent call last):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 480, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "class Microscope(nn.Module):\n",
    "    \"\"\"\n",
    "    The Mircoscope module takes 5 vectors 'locations', 'x_os', 'y_os', 'z_os',\n",
    "    'ints_3d' and the outputshape and turns them into 3D data through the following steps:\n",
    "    1) Apply continuous shifts to the PSF according to x_os, y_os, z_os\n",
    "    2) Clamping the PSF (retaining only positive values)\n",
    "    3) Normalize the PSF (if set to do so)\n",
    "    4) Scales PSFs by intensities\n",
    "    6) Place point spread function according to locations\n",
    "    7) Multiply resulting image by scale\n",
    "\n",
    "    Args:\n",
    "        psf (torch.nn.Module): Parametric PSF\n",
    "        noise (torch.nn.Module): Camera noise model\n",
    "        scale(float): Constant for scaling \n",
    "        \n",
    "    Shape:\n",
    "        -Input: locations: Tuple(torch.Tensor)\n",
    "                x_os_val: (N_emitters,)\n",
    "                y_os_val: (N_emitters,)\n",
    "                z_os_val: (N_emitters,)\n",
    "                ints_val: (N_emitters,C)\n",
    "                output_shape: Shape Tuple(BS, C, H, W, D)\n",
    "\n",
    "        -Output: xsim: (BS, C, H, W, D)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, psf, noise, scale = 10000., norm='none', psf_noise=0, pos_noise_xy=0, pos_noise_z=0, slice_rec=False, ch_facs=None, ch_cols=None, col_shifts_enabled=False, col_shifts_yxds=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.psf = psf\n",
    "        self.psf_init_vol = psf.psf_volume.detach().to('cuda')\n",
    "        self.scale = scale\n",
    "        self.noise = noise\n",
    "        self.norm = norm\n",
    "        \n",
    "        self.col_shifts_enabled = col_shifts_enabled\n",
    "        if col_shifts_enabled:\n",
    "            self.col_shifts_yx = col_shifts_yxds[:2]\n",
    "            self.col_shift_ds = col_shifts_yxds[2]   \n",
    "        \n",
    "        self.theta = self.noise.theta_scale * self.noise.theta_par\n",
    "        \n",
    "        self.psf_noise = psf_noise\n",
    "        self.pos_noise_xy = pos_noise_xy\n",
    "        self.pos_noise_z = pos_noise_z\n",
    "\n",
    "        self.slice_rec = slice_rec\n",
    "        self.psf_z_size = self.psf.psf_volume.shape[-3]\n",
    "        self.ch_cols = ch_cols\n",
    "        \n",
    "        self.register_parameter(name='channel_shifts', param=torch.nn.Parameter(torch.zeros((int(self.noise.channels/self.psf.n_cols), 3))))\n",
    "        \n",
    "        if self.col_shifts_enabled:\n",
    "            xs = int(np.ceil(self.col_shifts_yx[0]/self.col_shift_ds))\n",
    "            ys = int(np.ceil(self.col_shifts_yx[1]/self.col_shift_ds))\n",
    "            self.register_parameter(name='color_shifts', param=torch.nn.Parameter(torch.zeros([self.psf.n_cols, ys, xs])))\n",
    "                \n",
    "        self.ch_scale = 1. if ch_facs is None else torch.tensor(ch_facs).cuda()\n",
    "        self.register_parameter(name='channel_facs', param=torch.nn.Parameter(torch.ones(int(self.noise.channels)).cuda()))\n",
    "            \n",
    "        self.register_parameter(name='theta_par', param=self.noise.theta_par)\n",
    "        self.register_parameter(name='psf_vol', param=self.psf.psf_volume)\n",
    "        \n",
    "    def get_ch_mult(self):\n",
    "        return (self.channel_facs * self.ch_scale)[None,:,None,None,None]\n",
    "        \n",
    "    def add_psf_noise(self, psf_stack):\n",
    "\n",
    "        '''Gaussian noise'''\n",
    "        noise = torch.distributions.Normal(loc=0, scale=self.psf_noise).sample(psf_stack.shape).to(psf_stack.device)\n",
    "        noise *= torch.sqrt(psf_stack)\n",
    "\n",
    "        return psf_stack + noise\n",
    "    \n",
    "        '''Individual elastic deformation for each PSF (to slow)'''\n",
    "#         psf_deformed = torch.cat([etorch.deform_grid(psf, torch.distributions.Normal(loc=0, scale=self.psf_noise).sample([3,3,3,3]).to(psf_stack.device), order=3)[None] \n",
    "#                                   for psf in psf_stack[:,0]])\n",
    "        '''Single deformation for all PSF in batch (kinda stupid)'''\n",
    "#         psf_deformed = etorch.deform_grid(psf_stack[:,0], torch.distributions.Normal(loc=0, scale=self.psf_noise).sample([3,3,3,3]).to(psf_stack.device), axis=(1,2,3),order=3)\n",
    "#         return psf_deformed[:,None]\n",
    "\n",
    "    def add_pos_noise(self, x_os, y_os, z_os):\n",
    "        \n",
    "        x_n = torch.distributions.Normal(loc=0, scale=self.pos_noise_xy).sample(x_os.shape).to(x_os.device).reshape(-1,4)\n",
    "        x_n -= x_n.mean(-1, keepdim=True)\n",
    "        x_os = x_os + x_n.reshape(-1)\n",
    "        y_n = torch.distributions.Normal(loc=0, scale=self.pos_noise_xy).sample(y_os.shape).to(y_os.device).reshape(-1,4)\n",
    "        y_n -= y_n.mean(-1, keepdim=True)\n",
    "        y_os = y_os + y_n.reshape(-1)\n",
    "        z_n = torch.distributions.Normal(loc=0, scale=self.pos_noise_z).sample(z_os.shape).to(z_os.device).reshape(-1,4)\n",
    "        z_n -= z_n.mean(-1, keepdim=True)\n",
    "        z_os = z_os + z_n.reshape(-1)\n",
    "        \n",
    "        return x_os, y_os, z_os\n",
    "\n",
    "    def get_single_ch_inputs(self, locations, x_os_val, y_os_val, z_os_val, i_val, output_shape=None, ycrop=None, xcrop=None):\n",
    "\n",
    "        ch_inds = i_val.nonzero(as_tuple=True)\n",
    "\n",
    "        if len(ch_inds[1]):\n",
    "            if ch_inds[1].max() > 0:\n",
    "\n",
    "                i_val = i_val[ch_inds]\n",
    "                c_inds = torch.tensor(self.ch_cols)[ch_inds[1]]\n",
    "\n",
    "                locations = [l[ch_inds[0]] for l in locations]\n",
    "                locations.insert(1,ch_inds[1])   \n",
    "\n",
    "                shifts = self.channel_shifts - self.channel_shifts.mean(0)[None]\n",
    "                multi_col_shifts = torch.zeros([self.noise.channels, 3]).to(shifts.device)\n",
    "\n",
    "                multi_col_shifts[torch.tensor(self.ch_cols)==0,:] = shifts\n",
    "                multi_col_shifts[torch.tensor(self.ch_cols)==1,:] = shifts\n",
    "\n",
    "                x_os_val = x_os_val[ch_inds[0]] + multi_col_shifts[ch_inds[1], 0] \n",
    "                y_os_val = y_os_val[ch_inds[0]] + multi_col_shifts[ch_inds[1], 1]\n",
    "                z_os_val = z_os_val[ch_inds[0]] + multi_col_shifts[ch_inds[1], 2]\n",
    "\n",
    "                if self.col_shifts_enabled and ycrop is not None:\n",
    "\n",
    "                    c_inds = torch.tensor(self.ch_cols)[ch_inds[1]]\n",
    "                    blurred_col_shift = kornia.filters.gaussian_blur2d(self.color_shifts[None],  (9,9), (3,3))[0]\n",
    "\n",
    "                    col_shifts = blurred_col_shift[:, torch.div(locations[2][ch_inds[0]] + ycrop.cuda()[locations[0]], self.col_shift_ds, rounding_mode='trunc'), \n",
    "                                                      torch.div(locations[3][ch_inds[0]] + xcrop.cuda()[locations[0]], self.col_shift_ds, rounding_mode='trunc')]\n",
    "\n",
    "                    x_os_val[c_inds==1] = x_os_val[c_inds==1] + col_shifts[0, c_inds==1]\n",
    "                    y_os_val[c_inds==1] = y_os_val[c_inds==1] + col_shifts[1, c_inds==1]\n",
    "\n",
    "        else:\n",
    "            locations.insert(1,locations[0]) \n",
    "\n",
    "        return locations, x_os_val, y_os_val, z_os_val, i_val, output_shape\n",
    "    \n",
    "    def forward(self, locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, ret_psfs=False, add_noise=False, add_pos_noise=False):\n",
    "        \n",
    "        if len(locations[0]):\n",
    "            c_inds=torch.tensor(self.ch_cols)[locations[1]] if self.ch_cols is not None else None\n",
    "\n",
    "            # Apply continuous shift\n",
    "            if self.slice_rec and self.psf_z_size > 1:\n",
    "                z_os_ch = torch.clamp(z_os_ch,-0.49999,0.49999) + 0.5 # transform to [0,1]\n",
    "                z_scaled = z_os_ch * (self.psf_z_size - 2) # [0, z_size]\n",
    "                z_inds = (torch.div(z_scaled, 1, rounding_mode='trunc')).type(torch.cuda.LongTensor) + 1\n",
    "                z_os = -(z_scaled%1.) + 0.5\n",
    "\n",
    "                if self.pos_noise_xy and add_pos_noise: \n",
    "                    x_os_ch, y_os_ch, z_os = self.add_pos_noise(x_os_ch, y_os_ch, z_os)\n",
    "\n",
    "                psf = self.psf(x_os_ch, y_os_ch, z_os, z_inds, c_inds=c_inds)\n",
    "#                 psf = psf[torch.arange(len(z_os_ch)),:,z_inds][:,:,None]\n",
    "            else:\n",
    "                if self.pos_noise_xy and add_noise: \n",
    "                    x_os_ch, y_os_ch, z_os_ch = self.add_pos_noise(x_os_ch, y_os_ch, z_os_ch)\n",
    "                    \n",
    "                psf = self.psf(x_os_ch, y_os_ch, z_os_ch, c_inds=c_inds)\n",
    "                z_inds = None\n",
    "\n",
    "            if self.norm != 'none':\n",
    "                psf = torch.abs(psf)\n",
    "                psf = 4.5*psf/psf.flatten(-2,-1).sum(-1)[...,None,None]\n",
    "            else:\n",
    "                torch.clamp_min_(psf,0)\n",
    "                psf /= self.psf.psf_fac\n",
    "        \n",
    "            if self.psf_noise and add_noise: \n",
    "                psf = self.add_psf_noise(psf)\n",
    "\n",
    "            tot_intensity = torch.clamp_min(i_val, 0)  \n",
    "    \n",
    "            psf = psf * tot_intensity[:,None,None,None,None]\n",
    "            \n",
    "            if ret_psfs:\n",
    "                return self.scale * psf\n",
    "            \n",
    "            # place psf according to locations\n",
    "            xsim = place_psf(locations, psf, output_shape)\n",
    "            \n",
    "            # scale (not learnable)\n",
    "            xsim = self.scale * xsim\n",
    "            \n",
    "            return xsim\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return torch.zeros(output_shape).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def place_psf(locations, psf_volume, output_shape):\n",
    "    \"\"\"\n",
    "    Places point spread functions (psf_volume) in to corresponding locations.\n",
    "\n",
    "    Args:\n",
    "        locations: tuple with the 5D voxel coordinates\n",
    "        psf_volume: torch.Tensor\n",
    "        output_shape: Shape Tuple(BS, C, H, W, D) \n",
    "\n",
    "    Returns:\n",
    "        placed_psf: torch.Tensor with shape (BS, C, H, W, D)\n",
    "    \"\"\"\n",
    "\n",
    "    b, c, z, y, x = locations\n",
    "    # Deprecated python loop\n",
    "#     placed_psf = _place_psf(psf_volume, b, c, z, y, x, torch.tensor(output_shape))\n",
    "    \n",
    "    # New fancy cuda loop\n",
    "    N_psfs, _, psf_s_z, psf_s_y, psf_s_x = psf_volume.shape   \n",
    "    placed_psf = CudaPlaceROI.apply(psf_volume[:,0], output_shape[0], output_shape[1], output_shape[2], output_shape[3], output_shape[4], N_psfs, psf_s_z, psf_s_y, psf_s_x, b, c, z-psf_s_z//2, y-psf_s_y//2, x-psf_s_x//2)\n",
    "    \n",
    "    assert placed_psf.shape == output_shape\n",
    "    return placed_psf\n",
    "\n",
    "def extract_psf_roi(locations, x_vol, roi_shape):\n",
    "    \"\"\"\n",
    "    Extract ROIs from a given volume\n",
    "    \"\"\"\n",
    "    \n",
    "    batch, ch, z, y, x = locations \n",
    "    rois = _extract_psf_roi(x_vol, batch, ch, z, y, x, roi_shape)\n",
    "    \n",
    "    return rois\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "def get_roi_filt_inds(batch, ch, z, y, x, psf_shape, vol_shape, min_dist=None, slice_rec=False):\n",
    "    \"\"\"\n",
    "    Filter locations that are used for gen. model training.\n",
    "    Returns remaining indices.\n",
    "    \"\"\"\n",
    "    \n",
    "    inds = torch.arange(len(x))\n",
    "    \n",
    "    if min_dist:\n",
    "        # scale z if slice_rec ?? \n",
    "        bczyx = np.stack([cpu(batch)*1000,cpu(ch)*1000,cpu(z),cpu(y),cpu(x)]).T\n",
    "        tree = KDTree(bczyx)\n",
    "        pairs = tree.query_pairs(r=min_dist, output_type='ndarray')\n",
    "        pair_inds = np.unique(pairs.reshape(-1))\n",
    "        \n",
    "    psf_d, psf_h, psf_w = psf_shape[-3:]\n",
    "    vol_d, vol_h, vol_w = vol_shape[-3:]\n",
    "    # Filter locs at the edges\n",
    "    cond = (x > psf_w//2) & (x < vol_w - psf_w//2)\n",
    "    cond*= (y > psf_h//2) & (y < vol_h - psf_h//2)\n",
    "    if not slice_rec:\n",
    "        cond*= (z > psf_d//2) & (z < vol_d - psf_d)   \n",
    "        \n",
    "    if min_dist:\n",
    "        return np.setdiff1d(inds[cond], pair_inds, assume_unique=True)\n",
    "    else:\n",
    "        return inds[cond]\n",
    "    \n",
    "def mic_inp_apply_inds(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, inds):\n",
    "    \n",
    "    locations = [l[inds] for l in locations]\n",
    "    return locations, x_os_ch[inds], y_os_ch[inds], z_os_ch[inds], i_val[inds], output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@script\n",
    "def _extract_psf_roi(x_vol, batch, ch, z, y, x, roi_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract rois. We assume that border conditions are dealt with already. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    psf_b, psf_ch, psf_d, psf_h, psf_w = roi_shape[0], roi_shape[1], roi_shape[2], roi_shape[3], roi_shape[4]\n",
    "    roi_vol = torch.empty(psf_b, psf_ch, psf_d, psf_h, psf_w).to(x_vol.device)    \n",
    "    pad_zyx = [torch.div(psf_d, 2, rounding_mode='trunc'), torch.div(psf_h, 2, rounding_mode='trunc'), torch.div(psf_w, 2, rounding_mode='trunc')]\n",
    "    \n",
    "    z_l = z - pad_zyx[0]\n",
    "    y_l = y - pad_zyx[1]\n",
    "    x_l = x - pad_zyx[2]\n",
    "    \n",
    "    z_h = z + pad_zyx[0] + 1\n",
    "    y_h = y + pad_zyx[1] + 1\n",
    "    x_h = x + pad_zyx[2] + 1\n",
    "    \n",
    "    for idx in range(x.shape[0]):\n",
    "\n",
    "        roi_vol[idx] = x_vol[batch[idx], ch[idx],\n",
    "                         z_l[idx] : z_h[idx],\n",
    "                         y_l[idx] : y_h[idx],\n",
    "                         x_l[idx] : x_h[idx]]\n",
    "        \n",
    "    return roi_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.engine.psf import LinearInterpolatedPSF\n",
    "from decode_fish.engine.noise import sCMOS\n",
    "from decode_fish.engine.point_process import PointProcessUniform\n",
    "from decode_fish.funcs.file_io import get_gaussian_psf\n",
    "from decode_fish.funcs.file_io import get_vol_psf\n",
    "from decode_fish.funcs.output_trafo import sample_to_df\n",
    "\n",
    "# psf = get_gaussian_psf([3,13,13],[.1,1.7,1.7], pred_z=True, n_cols=2).cuda()\n",
    "psf = get_vol_psf('../figures/MF_psf2n.tif', n_cols=2, fac=1.)\n",
    "\n",
    "noise = sCMOS(channels=22)\n",
    "\n",
    "# micro = Microscope(psf=psf, noise=noise, scale=100, norm='sum', sum_fac=psf.psf_volume.sum().item()).cuda()\n",
    "micro = Microscope(psf=psf, noise=noise, scale=100, norm='none',  psf_noise=0.0, pos_noise_xy=0.7, pos_noise_z=0.3, slice_rec=True).cuda()\n",
    "micro.ch_cols = [0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = OmegaConf.load('../config/experiment/MERFISH_mop_4a.yaml')\n",
    "# from decode_fish.funcs.file_io import load_psf_noise_micro\n",
    "# psf, noise, micro = load_psf_noise_micro(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_shifts True\n",
      "channel_facs True\n",
      "theta_par True\n",
      "psf_vol True\n"
     ]
    }
   ],
   "source": [
    "for name, p in micro.named_parameters():\n",
    "    print(name, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.funcs.exp_specific import *\n",
    "codebook, targets = get_mop_codebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_process = PointProcessUniform(local_rate = torch.ones([3,7,48,48]).cuda()*.01, int_conc=3, int_rate=1, int_loc=1, sim_iters=5, channels=22, n_bits=4, sim_z=True, codebook=torch.tensor(codebook, dtype=torch.bool), int_option=2)\n",
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, codes = point_process.sample(from_code_book=True)\n",
    "# locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape = micro.get_single_ch_inputs(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, torch.tensor([50,200,1500]),torch.tensor([50,200,1500]))\n",
    "# df = sample_to_df(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, codes, px_size_zyx=[1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_ch_inputs(self, locations, x_os_val, y_os_val, z_os_val, i_val, output_shape=None, ycrop=None, xcrop=None):\n",
    "\n",
    "    ch_inds = i_val.nonzero(as_tuple=True)\n",
    "    \n",
    "    print(ch_inds)\n",
    "\n",
    "    if len(ch_inds[1]):\n",
    "        if ch_inds[1].max() > 0:\n",
    "\n",
    "            i_val = i_val[ch_inds]\n",
    "            c_inds = torch.tensor(self.ch_cols)[ch_inds[1]]\n",
    "\n",
    "            locations = [l[ch_inds[0]] for l in locations]\n",
    "            locations.insert(1,ch_inds[1])   \n",
    "\n",
    "            shifts = self.channel_shifts - self.channel_shifts.mean(0)[None]\n",
    "            multi_col_shifts = torch.zeros([self.noise.channels, 3]).to(shifts.device)\n",
    "\n",
    "            multi_col_shifts[torch.tensor(self.ch_cols)==0,:] = shifts\n",
    "            multi_col_shifts[torch.tensor(self.ch_cols)==1,:] = shifts\n",
    "\n",
    "            x_os_val = x_os_val[ch_inds[0]] + multi_col_shifts[ch_inds[1], 0] \n",
    "            y_os_val = y_os_val[ch_inds[0]] + multi_col_shifts[ch_inds[1], 1]\n",
    "            z_os_val = z_os_val[ch_inds[0]] + multi_col_shifts[ch_inds[1], 2]\n",
    "\n",
    "            if self.col_shifts_enabled and ycrop is not None:\n",
    "\n",
    "                c_inds = torch.tensor(self.ch_cols)[ch_inds[1]]\n",
    "                blurred_col_shift = kornia.filters.gaussian_blur2d(self.color_shifts[None],  (9,9), (3,3))[0]\n",
    "\n",
    "                col_shifts = blurred_col_shift[:, torch.div(locations[2][ch_inds[0]] + ycrop.cuda()[locations[0]], self.col_shift_ds, rounding_mode='trunc'), \n",
    "                                                  torch.div(locations[3][ch_inds[0]] + xcrop.cuda()[locations[0]], self.col_shift_ds, rounding_mode='trunc')]\n",
    "\n",
    "                x_os_val[c_inds==1] = x_os_val[c_inds==1] + col_shifts[0, c_inds==1]\n",
    "                y_os_val[c_inds==1] = y_os_val[c_inds==1] + col_shifts[1, c_inds==1]\n",
    "\n",
    "    else:\n",
    "        locations.insert(1,locations[0]) \n",
    "\n",
    "    return locations, x_os_val, y_os_val, z_os_val, i_val, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([  0,   0,   0,  ..., 475, 475, 475], device='cuda:0'), tensor([11, 17, 20,  ..., 16, 19, 20], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape = get_single_ch_inputs(micro, locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, torch.tensor([50,200,1500]),torch.tensor([50,200,1500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1904, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ints_3d.nonzero().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psfs = micro(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, add_noise=False, ret_psfs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsim = micro(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, add_noise=True, add_pos_noise=False)\n",
    "xsim.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsim2 = micro(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, add_noise=True, add_pos_noise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsim2.max()/xsim.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsim.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_inds = get_roi_filt_inds(*locations, micro.psf.psf_volume.shape, xsim.shape, slice_rec=True, min_dist=10)\n",
    "ch_out_inp = mic_inp_apply_inds(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, filt_inds)\n",
    "rois = extract_psf_roi(ch_out_inp[0], xsim, torch.tensor(psfs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# rois = extract_psf_roi(ch_out_inp[0], xsim, torch.tensor(psfs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.funcs.plotting import *\n",
    "_ = plot_channels((xsim-xsim2)[0],2, proj_func=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.funcs.plotting import *\n",
    "_ = plot_channels((xsim-xsim2)[0],2, proj_func=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cpu(torch.sqrt(torch.distributions.Normal(loc=0, scale=0.3).sample([1000])**2 +\n",
    "torch.distributions.Normal(loc=0, scale=0.3).sample([1000])**2 +\n",
    "torch.distributions.Normal(loc=0, scale=0.3).sample([1000])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xsim-xsim2).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check that 2D Z reconstruction is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_rate = torch.zeros([100,7,11,11]).cuda()\n",
    "local_rate[:,0,5,5] = 1.\n",
    "\n",
    "point_process = PointProcessUniform(local_rate =local_rate, int_conc=3, int_rate=1, sim_iters=1, int_loc=1, channels=22, n_bits=4, codebook=torch.tensor(code_ref)[:1], sim_z=True)\n",
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, codes = point_process.sample(from_code_book=True)\n",
    "df = sample_to_df(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, codes, px_size_zyx=[1,1,1])\n",
    "\n",
    "x_os_3d *= 0 \n",
    "y_os_3d *= 0 \n",
    "ints_3d *= 0 \n",
    "ints_3d += 1\n",
    "z_os_3d = torch.linspace(-0.7,0.7,100).cuda()\n",
    "\n",
    "ch_inp = micro.get_single_ch_inputs(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape)\n",
    "\n",
    "psf_s = micro(*ch_inp, add_noise=False, ret_psfs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cpu(psf_s)[::22,0,0,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_micro_inp(res_dict, code_ref, p_si=None, n_bits=4, channels=16):\n",
    "\n",
    "    res_dict['Samples_si'] = torch.where(torch.sigmoid(res_dict['logits']) > 0.0091, 1, 0)\n",
    "    # remove dump inds. Wont get reconstructed. \n",
    "    locations = res_dict['Samples_si'][:,:-1].nonzero(as_tuple=True)\n",
    "\n",
    "    xyzi_ix = [locations[0],locations[2],locations[3], locations[4]]\n",
    "    x_os_3d = res_dict['xyzi_mu'][:,0][xyzi_ix]\n",
    "    y_os_3d = res_dict['xyzi_mu'][:,1][xyzi_ix]\n",
    "    z_os_3d = res_dict['xyzi_mu'][:,2][xyzi_ix]\n",
    "    ints_3d = res_dict['xyzi_mu'][:,3][xyzi_ix]\n",
    "    # output_shape  = res_dict['Samples_si'].shape\n",
    "    ints_3d = ints_3d/n_bits+1\n",
    "\n",
    "    ints_ret = ints_3d[:,None].repeat_interleave(channels, 1)\n",
    "#     ch_bin = torch.zeros(ints_ret.shape).to(ints_ret.device)\n",
    "#     ch_bin.scatter_(index=torch.tensor(code_inds).to(ints_ret.device)[locations[1]], dim=1, value=1)\n",
    "    ch_bin = torch.tensor(code_ref)[locations[1]]\n",
    "    ints_ret = ints_ret*ch_bin.to(ints_ret.device)\n",
    "\n",
    "    output_shape  = res_dict['Samples_si'].shape\n",
    "    output_shape  = torch.Size([output_shape[0],channels,output_shape[2],output_shape[3],output_shape[4]])\n",
    "\n",
    "    return xyzi_ix, x_os_3d, y_os_3d, z_os_3d, ints_ret, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape = get_micro_inp(res_dict, torch.tensor(code_ref), p_si=None, n_bits = 4, channels=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of decode_fish.engine.place_psfs failed: Traceback (most recent call last):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 480, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 20_MERFISH_visualization.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decode_fish_dev2",
   "language": "python",
   "name": "decode_fish_dev2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
