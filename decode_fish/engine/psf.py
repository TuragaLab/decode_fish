# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_psf.ipynb (unless otherwise specified).

__all__ = ['LinearInterpolatedPSF', 'crop_psf', 'generate_perlin_noise_3d_torch', 'generate_fractal_noise_3d_torch']

# Cell
from ..imports import *
import torch.nn as nn
from torch.jit import script
import torch.nn.functional as F
from ..funcs.utils import *
from ..funcs.plotting import *

# Cell
class LinearInterpolatedPSF(nn.Module):
    """ Stores a PSF volume parameter and enables linear subpixel interpolation

    Args:
        size_zyx: size of the psf volume in pixels
        device: 'cuda' or 'cpu'

    ToDo:
        Eventually remove unneeded losses.
    """

    def __init__(self, size_zyx=[21,21,21], n_cols=1, device='cuda'):
        super().__init__()

        self.psf_size = list(np.array(size_zyx).astype('int'))
        self.n_cols = n_cols
        # +- /sz so that the values correspond to the pixel centers
        v = [torch.linspace(-1+1/sz, 1-1/sz, int(sz)) for sz in self.psf_size]

        # Buffers are not optimized
        self.register_buffer('x', v[2])
        self.register_buffer('y', v[1])
        self.register_buffer('z', v[0])
        self.register_buffer('z_2d', torch.zeros(1))
        self.device=device
        self.psf_volume = nn.Parameter(0.01*torch.rand(self.n_cols, *self.psf_size), requires_grad=True)
        self.forward_nonlin = torch.nn.Identity()

    def forward(self, x_offset_val, y_offset_val, z_offset_val, z_inds=None, c_inds=None):
        """ Returns the PSF volume for a number of given subpixel shift.

        Args:
            x_offset_val, y_offset_val, z_offset_val: Vector of shifts in x,y,z

        Returns:
            PSF volumes shifted by x,y,z
        """

        N_em = x_offset_val.shape[0]
        # Scale offsets by size. Factor of two because range [-1,1]
        x_offset = 2 * x_offset_val.view(-1) / self.psf_size[2]
        y_offset = 2 * y_offset_val.view(-1) / self.psf_size[1]
        if z_inds is None:
            z_offset = 2 * z_offset_val.view(-1) / self.psf_size[0]
            z_g = self.z.to(self.device)
            vol = self.forward_nonlin(self.psf_volume).expand(N_em, -1, -1, -1, -1).to(self.device)
        else:
            z_offset = z_offset = 2 * z_offset_val.view(-1) / 3
            z_g = self.z_2d.to(self.device)

            vol = torch.cat([self.psf_volume[None,:,[z-1 for z in z_inds]],
                             self.psf_volume[None,:,z_inds],
                             self.psf_volume[None,:,[z+1 for z in z_inds]]], dim=0).transpose(0,2).to(self.device)

        if c_inds is not None:
            vol = vol[torch.arange(len(c_inds)),c_inds]
            vol = vol[:,None]

        i_img, x_grid, y_grid, z_grid = torch.meshgrid(torch.arange(N_em, dtype=torch.float32).to(self.device), self.x.to(self.device), self.y.to(self.device), z_g)

        x_grid = x_grid - x_offset[:, None, None, None]
        y_grid = y_grid - y_offset[:, None, None, None]
        z_grid = z_grid - z_offset[:, None, None, None]

        m_grid = torch.stack([x_grid, y_grid, z_grid], -1)
        psf_out = torch.nn.functional.grid_sample(vol, m_grid, align_corners = False)

        return psf_out.transpose(-3,-1)

    def get_com(self):
        """ Returns the center of mass of the squared volume."""

        x_grid, y_grid, z_grid = torch.meshgrid(torch.arange(self.psf_size[0]),torch.arange(self.psf_size[1]),torch.arange(self.psf_size[2]))
        m_grid = torch.stack([x_grid, y_grid, z_grid], -1).to(self.device)

        vol = (self.forward_nonlin(self.psf_volume[0])**2).to(self.device)

        zc = (m_grid[:,:,:,0] * vol).sum()/vol.sum()
        yc = (m_grid[:,:,:,1] * vol).sum()/vol.sum()
        xc = (m_grid[:,:,:,2] * vol).sum()/vol.sum()

        return zc, yc, xc

    def com_loss(self):
        """ Returns the difference between the current CoM and the center of the volume.

        Used as a loss term during AE training to avoid drift of the PSF.
        """

        return torch.norm(torch.stack(self.get_com()) - torch.tensor(self.psf_size).to(self.device)//2, 2)

    def clip_loss(self):
        """ Returns the 2 norm of negative values of the PSF volume. """
        return torch.norm(torch.nn.ReLU().forward(-self.psf_volume).sum(), 2)

    def sum_loss(self):
        """ Returns the 1 norm of the PSF volume. """
        return torch.norm(self.forward_nonlin(self.psf_volume).sum(), 1)

    def l1_diff_norm(self, init_vol):
        """ Returns the 1 norm of the difference to the initial volume. """
        return torch.linalg.norm((self.psf_volume - init_vol).reshape(-1), 1)

# Cell
def crop_psf(psf, extent_zyx):
    """Returns a cropped version of a PSF"""
    cropped_vol = center_crop(psf.psf_volume, extent_zyx)
    cropped_psf = LinearInterpolatedPSF(extent_zyx)
    cropped_psf.load_state_dict({'psf_volume':cropped_vol}, strict=False)
    return cropped_psf

# Cell
def generate_perlin_noise_3d_torch(shape, res, device='cpu'):
    ''' Adopted from https://pvigier.github.io/2018/11/02/3d-perlin-noise-numpy.html '''
    def f(t):
        return 6*t**5 - 15*t**4 + 10*t**3

    delta = (res[0] / shape[0], res[1] / shape[1], res[2] / shape[2])
    d = (shape[0] // res[0], shape[1] // res[1], shape[2] // res[2])

    grid = torch.stack(torch.meshgrid(torch.arange(0, res[0], delta[0], device=device),
                                      torch.arange(0, res[1], delta[1], device=device),
                                      torch.arange(0, res[2], delta[2], device=device)), dim = -1) % 1

    theta = 2*np.pi*torch.rand(res[0]+1, res[1]+1, res[2]+1).to(device)
    phi = 2*np.pi*torch.rand(res[0]+1, res[1]+1, res[2]+1).to(device)

    gradients = torch.stack((torch.sin(phi)*torch.cos(theta), torch.sin(phi)*torch.sin(theta), torch.cos(phi)), axis=3)
    gradients[-1] = gradients[0]

    g000 = gradients[0:-1,0:-1,0:-1].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)
    g100 = gradients[1:  ,0:-1,0:-1].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)
    g010 = gradients[0:-1,1:  ,0:-1].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)
    g110 = gradients[1:  ,1:  ,0:-1].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)
    g001 = gradients[0:-1,0:-1,1:  ].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)
    g101 = gradients[1:  ,0:-1,1:  ].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)
    g011 = gradients[0:-1,1:  ,1:  ].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)
    g111 = gradients[1:  ,1:  ,1:  ].repeat_interleave(d[0], 0).repeat_interleave(d[1], 1).repeat_interleave(d[2], 2)
#     # Ramps
    n000 = torch.sum(torch.stack((grid[:,:,:,0]  , grid[:,:,:,1]  , grid[:,:,:,2]  ), axis=3) * g000, 3)
    n100 = torch.sum(torch.stack((grid[:,:,:,0]-1, grid[:,:,:,1]  , grid[:,:,:,2]  ), axis=3) * g100, 3)
    n010 = torch.sum(torch.stack((grid[:,:,:,0]  , grid[:,:,:,1]-1, grid[:,:,:,2]  ), axis=3) * g010, 3)
    n110 = torch.sum(torch.stack((grid[:,:,:,0]-1, grid[:,:,:,1]-1, grid[:,:,:,2]  ), axis=3) * g110, 3)
    n001 = torch.sum(torch.stack((grid[:,:,:,0]  , grid[:,:,:,1]  , grid[:,:,:,2]-1), axis=3) * g001, 3)
    n101 = torch.sum(torch.stack((grid[:,:,:,0]-1, grid[:,:,:,1]  , grid[:,:,:,2]-1), axis=3) * g101, 3)
    n011 = torch.sum(torch.stack((grid[:,:,:,0]  , grid[:,:,:,1]-1, grid[:,:,:,2]-1), axis=3) * g011, 3)
    n111 = torch.sum(torch.stack((grid[:,:,:,0]-1, grid[:,:,:,1]-1, grid[:,:,:,2]-1), axis=3) * g111, 3)
#     # Interpolation
    t = f(grid)
    n00 = n000*(1-t[:,:,:,0]) + t[:,:,:,0]*n100
    n10 = n010*(1-t[:,:,:,0]) + t[:,:,:,0]*n110
    n01 = n001*(1-t[:,:,:,0]) + t[:,:,:,0]*n101
    n11 = n011*(1-t[:,:,:,0]) + t[:,:,:,0]*n111
    n0 = (1-t[:,:,:,1])*n00 + t[:,:,:,1]*n10
    n1 = (1-t[:,:,:,1])*n01 + t[:,:,:,1]*n11
    return ((1-t[:,:,:,2])*n0 + t[:,:,:,2]*n1)

def generate_fractal_noise_3d_torch(shape, res, octaves=1, persistence=0.5, device='cpu'):
    noise = torch.zeros(shape, device=device)
    frequency = 1
    amplitude = 1
    for _ in range(octaves):
        noise += amplitude * generate_perlin_noise_3d_torch(shape, (frequency*res[0], frequency*res[1], frequency*res[2]), device=device)
        frequency *= 2
        amplitude *= persistence
    return noise