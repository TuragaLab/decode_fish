{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp engine.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECODE Network\n",
    "\n",
    "> Definition of the classes and modules we use to build our DECODE network\n",
    "\n",
    "ToDo: Lots of bloat. Different normalizations aren't needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "import torch.nn as nn\n",
    "import types\n",
    "from functools import partial\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def number_of_features_per_level(init_channel_number, num_levels):\n",
    "    return [init_channel_number * 2 ** k for k in range(num_levels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding):\n",
    "    \"\"\"\n",
    "    Create a list of modules with together constitute a single conv layer with non-linearity\n",
    "    and optional batchnorm/groupnorm.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size(int or tuple): size of the convolving kernel\n",
    "        order (string): order of things, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'gcr' -> groupnorm + conv + ReLU\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "            'bcr' -> batchnorm + conv + ReLU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    Return:\n",
    "        list of tuple (name, module)\n",
    "    \"\"\"\n",
    "    assert 'c' in order, \"Conv layer MUST be present\"\n",
    "    assert order[0] not in 'rle', 'Non-linearity cannot be the first operation in the layer'\n",
    "\n",
    "    modules = []\n",
    "    for i, char in enumerate(order):\n",
    "        if char == 'r':\n",
    "            modules.append(('ReLU', nn.ReLU(inplace=True)))\n",
    "        elif char == 'l':\n",
    "            modules.append(('LeakyReLU', nn.LeakyReLU(negative_slope=0.1, inplace=True)))\n",
    "        elif char == 'e':\n",
    "            modules.append(('ELU', nn.ELU(inplace=True)))\n",
    "        elif char == 'c':\n",
    "            # add learnable bias only in the absence of batchnorm/groupnorm\n",
    "            bias = not ('g' in order or 'b' in order)\n",
    "            modules.append(('conv', nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding, bias=bias, padding_mode='replicate')))\n",
    "        elif char == 'g':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                num_channels = in_channels\n",
    "            else:\n",
    "                num_channels = out_channels\n",
    "\n",
    "            # use only one group if the given number of groups is greater than the number of channels\n",
    "            if num_channels < num_groups:\n",
    "                num_groups = 1\n",
    "\n",
    "            assert num_channels % num_groups == 0, f'Expected number of channels in input to be divisible by num_groups. num_channels={num_channels}, num_groups={num_groups}'\n",
    "            modules.append(('groupnorm', nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)))\n",
    "        elif char == 'b':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(in_channels)))\n",
    "            else:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(out_channels)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported layer type '{char}'. MUST be one of ['b', 'g', 'r', 'l', 'e', 'c']\")\n",
    "\n",
    "    return modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SingleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Basic convolutional module consisting of a Conv3d, non-linearity and optional batchnorm/groupnorm. The order\n",
    "    of operations can be specified via the `order` parameter\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple):\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
    "        super(SingleConv, self).__init__()\n",
    "\n",
    "        for name, module in create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding=padding):\n",
    "            self.add_module(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DoubleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A module consisting of two consecutive convolution layers (e.g. BatchNorm3d+ReLU+Conv3d).\n",
    "    We use (Conv3d+ReLU+GroupNorm3d) by default.\n",
    "    This can be changed however by providing the 'order' argument, e.g. in order\n",
    "    to change to Conv3d+BatchNorm3d+ELU use order='cbe'.\n",
    "    Use padded convolutions to make sure that the output (H_out, W_out) is the same\n",
    "    as (H_in, W_in), so that you don't have to crop in the decoder path.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        encoder (bool): if True we're in the encoder path, otherwise we're in the decoder\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, encoder, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        if encoder:\n",
    "            # we're in the encoder path\n",
    "            conv1_in_channels = in_channels\n",
    "            conv1_out_channels = out_channels // 2\n",
    "            if conv1_out_channels < in_channels:\n",
    "                conv1_out_channels = in_channels\n",
    "            conv2_in_channels, conv2_out_channels = conv1_out_channels, out_channels\n",
    "        else:\n",
    "            # we're in the decoder path, decrease the number of channels in the 1st convolution\n",
    "            conv1_in_channels, conv1_out_channels = in_channels, out_channels\n",
    "            conv2_in_channels, conv2_out_channels = out_channels, out_channels\n",
    "\n",
    "        # conv1\n",
    "        self.add_module('SingleConv1',\n",
    "                        SingleConv(conv1_in_channels, conv1_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding))\n",
    "        # conv2\n",
    "        self.add_module('SingleConv2',\n",
    "                        SingleConv(conv2_in_channels, conv2_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Upsampling(nn.Module):\n",
    "    \"\"\"\n",
    "    Upsamples a given multi-channel 3D data using either interpolation or learned transposed convolution.\n",
    "    Args:\n",
    "        transposed_conv (bool): if True uses ConvTranspose3d for upsampling, otherwise uses interpolation\n",
    "        in_channels (int): number of input channels for transposed conv\n",
    "            used only if transposed_conv is True\n",
    "        out_channels (int): number of output channels for transpose conv\n",
    "            used only if transposed_conv is True\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "            used only if transposed_conv is True\n",
    "        scale_factor (int or tuple): stride of the convolution\n",
    "            used only if transposed_conv is True\n",
    "        mode (str): algorithm used for upsampling:\n",
    "            'nearest' | 'linear' | 'bilinear' | 'trilinear' | 'area'. Default: 'nearest'\n",
    "            used only if transposed_conv is False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transposed_conv, in_channels=None, out_channels=None, kernel_size=3,\n",
    "                 scale_factor=(2, 2, 2), mode='nearest'):\n",
    "        super(Upsampling, self).__init__()\n",
    "\n",
    "        if transposed_conv:\n",
    "            # make sure that the output size reverses the MaxPool3d from the corresponding encoder\n",
    "            # (D_out = (D_in − 1) ×  stride[0] − 2 ×  padding[0] +  kernel_size[0] +  output_padding[0])\n",
    "            self.upsample = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=kernel_size, stride=scale_factor,\n",
    "                                               padding=1)\n",
    "        else:\n",
    "            self.upsample = partial(self._interpolate, mode=mode)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        output_size = encoder_features.size()[2:]\n",
    "        return self.upsample(x, output_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def _interpolate(x, size, mode):\n",
    "        return F.interpolate(x, size=size, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module from the encoder path consisting of the optional max\n",
    "    pooling layer (one may specify the MaxPool kernel_size to be different\n",
    "    than the standard (2,2,2), e.g. if the volumetric data is anisotropic\n",
    "    (make sure to use complementary scale_factor in the decoder path) followed by\n",
    "    a DoubleConv module.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        apply_pooling (bool): if True use MaxPool3d before DoubleConv\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        pool_type (str): pooling layer: 'max' or 'avg'\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, apply_pooling=True,\n",
    "                 pool_kernel_size=2, pool_type='max', basic_module=DoubleConv, conv_layer_order='gcr',\n",
    "                 num_groups=8, padding=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        assert pool_type in ['max', 'avg']\n",
    "        if apply_pooling:\n",
    "            if pool_type == 'max':\n",
    "                self.pooling = nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
    "            else:\n",
    "                self.pooling = nn.AvgPool3d(kernel_size=pool_kernel_size)\n",
    "        else:\n",
    "            self.pooling = None\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=True,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.pooling is not None:\n",
    "            x = self.pooling(x)\n",
    "        x = self.basic_module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module for decoder path consisting of the upsampling layer\n",
    "    (either learned ConvTranspose3d or nearest neighbor interpolation) followed by a basic module (DoubleConv or ExtResNetBlock).\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        scale_factor (tuple): used as the multiplier for the image H/W/D in\n",
    "            case of nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation\n",
    "            from the corresponding encoder\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, scale_factor=(2, 2, 2), basic_module=DoubleConv,\n",
    "                 conv_layer_order='gcr', num_groups=8, mode='nearest', padding=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        if basic_module == DoubleConv:\n",
    "            # if DoubleConv is the basic_module use interpolation for upsampling and concatenation joining\n",
    "            self.upsampling = Upsampling(transposed_conv=False, in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=conv_kernel_size, scale_factor=scale_factor, mode=mode)\n",
    "            # concat joining\n",
    "            self.joining = partial(self._joining, concat=True)\n",
    "        else:\n",
    "            # if basic_module=ExtResNetBlock use transposed convolution upsampling and summation joining\n",
    "            self.upsampling = Upsampling(transposed_conv=True, in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=conv_kernel_size, scale_factor=scale_factor, mode=mode)\n",
    "            # sum joining\n",
    "            self.joining = partial(self._joining, concat=False)\n",
    "            # adapt the number of in_channels for the ExtResNetBlock\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=False,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        x = self.upsampling(encoder_features=encoder_features, x=x)\n",
    "        x = self.joining(encoder_features, x)\n",
    "        x = self.basic_module(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _joining(encoder_features, x, concat):\n",
    "        if concat:\n",
    "            return torch.cat((encoder_features, x), dim=1)\n",
    "        else:\n",
    "            return encoder_features + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Abstract3DUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for standard and residual UNet.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        final_sigmoid (bool): if True apply element-wise nn.Sigmoid after the\n",
    "            final 1x1 convolution, otherwise apply nn.Softmax. MUST be True if nn.BCELoss (two-class) is used\n",
    "            to train the model. MUST be False if nn.CrossEntropyLoss (multi-class) is used to train the model.\n",
    "        basic_module: basic model for the encoder/decoder (DoubleConv, ExtResNetBlock, ....)\n",
    "        layer_order (string): determines the order of layers\n",
    "            in `SingleConv` module. e.g. 'crg' stands for Conv3d+ReLU+GroupNorm3d.\n",
    "            See `SingleConv` for more info\n",
    "        f_maps (int, tuple): if int: number of feature maps in the first conv layer of the encoder (default: 64);\n",
    "            if tuple: number of feature maps at each level\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        num_levels (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
    "        is_segmentation (bool): if True (semantic segmentation problem) Sigmoid/Softmax normalization is applied\n",
    "            after the final convolution; if False (regression problem) the normalization layer is skipped at the end\n",
    "        testing (bool): if True (testing mode) the `final_activation` (if present, i.e. `is_segmentation=true`)\n",
    "            will be applied as the last operation during the forward pass; if False the model is in training mode\n",
    "            and the `final_activation` (even if present) won't be applied; default: False\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel in the basic_module\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        conv_padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, final_sigmoid, basic_module, f_maps=64, is_2D=False, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, testing=False,\n",
    "                 conv_kernel_size=3, pool_kernel_size=2, conv_padding=1, **kwargs):\n",
    "        super(Abstract3DUNet, self).__init__()\n",
    "\n",
    "        self.testing = testing\n",
    "        if is_2D:\n",
    "            conv_kernel_size = [1, conv_kernel_size, conv_kernel_size]\n",
    "            pool_kernel_size = [1, pool_kernel_size, pool_kernel_size]\n",
    "            conv_padding = [0, conv_padding, conv_padding]\n",
    "\n",
    "        if isinstance(f_maps, int):\n",
    "            f_maps = number_of_features_per_level(f_maps, num_levels=num_levels)\n",
    "\n",
    "        # create encoder path consisting of Encoder modules. Depth of the encoder is equal to `len(f_maps)`\n",
    "        encoders = []\n",
    "        for i, out_feature_num in enumerate(f_maps):\n",
    "            if i == 0:\n",
    "                encoder = Encoder(in_channels, out_feature_num,\n",
    "                                  apply_pooling=False,  # skip pooling in the firs encoder\n",
    "                                  basic_module=basic_module,\n",
    "                                  conv_layer_order=layer_order,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  num_groups=num_groups,\n",
    "                                  padding=conv_padding)\n",
    "            else:\n",
    "                # TODO: adapt for anisotropy in the data, i.e. use proper pooling kernel to make the data isotropic after 1-2 pooling operations\n",
    "                encoder = Encoder(f_maps[i - 1], out_feature_num,\n",
    "                                  basic_module=basic_module,\n",
    "                                  conv_layer_order=layer_order,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  num_groups=num_groups,\n",
    "                                  pool_kernel_size=pool_kernel_size,\n",
    "                                  padding=conv_padding)\n",
    "\n",
    "            encoders.append(encoder)\n",
    "\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "\n",
    "        # create decoder path consisting of the Decoder modules. The length of the decoder is equal to `len(f_maps) - 1`\n",
    "        decoders = []\n",
    "        reversed_f_maps = list(reversed(f_maps))\n",
    "        for i in range(len(reversed_f_maps) - 1):\n",
    "            if basic_module == DoubleConv:\n",
    "                in_feature_num = reversed_f_maps[i] + reversed_f_maps[i + 1]\n",
    "            else:\n",
    "                in_feature_num = reversed_f_maps[i]\n",
    "\n",
    "            out_feature_num = reversed_f_maps[i + 1]\n",
    "            # TODO: if non-standard pooling was used, make sure to use correct striding for transpose conv\n",
    "            # currently strides with a constant stride: (2, 2, 2)\n",
    "            decoder = Decoder(in_feature_num, out_feature_num,\n",
    "                              basic_module=basic_module,\n",
    "                              conv_layer_order=layer_order,\n",
    "                              conv_kernel_size=conv_kernel_size,\n",
    "                              num_groups=num_groups,\n",
    "                              padding=conv_padding)\n",
    "            decoders.append(decoder)\n",
    "\n",
    "        self.decoders = nn.ModuleList(decoders)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder part\n",
    "        encoders_features = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            # reverse the encoder outputs to be aligned with the decoder\n",
    "            encoders_features.insert(0, x)\n",
    "\n",
    "        # remove the last encoder's output from the list\n",
    "        # !!remember: it's the 1st in the list\n",
    "        encoders_features = encoders_features[1:]\n",
    "\n",
    "        # decoder part\n",
    "        for decoder, encoder_features in zip(self.decoders, encoders_features):\n",
    "            # pass the output from the corresponding encoder and the output\n",
    "            # of the previous decoder\n",
    "            x = decoder(encoder_features, x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UNet3D(Abstract3DUNet):\n",
    "    \"\"\"\n",
    "    3DUnet model from\n",
    "    `\"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation\"\n",
    "        <https://arxiv.org/pdf/1606.06650.pdf>`.\n",
    "    Uses `DoubleConv` as a basic_module and nearest neighbor upsampling in the decoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, final_sigmoid=True, f_maps=64, is_2D=False, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1,  **kwargs):\n",
    "        super(UNet3D, self).__init__(in_channels=in_channels, final_sigmoid=final_sigmoid,\n",
    "                                     basic_module=DoubleConv, f_maps=f_maps, is_2D=is_2D, layer_order=layer_order,\n",
    "                                     num_groups=num_groups, num_levels=num_levels, is_segmentation=is_segmentation,\n",
    "                                     conv_padding=conv_padding, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export  \n",
    "class OutputNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes the output maps from the U-net and processes them seperately, using two conv3D layers for each group (xyzi_mean, xyzi_sigma, probability, background)\n",
    "    Args:\n",
    "        f_maps: number of channels of the U-net output\n",
    "        p_offset: probability channel bias \n",
    "        is_2D: whether the input is 1D in the z dimension\n",
    "        n_p_ch: Number probability channels (number of genes + number of channels)\n",
    "        n_bg_ch: Number background channels (number of channels or 1)\n",
    "        n_int_ch: Number intensity channels (number of channels)\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, f_maps=64, p_offset=-5., is_2D=False, n_p_ch=1, n_bg_ch=1, n_int_ch=1.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.is_2D = is_2D\n",
    "        self.n_p_ch = n_p_ch\n",
    "        self.n_bg_ch = n_bg_ch\n",
    "        self.n_int_ch = n_int_ch\n",
    "        self.p_offset = p_offset\n",
    "        \n",
    "        xyzi_dim = 3 + n_int_ch\n",
    "        \n",
    "        kernel_size = [1,3,3] if is_2D else [3,3,3]\n",
    "        padding = [0,1,1] if is_2D else [1,1,1]\n",
    "        \n",
    "        \n",
    "        self.p_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.p_out2 = nn.Conv3d(f_maps, n_p_ch, kernel_size=1, padding=0)\n",
    "        nn.init.constant_(self.p_out2.bias,p_offset)\n",
    "        \n",
    "        self.xyzi_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.xyzi_out2 = nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.xyzis_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.xyzis_out2 = nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.bg_out1 = nn.Conv3d(f_maps + n_int_ch, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.bg_out2 = nn.Conv3d(f_maps, n_bg_ch, kernel_size=1, padding=0)\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.p_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.p_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.xyzi_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.xyzi_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.xyzis_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.xyzis_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.bg_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.bg_out2.weight, mode='fan_in', nonlinearity='linear')    \n",
    "        \n",
    "    def forward(self, u_net_out, resid_x):\n",
    "        \n",
    "        # Sigmoid is applied later\n",
    "        logit    = F.elu(self.p_out1(u_net_out))\n",
    "        logit    = self.p_out2(logit)\n",
    "        logit    = torch.clamp(logit, -20., 20)\n",
    "        \n",
    "        xyzi = F.elu(self.xyzi_out1(u_net_out))\n",
    "        xyzi = self.xyzi_out2(xyzi)\n",
    "        \n",
    "        # xyz [-1, 1]\n",
    "        xyz_mu   = torch.tanh(xyzi[:, :3])\n",
    "\n",
    "        # xyz [0, :]\n",
    "        i_mu     = F.softplus(xyzi[:, 3:])\n",
    "        xyzi_mu = torch.cat((xyz_mu, i_mu), dim=1)\n",
    "        \n",
    "        xyzis = F.elu(self.xyzis_out1(u_net_out))\n",
    "        xyzis = self.xyzis_out2(xyzis)\n",
    "        # sigmas [0.01, :]\n",
    "        xyzi_sig = F.softplus(xyzis) + 0.01\n",
    "        \n",
    "        # We use a residual connection from input to facilitate background prediction\n",
    "        bg_inp = torch.cat([u_net_out, resid_x], 1)\n",
    "        \n",
    "        background = F.elu(self.bg_out1(bg_inp))\n",
    "        background = self.bg_out2(background)\n",
    "        # sigmas [0., :]\n",
    "        background = F.softplus(background)\n",
    "        \n",
    "        return torch.cat([logit,xyzi_mu,xyzi_sig,background],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class UnetDecodeNoBn_2S(nn.Module):\n",
    "    \"\"\"\n",
    "    Our DECODE network consists of two 3D U-nets, and an output net module.\n",
    "    The first (small) network runs over each input channel seperately (shared parameters), the second combines information from all channels.\n",
    "    The network parameters can be accessed through model.network\n",
    "    \n",
    "    The forward function returns a tensor batch_size x n_output_channel tensor to make it compatible with the monai.inferers.sliding_window_inference function.\n",
    "    \n",
    "    To get the final output dictionary one has to also apply the tensor_to_dict function.\n",
    "    \n",
    "    Args:\n",
    "        ch_in (int): number of input channels (i.e. n_rounds * n_colors)\n",
    "        depth (int): number of levels in the encoder/decoder path of the second U-net\n",
    "        inp_offset, inp_scale (float): Values used for scaling the input. \n",
    "        order (string): determines the order of layers\n",
    "            in `SingleConv` module. e.g. 'ce' stands for Conv3d+ELU.\n",
    "            See `SingleConv` for more info\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        is_2D: whether the input is 1D in the z dimension (i.e. slice data)\n",
    "        pred_z: setting to false will disable inference of the z position\n",
    "        p_offset (float): bias of the probabilty channel. The negative value avoids very high rates at the start of the training which might cause memory issues.\n",
    "        n_p_ch: Number probability channels (number of genes + number of channels)\n",
    "        n_bg_ch: Number background channels (number of channels or 1)\n",
    "        n_int_ch: Number intensity channels (number of channels)\n",
    "        n_chrom_map_ch: number of colors of. If you dont want to use chromatic abberation map as an additional input set to 0   \n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in=1, depth=3, inp_scale=1., inp_offset=0., order='ce', f_maps=64, \n",
    "                 is_2D=False, pred_z=True, p_offset=-5., int_conc=4., int_rate=1., int_loc=1., n_p_ch=1, n_bg_ch=1, n_int_ch=1, n_chrom_map_ch=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.inp_scale = inp_scale\n",
    "        self.inp_offset = inp_offset\n",
    "        \n",
    "        self.n_chrom_map_ch = n_chrom_map_ch\n",
    "\n",
    "        self.n_ch = ch_in\n",
    "        self.is_2D = is_2D\n",
    "        self.pred_z = pred_z\n",
    "        self.n_p_ch = n_p_ch\n",
    "        self.n_bg_ch = n_bg_ch\n",
    "        self.n_int_ch = n_int_ch\n",
    "            \n",
    "        self.single_n_ch = 12\n",
    "        ch_in = self.n_ch * self.single_n_ch\n",
    "        ch_in = ch_in + self.n_chrom_map_ch\n",
    "\n",
    "        self.single_ch_unet = UNet3D(1, final_sigmoid=False, num_levels=1, is_2D=is_2D, layer_order = order, f_maps=self.single_n_ch)\n",
    "        self.unet = UNet3D(ch_in, final_sigmoid=False, num_levels=depth, is_2D=is_2D, layer_order = order, f_maps=f_maps)\n",
    "        self.outnet = OutputNet(f_maps=f_maps, p_offset=p_offset, is_2D=is_2D, n_p_ch=n_p_ch, n_bg_ch=n_bg_ch, n_int_ch=n_int_ch)  \n",
    "            \n",
    "        self.network = nn.ModuleList([self.single_ch_unet, self.unet, self.outnet])\n",
    "            \n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.n_chrom_map_ch:\n",
    "            # Don't scale chrom. map input\n",
    "            x[:,:-self.n_chrom_map_ch] = (x[:,:-self.n_chrom_map_ch]-self.inp_offset) / self.inp_scale\n",
    "        else:\n",
    "            x = (x-self.inp_offset) / self.inp_scale\n",
    "            \n",
    "        s_x = x[:,:-self.n_chrom_map_ch] if self.n_chrom_map_ch else x\n",
    "        single_ch_out = self.network[0](s_x.flatten(0,1)[:,None]).reshape(s_x.shape[0],-1,*s_x.shape[2:])\n",
    "        m_x = torch.cat([single_ch_out, x[:,-n_chrom_map_ch:]], 1) if self.n_chrom_map_ch else single_ch_out\n",
    "        unet_out = self.network[1](m_x)\n",
    "\n",
    "        res_x = x[:,:-n_chrom_map_ch] if self.n_chrom_map_ch else x\n",
    "        net_out = self.network[-1](unet_out, res_x)\n",
    "            \n",
    "        return net_out\n",
    "        \n",
    "    def tensor_to_dict(self, x):\n",
    "        \n",
    "        logits = x[:, 0:self.n_p_ch]\n",
    "        xyzi_mu = x[:, self.n_p_ch:self.n_p_ch+3+self.n_int_ch]\n",
    "        xyzi_sig = x[:, self.n_p_ch+3+self.n_int_ch:self.n_p_ch+2*(3+self.n_int_ch)]\n",
    "        bg = x[:, self.n_p_ch+2*(3+self.n_int_ch):self.n_p_ch+2*(3+self.n_int_ch)+self.n_bg_ch]\n",
    "        \n",
    "        # Scale bg output\n",
    "        bg = bg * self.inp_scale\n",
    "    \n",
    "        if not self.pred_z:\n",
    "            # If we don't want to predict z, set mu to 0 and sigma to 1\n",
    "            xyzi_mu[:,2] *= 0\n",
    "            xyzi_sig[:,2] *= 0\n",
    "            xyzi_sig[:,2] += 1\n",
    "\n",
    "        ret_dict = {'logits': logits, \n",
    "                    'xyzi_mu': xyzi_mu, \n",
    "                    'xyzi_sigma': xyzi_sig, \n",
    "                    'background': bg}\n",
    "        \n",
    "        return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn([2,9,1,48,48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([3, 274, 1, 48, 48])\n",
      "xyzi_mu torch.Size([3, 25, 1, 48, 48])\n",
      "xyzi_sigma torch.Size([3, 25, 1, 48, 48])\n",
      "background torch.Size([3, 22, 1, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "model = UnetDecodeNoBn_2S(order= 'ce', ch_in=22, f_maps=256, depth=2, is_2D=True, pred_z=False, n_p_ch=252 + 22, n_bg_ch=22, n_int_ch=22, n_chrom_map_ch=0)\n",
    "output = model.tensor_to_dict(model(torch.randn([3,22,1,48,48])))\n",
    "\n",
    "for k in output.keys():\n",
    "    print(k, output[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f054c4f21c0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((output['logits'])[0,0,0].detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.tensor_to_dict(model.cuda()(torch.randn([3,22,7,48,48]).cuda()))\n",
    "torch.save(output, '../data/model_batch_output_class5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7866738"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted 25_ensembling.ipynb.\n",
      "Converted 26_gen_train.ipynb.\n",
      "Converted 27_testtime_rescale.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decode_fish_dev2",
   "language": "python",
   "name": "decode_fish_dev2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
