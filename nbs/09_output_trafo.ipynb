{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.output_trafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations of sampled data and model output into emitter dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from decode_fish.funcs.utils import *\n",
    "import torch.nn.functional as F\n",
    "from decode_fish.funcs.plotting import *\n",
    "from decode_fish.funcs.emitter_io import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sample_to_df(locs, x_os, y_os, z_os, ints, codes, px_size_zyx=[100,100,100]):\n",
    "    \n",
    "    x = locs[-1] + x_os + 0.5 \n",
    "    y = locs[-2] + y_os + 0.5 \n",
    "    z = locs[-3] + z_os + 0.5 \n",
    "    \n",
    "    n_gt = len(x)\n",
    "    channels = ints.shape[1]\n",
    "    \n",
    "    frame_idx = locs[0]\n",
    "    \n",
    "    df = DF({'loc_idx': torch.arange(n_gt),\n",
    "             'frame_idx': frame_idx.cpu(),\n",
    "             'x': x.cpu()*px_size_zyx[2],\n",
    "             'y': y.cpu()*px_size_zyx[1], \n",
    "             'z': z.cpu()*px_size_zyx[0]}) \n",
    "    \n",
    "    for i in range(channels):\n",
    "        df[f'int_{i}'] = ints[:,i].cpu()\n",
    "        \n",
    "    df['code_inds'] = codes\n",
    "    df['ints'] = ints.sum(-1).cpu()\n",
    "\n",
    "    return df\n",
    "\n",
    "def df_to_micro(df, px_size_zyx=[100,100,100]):\n",
    "    \n",
    "    locs = tuple([torch.tensor(df['frame_idx'],dtype=torch.int64).cuda(),\n",
    "                 torch.zeros(len(df),dtype=torch.int64).cuda(),\n",
    "                 torch.tensor((df['z']/px_size_zyx[0] + 0.5),dtype=torch.int64).cuda(),\n",
    "                 torch.tensor((df['y']/px_size_zyx[1] + 0.5),dtype=torch.int64).cuda(),\n",
    "                 torch.tensor((df['x']/px_size_zyx[2] + 0.5),dtype=torch.int64).cuda()])\n",
    "    z = (torch.tensor(df['z'],dtype=torch.float32).cuda()-locs[2]*px_size_zyx[0])/px_size_zyx[0] - 0.5\n",
    "    y = (torch.tensor(df['y'],dtype=torch.float32).cuda()-locs[3]*px_size_zyx[1])/px_size_zyx[1] - 0.5\n",
    "    x = (torch.tensor(df['x'],dtype=torch.float32).cuda()-locs[4]*px_size_zyx[2])/px_size_zyx[2] - 0.5\n",
    "    ints = torch.tensor(df['int']).cuda()\n",
    "\n",
    "    return locs, x, y, z, ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13832\n"
     ]
    }
   ],
   "source": [
    "from decode_fish.funcs.merfish_eval import *\n",
    "bench_df, code_ref, targets = get_benchmark()\n",
    "code_inds = np.stack([np.nonzero(c)[0] for c in code_ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.engine.point_process import PointProcessUniform\n",
    "point_process = PointProcessUniform(local_rate = torch.ones([7,1,48,48]).cuda()*.3, int_conc=3, int_rate=1, int_loc=1, sim_iters=1, channels=16, n_bits=4, codebook=torch.tensor(code_ref, dtype=torch.bool), int_option=1)\n",
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, codes = point_process.sample(from_code_book=True, phasing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15667/712854192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSIPostProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1_threshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2_threshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamp_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpx_size_zyx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#export\n",
    "class SIPostProcess(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, m1_threshold:float = 0.03, m2_threshold:float = 0.3, samp_threshold=0.1, px_size_zyx=[100,100,100], diag=0):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.m1_threshold = m1_threshold\n",
    "        self.m2_threshold = m2_threshold\n",
    "        self.samp_threshold = samp_threshold\n",
    "        self.diag = diag\n",
    "        self.px_size_zyx = px_size_zyx\n",
    "        self.codebook = False\n",
    "        \n",
    "        if not diag:\n",
    "            d1 = 0; d2 = 0\n",
    "        else:\n",
    "            d1 = 1/np.sqrt(2); d2 = 1/np.sqrt(3)\n",
    "#             d1 = 1; d2 = 1\n",
    "        self.filt = torch.FloatTensor([[[d2,d1,d2],[d1,1,d1],[d2,d1,d2]],\n",
    "                                       [[d1, 1,d1],[1, 1, 1],[d1, 1,d1]],\n",
    "                                       [[d2,d1,d2],[d1,1,d1],[d2,d1,d2]]])[None,None]\n",
    "        \n",
    "    def forward(self, logits):\n",
    "\n",
    "        device = logits.device\n",
    "        p = torch.sigmoid(logits)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            p_copy = p + 0\n",
    "\n",
    "            # probability values > threshold are regarded as possible locations\n",
    "            p_clip = torch.where(p>self.m1_threshold,p,torch.zeros_like(p))\n",
    "\n",
    "            # localize maximum values within a 3x3 patch\n",
    "            pool = F.max_pool3d(p_clip,3,1,padding=1)\n",
    "            max_mask1 = torch.eq(p, pool).float()\n",
    "\n",
    "            # Add probability values from the 4 adjacent pixels\n",
    "            conv = F.conv3d(p, self.filt.to(device) ,padding=1)\n",
    "            p_ps1 = (max_mask1 * conv)\n",
    "\n",
    "            # In order do be able to identify two fluorophores in adjacent pixels we look for probablity values > 0.5 that are not part of the first mask\n",
    "\n",
    "            p_copy *= (1-max_mask1)\n",
    "            p_clip = torch.where(p_copy>self.m2_threshold, p_copy,torch.zeros_like(p_copy))\n",
    "            max_mask2 = torch.where(p_copy>self.m2_threshold, torch.ones_like(p_copy),torch.zeros_like(p_copy))\n",
    "            p_ps2 = max_mask2*conv\n",
    "\n",
    "            # This is our final clustered probablity which we then threshold (normally > 0.7) to get our final discrete locations \n",
    "            p_ps = p_ps1 + p_ps2        \n",
    "\n",
    "            return p_ps\n",
    "        \n",
    "    def get_si_resdict(self, res_dict, p_si=None):\n",
    "        \n",
    "        if p_si is None:\n",
    "            p_si = self.forward(res_dict['logits'])\n",
    "            \n",
    "        res_dict['Probs_si'] = p_si\n",
    "        res_dict['Samples_si'] = torch.where(res_dict['Probs_si'] > self.samp_threshold, torch.ones_like(res_dict['Probs_si']), torch.zeros_like(res_dict['Probs_si']))\n",
    "        \n",
    "        return res_dict\n",
    "        \n",
    "    def get_df(self, res_dict, p_si=None, softmax=False):\n",
    "        \n",
    "        res_dict = self.get_si_resdict(res_dict, p_si)\n",
    "        \n",
    "        res_dict = {k:v.cpu() for (k,v) in res_dict.items()}\n",
    "        locations = res_dict['Samples_si'].nonzero(as_tuple=True)\n",
    "        ch0_locs = locations[0], locations[1]*0, locations[2] ,locations[3], locations[4]\n",
    "\n",
    "        pos_x, pos_y, pos_z = locations[-1] ,locations[-2], locations[-3]\n",
    "        \n",
    "        x = pos_x + res_dict['xyzi_mu'][:,[0]][ch0_locs] + 0.5 \n",
    "        y = pos_y + res_dict['xyzi_mu'][:,[1]][ch0_locs] + 0.5 \n",
    "        z = pos_z + res_dict['xyzi_mu'][:,[2]][ch0_locs] + 0.5\n",
    "\n",
    "        loc_idx = torch.arange(len(x))\n",
    "        frame_idx = locations[0]\n",
    "\n",
    "        df = DF({'loc_idx': loc_idx,\n",
    "                 'frame_idx': frame_idx,\n",
    "                 'code_inds': locations[1],\n",
    "                 'x': x*self.px_size_zyx[2],\n",
    "                 'y': y*self.px_size_zyx[1], \n",
    "                 'z': z*self.px_size_zyx[0], \n",
    "                 'prob': res_dict['Probs_si'][locations], \n",
    "                 'int': res_dict['xyzi_mu'][:,[3]][ch0_locs], \n",
    "                 'int_sig': res_dict['xyzi_sigma'][:,[3]][ch0_locs], \n",
    "                 'x_sig': res_dict['xyzi_sigma'][:,[0]][ch0_locs]*self.px_size_zyx[0], \n",
    "                 'y_sig': res_dict['xyzi_sigma'][:,[1]][ch0_locs]*self.px_size_zyx[1], \n",
    "                 'z_sig': res_dict['xyzi_sigma'][:,[2]][ch0_locs]*self.px_size_zyx[2],\n",
    "                 'comb_sig': torch.sqrt(res_dict['xyzi_sigma'][:,[0]][ch0_locs]**2\n",
    "                                       +res_dict['xyzi_sigma'][:,[1]][ch0_locs]**2\n",
    "                                       +res_dict['xyzi_sigma'][:,[2]][ch0_locs]**2)})\n",
    "\n",
    "        return df\n",
    "        \n",
    "    def get_micro_inp(self, res_dict, p_si=None):\n",
    "\n",
    "        channels = self.codebook.shape[1]\n",
    "        n_bits = (1.*self.codebook.sum(1)).mean()\n",
    "        res_dict = self.get_si_resdict(res_dict, p_si)\n",
    "        # remove dump inds. Wont get reconstructed. \n",
    "        locations = res_dict['Samples_si'][:,:-1].nonzero(as_tuple=True)\n",
    "\n",
    "        xyzi_ix = [locations[0],locations[2],locations[3], locations[4]]\n",
    "        x_os_3d = res_dict['xyzi_mu'][:,0][xyzi_ix]\n",
    "        y_os_3d = res_dict['xyzi_mu'][:,1][xyzi_ix]\n",
    "        z_os_3d = res_dict['xyzi_mu'][:,2][xyzi_ix]\n",
    "        ints_3d = res_dict['xyzi_mu'][:,3][xyzi_ix]\n",
    "        # output_shape  = res_dict['Samples_si'].shape\n",
    "        ints_3d = ints_3d/n_bits\n",
    "        \n",
    "        ints_ret = ints_3d[:,None].repeat_interleave(channels, 1)\n",
    "#         ch_bin = torch.zeros(ints_ret.shape).to(ints_ret.device)\n",
    "#         ch_bin.scatter_(index=torch.tensor(code_inds).to(ints_ret.device)[locations[1]], dim=1, value=1)\n",
    "        ch_bin = self.codebook.to(ints_ret.device)[locations[1]]\n",
    "        ints_ret = ints_ret*ch_bin\n",
    "        \n",
    "        output_shape  = res_dict['Samples_si'].shape\n",
    "        output_shape  = torch.Size([output_shape[0],channels,output_shape[2],output_shape[3],output_shape[4]])\n",
    "\n",
    "        return xyzi_ix, x_os_3d, y_os_3d, z_os_3d, ints_ret, output_shape\n",
    "# p_col = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# class ISIPostProcess(SIPostProcess):\n",
    "    \n",
    "#     def __init__(self, m1_threshold:float = 0.1, samp_threshold=0.1, px_size_zyx=[100,100,100], diag=False):\n",
    "        \n",
    "#         super().__init__(m1_threshold = m1_threshold, samp_threshold=samp_threshold, px_size_zyx=px_size_zyx, diag=diag)\n",
    "#         self.m2_threshold = None\n",
    "        \n",
    "#     def forward(self, logits):\n",
    "\n",
    "#         device = logits.device\n",
    "#         count = 0\n",
    "#         p = torch.sigmoid(logits)\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "            \n",
    "#             p_ret = 0\n",
    "#             tot_mask = torch.ones_like(p)\n",
    "# #             count_arr = torch.zeros_like(p)\n",
    "            \n",
    "#             while True:\n",
    "                \n",
    "#                 count += 1\n",
    "\n",
    "#                 # probability values > threshold are regarded as possible locations\n",
    "#                 p_clip = torch.where(p>self.m1_threshold,p,torch.zeros_like(p))*tot_mask\n",
    "\n",
    "#                 # localize maximum values within a 3x3 patch\n",
    "#                 pool = F.max_pool3d(p_clip,3,1,padding=1)\n",
    "#                 max_mask1 = torch.eq(p, pool).float()\n",
    "#                 max_mask1[p==0] = 0\n",
    "                \n",
    "# #                 count_arr += max_mask1*count\n",
    "                \n",
    "#                 tot_mask *= (torch.ones_like(max_mask1) - max_mask1)\n",
    "                \n",
    "#                 # Add probability values from the adjacent pixels\n",
    "#                 conv = F.conv3d(p, self.filt.to(device).expand(-1,p.shape[1],-1,-1,-1) ,padding=1)\n",
    "#                 p_ps = max_mask1 * conv\n",
    "                \n",
    "#                 p_ret += torch.clamp_max(p_ps, 1) \n",
    "                \n",
    "#                 p_fac = 1/p_ps\n",
    "#                 p_fac[torch.isinf(p_fac)] = 0\n",
    "#                 p_fac = torch.clamp_max(p_fac, 1) \n",
    "#                 p_proc = F.conv3d(p_fac, self.filt.to(device),padding=1)*p\n",
    "\n",
    "#                 p = p - p_proc\n",
    "#                 torch.clamp_min_(p, 0)\n",
    "                \n",
    "#                 if not max_mask1.sum():\n",
    "#                     break\n",
    "            \n",
    "#             return p_ret #, count_arr\n",
    "        \n",
    "# #                 plt.figure(figsize=(20,5))\n",
    "# #                 plt.subplot(141)\n",
    "# #                 plt.imshow(cpu(p[0,0][sl[1:]]).sum(0))\n",
    "# #                 plt.subplot(142)\n",
    "# #                 plt.imshow(cpu(p_ps[0,0][sl[1:]]).sum(0))\n",
    "# #                 plt.title(cpu(p_ps[0,0][sl[1:]]).sum())\n",
    "# #                 plt.colorbar()\n",
    "# #                 plt.subplot(143)\n",
    "# #                 plt.imshow(cpu(p_proc[0,0][sl[1:]]).sum(0))\n",
    "# #                 plt.title(cpu(p_proc[0,0][sl[1:]]).sum())\n",
    "# #                 plt.colorbar()\n",
    "# #                 plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ISIPostProcess(SIPostProcess):\n",
    "    \n",
    "    def __init__(self, m1_threshold:float = 0.1, samp_threshold=0.1, px_size_zyx=[100,100,100], diag=False):\n",
    "        \n",
    "        super().__init__(m1_threshold = m1_threshold, samp_threshold=samp_threshold, px_size_zyx=px_size_zyx, diag=diag)\n",
    "        self.m2_threshold = None\n",
    "        \n",
    "    def forward(self, logits):\n",
    "\n",
    "        device = logits.device\n",
    "        p = torch.sigmoid(logits)\n",
    "        \n",
    "        batch_size = p.shape[0]\n",
    "        n_codes = p.shape[1]\n",
    "        \n",
    "        p = p.reshape(batch_size*n_codes,1,*p.shape[-3:])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            p_SI = 0\n",
    "            tot_mask = torch.ones_like(p)\n",
    "            max_mask = torch.ones_like(p)\n",
    "            \n",
    "            while max_mask.sum():\n",
    "                \n",
    "                # voxels with probability values > threshold,\n",
    "                # and which where not previously counted as locations, are canditates\n",
    "                p_cand = torch.where(p>self.m1_threshold, p, torch.zeros_like(p)) * tot_mask\n",
    "\n",
    "                # localize maximum (nonzero) values within a 3x3x3 volume\n",
    "                p_cand = F.max_pool3d(p_cand,3,1,padding=1)\n",
    "                max_mask = torch.eq(p, p_cand).float()\n",
    "                max_mask[p==0] = 0\n",
    "                \n",
    "                # Add up probability values from the adjacent pixels\n",
    "                conv = F.conv3d(p, self.filt.to(device), padding=1)\n",
    "                p_sum = max_mask * conv\n",
    "                \n",
    "                # Add the integrated probabilities to the return tensor. \n",
    "                p_SI += torch.clamp_max(p_sum, 1) \n",
    "                # Voxels that where added can not be added again\n",
    "                tot_mask *= (torch.ones_like(max_mask) - max_mask)\n",
    "                \n",
    "                # The probability mass that contributed to p_sum is removed.\n",
    "                p_fac = 1/p_sum\n",
    "                p_fac[torch.isinf(p_fac)] = 0\n",
    "                p_fac = torch.clamp_max(p_fac, 1) \n",
    "                p_proc = F.conv3d(p_fac, self.filt.to(device),padding=1)*p\n",
    "\n",
    "                p = p - p_proc\n",
    "                torch.clamp_min_(p, 0)\n",
    "            \n",
    "            return p_SI.reshape(batch_size,n_codes,*p.shape[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from decode_fish.funcs.evaluation import *\n",
    "\n",
    "post_proc1 = SIPostProcess(m1_threshold=0.03, m2_threshold=0.25, samp_threshold=0.6, px_size_zyx=[100,100,100], diag=True)\n",
    "post_proc2 = ISIPostProcess(m1_threshold=0.03, samp_threshold=0.5, px_size_zyx=[100,100,100], diag=True)\n",
    "\n",
    "# matching(px_to_nm(gt_df),  post_proc1.forward(model_out, ret='df'), tolerance=500, print_res=True)\n",
    "# _=matching(px_to_nm(gt_df),  post_proc2.forward(model_out, ret='df'), tolerance=500, print_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from decode_fish.funcs.utils import *\n",
    "# model_out = torch.load('../data/model_output.pt')\n",
    "# probs_inp = torch.sigmoid(model_out['logits'])[:,:,:,250:300,200:250]\n",
    "\n",
    "# model_out = torch.load('../data/model_batch_output.pt')\n",
    "# probs_inp = torch.sigmoid(model_out['logits'])\n",
    "\n",
    "# model_out = torch.load('../data/model_output_t.pt')\n",
    "# probs_inp = torch.sigmoid(model_out['logits'])[:,:,:,:,:]\n",
    "\n",
    "# model_out = torch.load('../data/model_output_2d.pt')\n",
    "# probs_inp = torch.sigmoid(model_out['logits'])\n",
    "model_out = torch.load('../data/model_batch_output_class.pt')\n",
    "# for m in model_out:\n",
    "#     model_out[m] =model_out[m].detach() \n",
    "# gt_df = torch.load('../data/gt_1.pt')\n",
    "# len(gt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13832\n"
     ]
    }
   ],
   "source": [
    "from decode_fish.funcs.merfish_eval import *\n",
    "bench_df, code_ref, targets = get_benchmark()\n",
    "code_inds = np.stack([np.nonzero(c)[0] for c in code_ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 6],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tra = post_proc2.get_micro_inp(model_out,code_inds, p_si=None, n_bits=4, channels=16)\n",
    "ints = tra[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6c3841a210>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cpu(ints[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_2d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34550/1113807055.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m140\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_2d' is not defined"
     ]
    }
   ],
   "source": [
    "model_out['logits'] = model_2d['logits'].expand(-1,140,-1,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra1 = post_proc2(model_out['logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra2 = post_proc2(model_out['logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cpu(tra2)[0,0,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_proc2.get_df(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs_inp = probs_inp[:,:,10:11]\n",
    "# for k in model_out:\n",
    "#     model_out[k] = model_out[k][:,:,10:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# print(len(gt_df))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(231)\n",
    "probs = cpu(probs_inp[0,0])\n",
    "probsf = probs + 0\n",
    "probsf[probsf<0.01] = 0\n",
    "im = plt.imshow(probs.sum(0))\n",
    "# plt.scatter(gt_df['x'],gt_df['y'], color='red', s=5.)\n",
    "plt.title(f'Net output {probs.sum().item():.1f} and {probsf.sum().item():.1f}'.format())\n",
    "add_colorbar(im)\n",
    "\n",
    "recs = post_proc1.get_si_resdict(model_out)\n",
    "plt.subplot(232)\n",
    "im = plt.imshow(cpu(recs['Probs_si'][0,0]).max(0))\n",
    "add_colorbar(im)\n",
    "N = cpu(recs['Probs_si'][0,0]).sum().item()\n",
    "plt.title(f'SI Probs SI {N:.1f}')\n",
    "\n",
    "plt.subplot(235)\n",
    "im = plt.imshow(cpu(recs['Samples_si'][0,0]).sum(0))\n",
    "add_colorbar(im)\n",
    "plt.title(cpu(recs['Samples_si'][0,0]).sum().item())\n",
    "\n",
    "recs = post_proc2.get_si_resdict(model_out)\n",
    "plt.subplot(233)\n",
    "im = plt.imshow(cpu(recs['Probs_si'][0,0]).max(0))\n",
    "add_colorbar(im)\n",
    "N = cpu(recs['Probs_si'][0,0]).sum().item()\n",
    "plt.title(f'ISI Probs SI {N:.1f}')\n",
    "\n",
    "plt.subplot(236)\n",
    "im = plt.imshow(cpu(recs['Samples_si'][0,0]).sum(0))\n",
    "add_colorbar(im)\n",
    "plt.title(cpu(recs['Samples_si'][0,0]).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = np.s_[:,:10,35:45,20:30]\n",
    "gt_sub = crop_df(gt_df, sl)\n",
    "p_sub = crop_df(nm_to_px(post_proc2.forward(model_out, ret='df')), sl)\n",
    "axes=plot_3d_projections(probs[sl[1:]], 'max', size=15)\n",
    "# print(probs[sl[1:]].sum(), len(gt_sub), len(p_sub))\n",
    "# axes[0].scatter(gt_sub['x'],gt_sub['y'], color='red', s=5.)\n",
    "# axes[1].scatter(gt_sub['x'],gt_sub['z'], color='red', s=5.)\n",
    "# axes[2].scatter(gt_sub['y'],gt_sub['z'], color='red', s=5.)\n",
    "\n",
    "axes[0].scatter(p_sub['x'],p_sub['y'], color='red', s=15.)\n",
    "axes[1].scatter(p_sub['x'],p_sub['z'], color='red', s=15.)\n",
    "axes[2].scatter(p_sub['y'],p_sub['z'], color='red', s=15.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in p_col:\n",
    "    plt.imshow(cpu(p[0,0][sl[1:]]).max(0))\n",
    "#     plt.title(cpu(p[0,0][sl[1:]]).sum())\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cpu(p[0,0][sl[1:]]).max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(probs.reshape(-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_si = post_proc.spatial_integration(probs_inp)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "probs = probs_inp[0,0].detach().cpu()\n",
    "# probs[probs<0.01] = 0\n",
    "im = plt.imshow(probs.max(dim=0).values)\n",
    "plt.title(probs.sum().item())\n",
    "add_colorbar(im)\n",
    "plt.subplot(122)\n",
    "im = plt.imshow(probs_si[0,0].cpu().max(dim=0).values, vmax=1)\n",
    "add_colorbar(im)\n",
    "plt.title(probs_si[0].sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = torch.load('../data/model_output_1.pt')\n",
    "out_df = post_proc2(model_out)\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(121)\n",
    "im = plt.imshow(probs_inp[0,0].cpu().max(dim=0).values)\n",
    "add_colorbar(im)\n",
    "plt.title(len(out_df))\n",
    "plt.scatter(out_df['x']/100,out_df['y']/100, color='red', s=5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = torch.load('../data/model_batch_output.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.engine.psf import LinearInterpolatedPSF\n",
    "from decode_fish.engine.noise import sCMOS\n",
    "from decode_fish.engine.point_process import PointProcessUniform\n",
    "from decode_fish.funcs.plotting import plot_3d_projections\n",
    "from decode_fish.engine.microscope import Microscope\n",
    "\n",
    "psf_state = torch.load('/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/fishcod/simfish_psf.pkl')\n",
    "_,xs,ys,zs = psf_state['psf_volume'].shape\n",
    "psf = LinearInterpolatedPSF(fs_x=xs, fs_y=ys, fs_z=zs, upsample_factor= 1)\n",
    "psf.load_state_dict(psf_state)\n",
    "\n",
    "noise = sCMOS()\n",
    "\n",
    "micro = Microscope(parametric_psf=[psf], noise=noise, multipl=10000).cuda()\n",
    "\n",
    "point_process = PointProcessUniform(local_rate = torch.ones([1,1,48,48,48]).cuda()*.0001, min_int = 0.5)\n",
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape = point_process.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsim = micro(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape)\n",
    "xrec = micro(locs_mod, x_os_mod, y_os_mod, z_os_mod, ints_mod, output_shape_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_projections(xsim[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_projections(xrec[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 20_MERFISH_visualization.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode_fish_dev2]",
   "language": "python",
   "name": "conda-env-decode_fish_dev2-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
