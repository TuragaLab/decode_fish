{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.train_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport -decode_fish.engine.place_psfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop simulator learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from decode_fish.funcs.evaluation import *\n",
    "from decode_fish.funcs.file_io import *\n",
    "from decode_fish.funcs.emitter_io import *\n",
    "from decode_fish.funcs.utils import *\n",
    "from decode_fish.funcs.dataset import *\n",
    "from decode_fish.funcs.output_trafo import *\n",
    "from decode_fish.funcs.plotting import *\n",
    "from decode_fish.funcs.predict import *\n",
    "from decode_fish.funcs.visualization import *\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as D\n",
    "from torch.utils.data import DataLoader\n",
    "import torch_optimizer\n",
    "from decode_fish.engine.microscope import Microscope, get_roi_filt_inds, extract_psf_roi, mic_inp_apply_inds, add_pos_noise\n",
    "from decode_fish.engine.model import UnetDecodeNoBn\n",
    "from decode_fish.engine.point_process import PointProcessUniform, get_phased_ints\n",
    "from decode_fish.engine.gmm_loss import PointProcessGaussian\n",
    "import shutil\n",
    "import wandb\n",
    "import kornia\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from decode_fish.funcs.merfish_eval import *\n",
    "from decode_fish.funcs.exp_specific import *\n",
    "# from decode_fish.funcs.visualization vimport get_simulation_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_logger(pred_df, target_df, iteration, data_str='Sim. '):\n",
    "    \n",
    "    perf_dict,matches,shift = matching(target_df, pred_df, print_res=False,  match_genes=True)\n",
    "    if 'Inp' in data_str:\n",
    "        pred_corr = shift_df(pred_df, shift)\n",
    "        perf_dict, _, _ = matching(target_df, pred_corr, print_res=False,  match_genes=True)\n",
    "\n",
    "    wandb.log({data_str +'Metrics/eff_3d': perf_dict['eff_3d']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/jaccard': perf_dict['jaccard']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/rmse_vol': perf_dict['rmse_vol']}, step=iteration)\n",
    "\n",
    "    wandb.log({data_str +'Metrics/precision': perf_dict['precision']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/recall': perf_dict['recall']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/rmse_x': perf_dict['rmse_x']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/rmse_y': perf_dict['rmse_y']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/rmse_z': perf_dict['rmse_z']}, step=iteration)   \n",
    "    \n",
    "    return matches\n",
    "\n",
    "def save_train_state(save_dir, model, microscope, optim_dict, train_iter):\n",
    "    \n",
    "        torch.save({'state_dict':model.state_dict(), 'scaling':[model.inp_scale, model.inp_offset]}, save_dir/'model.pkl')\n",
    "        torch.save(microscope.state_dict(), save_dir/'microscope.pkl')\n",
    "        \n",
    "        save_dict = {k:v.state_dict() for (k,v) in optim_dict.items()}\n",
    "        save_dict['train_iter'] = train_iter\n",
    "        \n",
    "        torch.save(save_dict, save_dir/'training_state.pkl')\n",
    "        \n",
    "def exp_train_eval(bench_df, res_df, targets, wandb, batch_idx):\n",
    "    \n",
    "    if len(res_df):\n",
    "    \n",
    "        res_sub = res_df.nsmallest(len(bench_df), 'comb_sig')\n",
    "\n",
    "        bench_counts = DF(data=None, index=targets)\n",
    "        bench_counts['Res_all'] = res_sub.groupby('gene')['gene'].count()\n",
    "        bench_counts['Bench_all'] = bench_df.groupby('gene')['gene'].count()\n",
    "        bench_counts = bench_counts.fillna(0)\n",
    "        \n",
    "        r = np.corrcoef(bench_counts['Bench_all'].values, bench_counts['Res_all'].values)[0, 1]   \n",
    "\n",
    "        blinds = []\n",
    "        for i,g in enumerate(targets):\n",
    "            if 'Blank' in g:\n",
    "                blinds.append(g)\n",
    "\n",
    "        bc = bench_counts.loc[blinds,'Res_all'].values.sum()\n",
    "        bench_bc = bench_counts.loc[blinds,'Bench_all'].values.sum()\n",
    "        \n",
    "        bench_df['z'] = bench_df['z']/1000\n",
    "        res_sub['z'] = res_sub['z']/100\n",
    "        \n",
    "        wandb.log({'AE Losses/code_bench_corr': r}, step=batch_idx)\n",
    "        wandb.log({'AE Losses/N_blanks': bc/bench_bc}, step=batch_idx)\n",
    "        \n",
    "        perf_dict, match_df, shifts = matching(bench_df,  res_sub, tolerance=500)\n",
    "        wandb.log({'AE Losses/jaccard': perf_dict['jaccard']}, step=batch_idx)        \n",
    "        \n",
    "    wandb.log({'AE Losses/N_pred_tot': len(res_df)/len(bench_df)}, step=batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def train(cfg,\n",
    "          model, \n",
    "          microscope,\n",
    "          post_proc,\n",
    "          dl, \n",
    "          optim_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    Training loop for autoencoder learning. Alternates between a simulator training step to train the inference network\n",
    "    and an autoencoder step to train the PSF (and microscope) parameters.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): DECODE 3D UNet.\n",
    "        microscope (torch.nn.Module): Microscope class that transforms emitter locations into simulated images.\n",
    "        post_proc (torch.nn.Module): Post processing class that transforms emitter probilities deterministically into binary outputs.\n",
    "        dl  (torch.utils.data.dataloader.DataLoader): Dataloader that returns a random sub volume from the real volume, an estiamted emitter density and background.\n",
    "        optim_dict (dict of torch.optim.Optimizer and torch.optim.lr_scheduler): Dict. with optimizer and scheduler objects for the network and gen. model parameters.\n",
    "        \n",
    "    \"\"\" \n",
    "    \n",
    "    save_dir = Path(cfg.output.save_dir)\n",
    "    bench_df = None\n",
    "\n",
    "    model.cuda().train()\n",
    "    \n",
    "    # Save initial psf state\n",
    "    torch.save(microscope.psf.state_dict(), str(save_dir) + '/psf_init.pkl' )\n",
    "    \n",
    "    # Load codebook \n",
    "    if 'codebook' in cfg:\n",
    "        code_ref, targets = hydra.utils.instantiate(cfg.codebook)\n",
    "    \n",
    "    # Controls which genmodel parameters are optimized\n",
    "    for name, p in microscope.named_parameters():\n",
    "        p.requires_grad = cfg.training.mic.par_grads[name]\n",
    "        \n",
    "    calc_log_p_x = False\n",
    "    \n",
    "    # Hacky way to switch between network / genmodel training\n",
    "    if cfg.training.schedule is not None:\n",
    "        sched = cfg.training.schedule\n",
    "        cfg.training.net.enabled = True\n",
    "        cfg.training.mic.enabled = False\n",
    "#         cfg.training.int.enabled = False\n",
    "        switch_iter = sched.pop(0)\n",
    "    \n",
    "    for batch_idx in range(cfg.training.start_iter, cfg.training.num_iters+1):\n",
    "        \n",
    "        if cfg.training.schedule is not None:\n",
    "            if batch_idx == switch_iter:\n",
    "                cfg.training.net.enabled = not(cfg.training.net.enabled)\n",
    "                cfg.training.mic.enabled = not(cfg.training.mic.enabled)\n",
    "#                 cfg.training.int.enabled = not(cfg.training.int.enabled)\n",
    "                switch_iter += sched.pop(0)\n",
    "\n",
    "        t0 = time.time()\n",
    "        ret_dict = next(iter(dl))\n",
    "        # Get real data window and rate/background for the simulation\n",
    "        x, local_rate, background = ret_dict['x'], ret_dict['local_rate'], ret_dict['background'] \n",
    "        zcrop, ycrop, xcrop = ret_dict['crop_z'], ret_dict['crop_y'], ret_dict['crop_x']\n",
    "        \n",
    "        background = background * microscope.get_ch_mult().detach()\n",
    "        x = x * microscope.get_ch_mult().detach()\n",
    "        \n",
    "        colshift_crop = get_color_shift_inp(microscope.color_shifts, microscope.col_shifts_yx, ycrop, xcrop, cfg.sim.random_crop.crop_sz)\n",
    "\n",
    "        if cfg.training.net.enabled:\n",
    "    \n",
    "            optim_dict['optim_net'].zero_grad()\n",
    "\n",
    "            sim_vars = PointProcessUniform(local_rate[:,0], int_conc=model.int_dist.int_conc.detach(), \n",
    "                                           int_rate=model.int_dist.int_rate.detach(), int_loc=model.int_dist.int_loc.detach(), \n",
    "                                           sim_iters=5, channels=cfg.genm.exp_type.n_channels, n_bits=cfg.genm.exp_type.n_bits, \n",
    "                                           sim_z=cfg.genm.exp_type.pred_z, codebook=torch.tensor(code_ref, dtype=torch.bool), int_option=cfg.training.int_option).sample(from_code_book=True)\n",
    "\n",
    "            # sim_vars = locs_sl, x_os_sl, y_os_sl, z_os_sl, ints_sl, output_shape, codes\n",
    "#             print('Sim, ', time.time()-t0); t0 = time.time()\n",
    "            ch_inp = list(microscope.get_single_ch_inputs(*sim_vars[:-1], ycrop=ycrop.flatten(), xcrop=xcrop.flatten()))\n",
    "            ch_inp[1:4] = add_pos_noise(ch_inp[1:4], [cfg.genm.pos_noise.pos_noise_xy, cfg.genm.pos_noise.pos_noise_xy, cfg.genm.pos_noise.pos_noise_z], cfg.genm.exp_type.n_bits)\n",
    "            xsim = microscope(*ch_inp, add_noise=True)\n",
    "            \n",
    "            if cfg.genm.phasing:\n",
    "                \n",
    "                phasing_inp = list(microscope.get_single_ch_inputs(*sim_vars[:4], get_phased_ints(sim_vars[4], microscope.ch_cols, microscope.psf.n_cols) ,sim_vars[5], ycrop=ycrop.flatten(), xcrop=xcrop.flatten()))\n",
    "                phasing_inp[1:4] = add_pos_noise(phasing_inp[1:4], [cfg.genm.pos_noise.pos_noise_xy, cfg.genm.pos_noise.pos_noise_xy, cfg.genm.pos_noise.pos_noise_z], cfg.genm.exp_type.n_bits, rm_mean=False)\n",
    "                xsim += microscope(*phasing_inp, add_noise=True) * cfg.genm.phasing * torch.rand(xsim.shape, device=xsim.device)\n",
    "#             print('Micro, ', time.time()-t0); t0 = time.time()\n",
    "\n",
    "            # Spurious emitter patterns (not from codebook)\n",
    "            if cfg.genm.emitter_noise.rate_fac:\n",
    "\n",
    "                noise_vars = PointProcessUniform(local_rate[:,0] * cfg.genm.emitter_noise.rate_fac, int_conc=model.int_dist.int_conc.detach() * cfg.genm.emitter_noise.int_fac, \n",
    "                                               int_rate=model.int_dist.int_rate.detach(), int_loc=model.int_dist.int_loc.detach(), \n",
    "                                               sim_iters=5, channels=cfg.genm.exp_type.n_channels, n_bits=1, \n",
    "                                               sim_z=cfg.genm.exp_type.pred_z, codebook=None, int_option=cfg.training.int_option).sample(from_code_book=False)     \n",
    "\n",
    "                noise_inp = microscope.get_single_ch_inputs(*noise_vars[:-1], ycrop=ycrop.flatten(), xcrop=xcrop.flatten())\n",
    "                xsim += microscope(*noise_inp, add_noise=True)\n",
    "\n",
    "            xsim_noise = microscope.noise(xsim, background, const_theta_sim=cfg.genm.exp_type.const_theta_sim).sample()\n",
    "            \n",
    "\n",
    "#             print('Noise. ', time.time()-t0); t0 = time.time()\n",
    "            \n",
    "            out_sim = model.tensor_to_dict(model(torch.concat([xsim_noise,colshift_crop], 1)))\n",
    "            \n",
    "#             print('Model forw. ', time.time()-t0); t0 = time.time()\n",
    "\n",
    "            ppg = PointProcessGaussian(**out_sim)\n",
    "\n",
    "            count_prob, spatial_prob = ppg.log_prob(*sim_vars[:5], codes=sim_vars[-1], \n",
    "                                                    n_bits=cfg.genm.exp_type.n_bits, channels=cfg.genm.exp_type.n_channels, \n",
    "                                                    loss_option=cfg.training.loss_option, \n",
    "                                                    count_mult=cfg.training.count_mult, cat_logits=cfg.training.cat_logits,\n",
    "                                                    slice_rec=cfg.genm.exp_type.slice_rec, z_sig_fac=cfg.training.z_sig_fac,\n",
    "                                                    int_inf=cfg.genm.exp_type.int_inf)\n",
    "\n",
    "            gmm_loss = -(spatial_prob + cfg.training.net.cnt_loss_scale*count_prob).mean()\n",
    "\n",
    "            background_loss = F.mse_loss(out_sim['background'], background) * cfg.training.net.bl_loss_scale\n",
    "\n",
    "            loss = gmm_loss + background_loss\n",
    "            \n",
    "#             print('Loss calc. ', time.time()-t0); t0 = time.time()\n",
    "\n",
    "            # Update network parameters\n",
    "            loss.backward()\n",
    "\n",
    "            if cfg.training.net.grad_clip: torch.nn.utils.clip_grad_norm_(model.network.parameters(), max_norm=cfg.training.net.grad_clip, norm_type=2)\n",
    "\n",
    "            optim_dict['optim_net'].step()\n",
    "            optim_dict['sched_net'].step()\n",
    "\n",
    "#             print('Grad upd. ', time.time()-t0); t0 = time.time()\n",
    "\n",
    "        ch_out_inp = [[],[]]    \n",
    "        if batch_idx > min(cfg.training.start_mic,cfg.training.start_int) and batch_idx % cfg.training.mic.freq == 0:\n",
    "            \n",
    "#             out_inp = model.tensor_to_dict(model(x))\n",
    "            out_inp = model.tensor_to_dict(model(torch.concat([x, colshift_crop], 1)))\n",
    "            proc_out_inp = post_proc.get_micro_inp(out_inp)\n",
    "\n",
    "            if cfg.training.mic.enabled and batch_idx > cfg.training.start_mic and len(proc_out_inp[1]) > 0: # and len(proc_out_inp[1]) < 300:\n",
    "#                 print('Pre filt ', len(proc_out_inp[1]))\n",
    "                ch_out_inp = microscope.get_single_ch_inputs(*proc_out_inp, ycrop=ycrop.flatten(), xcrop=xcrop.flatten())\n",
    "                optim_dict['optim_mic'].zero_grad()\n",
    "                calc_log_p_x = False\n",
    "            \n",
    "                # Get ch_fac loss\n",
    "                ch_inds = ch_out_inp[0][1]\n",
    "                int_vals = ch_out_inp[-2]\n",
    "                \n",
    "                int_means = torch.ones(cfg.genm.exp_type.n_channels).cuda()\n",
    "                for i in range(cfg.genm.exp_type.n_channels):\n",
    "                    if i in ch_inds:\n",
    "                        int_means[i] = int_vals[ch_inds == i].mean() / int_vals.mean()\n",
    "                        \n",
    "                ch_fac_loss = torch.sqrt(torch.mean((microscope.channel_facs - microscope.channel_facs.detach() / int_means)**2))\n",
    "                \n",
    "                # Get autoencoder loss\n",
    "                if cfg.training.mic.roi_rec:\n",
    "                    filt_inds = get_roi_filt_inds(*ch_out_inp[0], microscope.psf.psf_volume.shape, x.shape, slice_rec=cfg.genm.exp_type.slice_rec, min_dist=10)\n",
    "                    ch_out_inp = mic_inp_apply_inds(*ch_out_inp, filt_inds)\n",
    "                    if len(ch_out_inp[1]):\n",
    "                        psf_recs = microscope(*ch_out_inp, ret_psfs=True, add_noise=False)  \n",
    "#                         print('N rec inds ', len(psf_recs))\n",
    "\n",
    "                        rois = extract_psf_roi(ch_out_inp[0], x, torch.tensor(psf_recs.shape))\n",
    "                        bgs = extract_psf_roi(ch_out_inp[0], out_inp['background'], torch.tensor(psf_recs.shape))\n",
    "        \n",
    "                        if cfg.training.mic.mean_diff:\n",
    "                            mean_diff = rois.mean([1,2,3,4], keepdim=True) - (psf_recs.detach()+bgs).mean([1,2,3,4], keepdim=True)\n",
    "                            rois -= mean_diff\n",
    "                        \n",
    "#                         if cfg.training.mic.edge_diff:\n",
    "#                             bg_edges = torch.cat([bgs[:,0,0,:2,:].flatten(1,2), bgs[:,0,0,-2:,:].flatten(1,2), bgs[:,0,0,:,:2].flatten(1,2), bgs[:,0,0,:,-2:].flatten(1,2)], 1)\n",
    "#                             rois_edges = torch.cat([rois[:,0,0,:2,:].flatten(1,2), rois[:,0,0,-2:,:].flatten(1,2), rois[:,0,0,:,:2].flatten(1,2), rois[:,0,0,:,-2:].flatten(1,2)], 1)\n",
    "#                             edge_diff = rois_edges.mean(-1) - bg_edges.mean(-1)\n",
    "#                             rois -= edge_diff[:,None,None,None,None]\n",
    "\n",
    "                        log_p_x_given_z = -microscope.noise(psf_recs, bgs, const_theta_sim=False, ch_inds=ch_out_inp[0][1]).log_prob(rois.clamp_min_(1.))\n",
    "\n",
    "                        log_p_x_given_z = log_p_x_given_z.mean()\n",
    "                        calc_log_p_x = True\n",
    "                        \n",
    "                else:\n",
    "                    ae_img = microscope(*ch_out_inp, add_noise=False)\n",
    "                    log_p_x_given_z = -microscope.noise(ae_img, out_inp['background'], const_theta_sim=False).log_prob(x.clamp_min_(1.)).mean()\n",
    "                    calc_log_p_x = True\n",
    "                    \n",
    "                if calc_log_p_x:\n",
    "                    \n",
    "#                     print(ch_fac_loss)\n",
    "                    log_p_x_given_z += ch_fac_loss\n",
    "                    \n",
    "                    if cfg.training.mic.norm_reg:\n",
    "                        log_p_x_given_z += cfg.training.mic.norm_reg * (microscope.psf.com_loss())\n",
    "                        \n",
    "                    if cfg.training.mic.l1_reg:\n",
    "                        log_p_x_given_z += cfg.training.mic.l1_reg * (microscope.psf.l1_diff_norm(microscope.psf_init_vol))  \n",
    "\n",
    "                    log_p_x_given_z.backward()\n",
    "                    if cfg.training.mic.grad_clip:\n",
    "                        torch.nn.utils.clip_grad_norm_(microscope.parameters(), max_norm=cfg.training.mic.grad_clip, norm_type=2)\n",
    "\n",
    "                    optim_dict['optim_mic'].step()\n",
    "                    \n",
    "                optim_dict['sched_mic'].step()\n",
    "               \n",
    "            if  cfg.training.int.enabled and batch_idx > cfg.training.start_int:\n",
    "                if len(ch_out_inp[1]):\n",
    "                    optim_dict['optim_int'].zero_grad()\n",
    "                    ints = ch_out_inp[-2]\n",
    "                    ints = torch.clamp_min(ints, model.int_dist.int_loc.detach() + 0.01)\n",
    "\n",
    "                    gamma_int = D.Gamma(model.int_dist.int_conc, model.int_dist.int_rate)\n",
    "                    loc_trafo = [D.AffineTransform(loc=model.int_dist.int_loc.detach(), scale=1)]\n",
    "                    int_loss = -D.TransformedDistribution(gamma_int, loc_trafo).log_prob(ints.detach()).mean()\n",
    "\n",
    "                    if cfg.training.int.grad_clip:\n",
    "                        torch.nn.utils.clip_grad_norm_(model.int_dist.parameters(), max_norm=cfg.training.mic.grad_clip, norm_type=2)\n",
    "\n",
    "                    int_loss.backward()\n",
    "                    optim_dict['optim_int'].step()\n",
    "                \n",
    "#                 print('INT ', time.time()-t0); t0 = time.time()\n",
    "\n",
    "        # Logging\n",
    "        if batch_idx % 10 == 0:\n",
    "            \n",
    "            if cfg.training.net.enabled:\n",
    "            \n",
    "                wandb.log({'SL Losses/xyz_loss': spatial_prob.mean().detach().cpu().item()}, step=batch_idx)\n",
    "    #             wandb.log({'SL Losses/ints_loss': int_prob.mean().detach().cpu().item()}, step=batch_idx)\n",
    "                wandb.log({'SL Losses/count_loss': (-count_prob.mean()).detach().cpu()}, step=batch_idx)\n",
    "    #             wandb.log({'SL Losses/bg_loss': background_loss.detach().cpu()}, step=batch_idx)\n",
    "        \n",
    "#                 wandb.log({'AE Losses/int_mu': model.int_dist.int_conc.item()/model.int_dist.int_rate.item() + model.int_dist.int_loc.item()}, step=batch_idx)\n",
    "#                 wandb.log({'AE Losses/int_rate': model.int_dist.int_rate.item()}, step=batch_idx)\n",
    "#                 wandb.log({'AE Losses/int_loc': model.int_dist.int_loc.item()}, step=batch_idx)\n",
    "                wandb.log({'AE Losses/theta': microscope.noise.theta_par.cpu().detach().mean().item()*microscope.noise.theta_scale}, step=batch_idx)\n",
    "\n",
    "            if batch_idx > cfg.training.start_mic: \n",
    "                if cfg.training.mic.enabled and calc_log_p_x:\n",
    "                    wandb.log({'AE Losses/p_x_given_z': log_p_x_given_z.detach().cpu()}, step=batch_idx)\n",
    "                    wandb.log({'AE Losses/RMSE(rec)': torch.sqrt(((rois-(psf_recs+bgs))**2).mean()).detach().cpu()}, step=batch_idx)\n",
    "#                     wandb.log({'AE Losses/RMSE(rec)': torch.sqrt(((x[:,:1]-(ae_img[:,:1]+out_inp['background'][:,:1]))**2).mean()).detach().cpu()}, step=batch_idx)\n",
    "                    wandb.log({'AE Losses/sum(psf)': F.relu(microscope.psf.psf_volume/microscope.psf.psf_volume.max())[0].sum().detach().cpu()}, step=batch_idx)\n",
    "#                     wandb.log({'AE Losses/theta': microscope.theta.item()}, step=batch_idx)\n",
    "        \n",
    "#         if batch_idx > 0 and batch_idx % 1500 == 0:\n",
    "#             torch.save({'state_dict':model.state_dict(), 'scaling':[model.inp_scale, model.inp_offset]}, save_dir/f'model_{batch_idx}.pkl')\n",
    "    \n",
    "        if batch_idx % cfg.output.log_interval == 0:\n",
    "            print(batch_idx)\n",
    "\n",
    "            if cfg.training.net.enabled:\n",
    "                \n",
    "                with torch.no_grad():\n",
    "\n",
    "                    pred_df = post_proc.get_df(out_sim)\n",
    "                    px_size = cfg.evaluation.px_size_zyx\n",
    "                    target_df = sample_to_df(*sim_vars[:5], sim_vars[-1], px_size_zyx=px_size)\n",
    "    #                 print(len(pred_df), len(target_df))\n",
    "                    matches = eval_logger(pred_df, target_df, batch_idx, data_str='Sim. ')\n",
    "\n",
    "                    wandb.log({'Sim. Metrics/prob_fac': torch.sigmoid(out_sim['logits']).sum().item()/(len(target_df)+0.1)}, step=batch_idx)\n",
    "                    wandb.log({'Sim. Metrics/n_em_fac': len(pred_df)/(len(target_df)+0.1)}, step=batch_idx)\n",
    "\n",
    "                    if cfg.output.log_figs:\n",
    "\n",
    "                        sl_fig = sl_plot(x, xsim_noise, nm_to_px(pred_df, px_size), nm_to_px(target_df, px_size), background, out_sim)\n",
    "                        plt.show()\n",
    "                        wandb.log({'SL summary': sl_fig}, step=batch_idx)\n",
    "\n",
    "\n",
    "                    if cfg.evaluation.code_stats.enabled:\n",
    "\n",
    "                        crop = eval(cfg.evaluation.code_stats.crop,{'__builtins__': None},{'s_': np.s_})\n",
    "                        if bench_df is None:\n",
    "                            bench_df = hydra.utils.call(cfg.evaluation.code_stats.bench_func, crop=crop)\n",
    "                            \n",
    "                        res_df = window_predict(model, post_proc, dl.dataset.volumes, window_size=[None, 64, 64], device='cuda', crop=crop, \n",
    "                                                chrom_map=get_color_shift_inp(microscope.color_shifts, microscope.col_shifts_yx)[:,:,None], scale=microscope.get_ch_mult().detach())\n",
    "                        res_df['gene'] = targets[res_df['code_inds']]\n",
    "                        res_df = hydra.utils.call(cfg.evaluation.code_stats.df_postp_func, res_df=res_df)\n",
    "                        exp_train_eval(bench_df, res_df, targets, wandb=wandb, batch_idx=batch_idx)\n",
    "\n",
    "\n",
    "            # storing\n",
    "            save_train_state(save_dir, model, microscope, optim_dict, batch_idx) \n",
    "            \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = cfg = OmegaConf.load('/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/models/fishcod/MERFISH_MOp/sweep_mop_22/mean_diff:Truexnorm:nonexenabled:True//train.yaml')\n",
    "cfg = OmegaConf.load(f'/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/models/fishcod/MERFISH_starfish/MERFISH_sweep_gen_3/nPSFxnorm:none///train.yaml')\n",
    "cfg.run_name = 'test'\n",
    "\n",
    "cfg.output.log_interval = 100\n",
    "cfg.training.bs = 5\n",
    "\n",
    "# cfg.training.num_iters = 50\n",
    "# cfg.data_path.model_init = None\n",
    "# cfg.genm.phasing = 0.1\n",
    "# cfg.training.start_mic = 0\n",
    "# cfg.training.start_int = 100000\n",
    "\n",
    "# cfg.training.net.enabled = False\n",
    "\n",
    "# cfg.training.mic.par_grads.channel_facs = False\n",
    "# cfg.training.mic.par_grads.channel_shifts = False\n",
    "# cfg.training.mic.par_grads.theta_par = False\n",
    "# cfg.training.mic.par_grads.psf_vol = True\n",
    "\n",
    "psf, noise, micro = load_psf_noise_micro(cfg)\n",
    "post_proc = hydra.utils.instantiate(cfg.post_proc_isi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop size larger than volume in at least one dimension. Crop size changed to (1, 48, 48)\n",
      "1 volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "img_3d, decode_dl = get_dataloader(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.data_path.model_init = '/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm//models/fishcod/MERFISH_MOp/sweep_mop_17/phasing:0.0'\n",
    "# cfg.training.num_iters = 100000\n",
    "# cfg.training.schedule = None\n",
    "# cfg.training.mic.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.evaluation.code_stats.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Microscope(\n",
       "  (psf): LinearInterpolatedPSF(\n",
       "    (forward_nonlin): Identity()\n",
       "  )\n",
       "  (noise): sCMOS()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_offset, inp_scale = get_forward_scaling(img_3d[0])\n",
    "# inp_scale = 300\n",
    "# inp_offset = 100\n",
    "model = hydra.utils.instantiate(cfg.network, inp_scale=inp_scale, inp_offset=inp_offset)\n",
    "\n",
    "psf  .to('cuda')\n",
    "model.to('cuda')\n",
    "micro.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for param in model.parameters():\n",
    "    params.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_dict = {}\n",
    "optim_dict['optim_net'] = hydra.utils.instantiate(cfg.training.net.opt, params=model.network.parameters())\n",
    "optim_dict['optim_mic'] = hydra.utils.instantiate(cfg.training.mic.opt, params=micro.parameters())\n",
    "optim_dict['optim_int'] = hydra.utils.instantiate(cfg.training.int.opt, params=model.int_dist.parameters())\n",
    "\n",
    "optim_dict['sched_net'] = hydra.utils.instantiate(cfg.training.net.sched, optimizer=optim_dict['optim_net'])\n",
    "optim_dict['sched_mic'] = hydra.utils.instantiate(cfg.training.mic.sched, optimizer=optim_dict['optim_mic'])\n",
    "optim_dict['sched_int'] = hydra.utils.instantiate(cfg.training.int.sched, optimizer=optim_dict['optim_int'])\n",
    "    \n",
    "save_dir = Path(cfg.output.save_dir)\n",
    "save_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading network\n"
     ]
    }
   ],
   "source": [
    "# cfg.data_path.model_init = cfg.output.save_dir\n",
    "# cfg.data_path.model_init = None #'/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm//models/fishcod/MERFISH_MOp/sweep_mop_20/schedule:nullxfreq:3xnorm:nonexz_facs:Falsexmean_diff:False'\n",
    "\n",
    "if cfg.training.resume:\n",
    "    cfg.data_path.model_init = cfg.output.save_dir\n",
    "    cfg.data_path.micro_init = cfg.output.save_dir\n",
    "\n",
    "if cfg.data_path.model_init is not None:\n",
    "    print('loading network')\n",
    "    model = load_model_state(model, Path(cfg.data_path.model_init)/'model.pkl').cuda()\n",
    "    # micro.load_state_dict(torch.load(Path(cfg.data_path.model_init)/'microscope.pkl'), strict=False)\n",
    "\n",
    "    if cfg.training.net.enabled:\n",
    "        train_state_dict = torch.load(Path(cfg.data_path.model_init)/'training_state.pkl')\n",
    "        for k in optim_dict:\n",
    "            if 'net' in k:\n",
    "                optim_dict[k].load_state_dict(train_state_dict[k])    \n",
    "\n",
    "        cfg.training.start_iter = train_state_dict['train_iter']\n",
    "\n",
    "if cfg.data_path.micro_init is not None:\n",
    "    print('loading microscope')\n",
    "    micro.load_state_dict(torch.load(Path(cfg.data_path.micro_init)/'microscope.pkl'), strict=False)\n",
    "    \n",
    "    if cfg.training.mic.enabled:\n",
    "        train_state_dict = torch.load(Path(cfg.data_path.micro_init)/'training_state.pkl')\n",
    "        for k in optim_dict:\n",
    "            if 'mic' in k:\n",
    "                optim_dict[k].load_state_dict(train_state_dict[k])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.training.start_iter = 9995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_ref, targets = hydra.utils.instantiate(cfg.codebook)\n",
    "post_proc.codebook = torch.tensor(code_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maspeiser\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "2022-05-12 08:20:47.940467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm//decode_fish/runs/wandb/run-20220512_082045-1642dlf3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/aspeiser/MERFISH_starfish/runs/1642dlf3\" target=\"_blank\">test</a></strong> to <a href=\"https://wandb.ai/aspeiser/MERFISH_starfish\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = wandb.init(project=cfg.output.project, \n",
    "               config=OmegaConf.to_container(cfg, resolve=True),\n",
    "               dir=cfg.output.log_dir,\n",
    "               group=cfg.output.group,\n",
    "               name=cfg.run_name,\n",
    "               mode='online'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmicroscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmicro\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m     \u001b[49m\u001b[43mpost_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m     \u001b[49m\u001b[43moptim_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(cfg, model, microscope, post_proc, dl, optim_dict)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mmin\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mstart_mic,cfg\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mstart_int) \u001b[38;5;129;01mand\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m cfg\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mmic\u001b[38;5;241m.\u001b[39mfreq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    139\u001b[0m             \n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m#             out_inp = model.tensor_to_dict(model(x))\u001b[39;00m\n\u001b[1;32m    141\u001b[0m             out_inp \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtensor_to_dict(model(torch\u001b[38;5;241m.\u001b[39mconcat([x, colshift_crop], \u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m--> 142\u001b[0m             proc_out_inp \u001b[38;5;241m=\u001b[39m \u001b[43mpost_proc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_micro_inp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_inp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mmic\u001b[38;5;241m.\u001b[39menabled \u001b[38;5;129;01mand\u001b[39;00m batch_idx \u001b[38;5;241m>\u001b[39m cfg\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mstart_mic \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(proc_out_inp[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(proc_out_inp[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m#                 print('Pre filt ', len(proc_out_inp[1]))\u001b[39;00m\n\u001b[1;32m    146\u001b[0m                 ch_out_inp \u001b[38;5;241m=\u001b[39m microscope\u001b[38;5;241m.\u001b[39mget_single_ch_inputs(\u001b[38;5;241m*\u001b[39mproc_out_inp, ycrop\u001b[38;5;241m=\u001b[39mycrop\u001b[38;5;241m.\u001b[39mflatten(), xcrop\u001b[38;5;241m=\u001b[39mxcrop\u001b[38;5;241m.\u001b[39mflatten())\n",
      "File \u001b[0;32m~/Dropbox (mackelab)/Artur/WorkDB/deepstorm/decode_fish/decode_fish/funcs/output_trafo.py:157\u001b[0m, in \u001b[0;36mSIPostProcess.get_micro_inp\u001b[0;34m(self, res_dict, p_si)\u001b[0m\n\u001b[1;32m    155\u001b[0m channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebook\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    156\u001b[0m n_bits \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebook\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m--> 157\u001b[0m res_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_si_resdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_si\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m locations \u001b[38;5;241m=\u001b[39m res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSamples_si\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnonzero(as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    160\u001b[0m n_int \u001b[38;5;241m=\u001b[39m res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxyzi_mu\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[0;32m~/Dropbox (mackelab)/Artur/WorkDB/deepstorm/decode_fish/decode_fish/funcs/output_trafo.py:107\u001b[0m, in \u001b[0;36mSIPostProcess.get_si_resdict\u001b[0;34m(self, res_dict, p_si)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_si_resdict\u001b[39m(\u001b[38;5;28mself\u001b[39m, res_dict, p_si\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p_si \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m         p_si \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbs_si\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m p_si\n\u001b[1;32m    110\u001b[0m     res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSamples_si\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbs_si\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamp_threshold, torch\u001b[38;5;241m.\u001b[39mones_like(res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbs_si\u001b[39m\u001b[38;5;124m'\u001b[39m]), torch\u001b[38;5;241m.\u001b[39mzeros_like(res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbs_si\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[0;32m~/Dropbox (mackelab)/Artur/WorkDB/deepstorm/decode_fish/decode_fish/funcs/output_trafo.py:214\u001b[0m, in \u001b[0;36mISIPostProcess.forward\u001b[0;34m(self, logits)\u001b[0m\n\u001b[1;32m    211\u001b[0m tot_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(p)\n\u001b[1;32m    212\u001b[0m max_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(p)\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m max_mask\u001b[38;5;241m.\u001b[39msum():\n\u001b[1;32m    215\u001b[0m \n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# voxels with probability values > threshold,\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# and which where not previously counted as locations, are canditates\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     p_cand \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(p\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm1_threshold, p, torch\u001b[38;5;241m.\u001b[39mzeros_like(p)) \u001b[38;5;241m*\u001b[39m tot_mask\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# localize maximum (nonzero) values within a 3x3x3 volume\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(cfg=cfg,\n",
    "     model=model, \n",
    "     microscope=micro, \n",
    "     post_proc=post_proc,\n",
    "     dl=decode_dl, \n",
    "     optim_dict=optim_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted 25_ensembling.ipynb.\n",
      "Converted 26_gen_train.ipynb.\n",
      "Converted 27_testtime_rescale.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode_fish_dev2]",
   "language": "python",
   "name": "conda-env-decode_fish_dev2-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
