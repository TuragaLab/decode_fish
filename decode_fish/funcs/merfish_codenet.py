# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/22_MERFISH_codenet.ipynb (unless otherwise specified).

__all__ = ['input_from_df', 'extract_rmses', 'code_net', 'net', 'make_roc']

# Cell
from ..imports import *
from .file_io import *
from .emitter_io import *
from .utils import *
from .dataset import *
from .plotting import *
from ..engine.noise import estimate_noise_scale
import shutil
from .visualization import *
from .predict import predict
import torch.nn as nn
import torch.nn.functional as F
import torch.tensor as T
from .predict import *

from omegaconf import open_dict
from hydra import compose, initialize
from .merfish_eval import *

# Cell

# def input_from_df(df, from_matches=True):

#     df_str = '_pred' if from_matches else  ''
#     df = get_code_from_ints(df, code_ref, targets, int_str=df_str)
#     matched_codes = code_ref[df['code_inds'].values]

#     input_keys = ['prob'+df_str,'x_sig'+df_str,'y_sig'+df_str, 'code_err'] + [f'int_{i}{df_str}' for i in range(16)] + [f'int_sig_{i}{df_str}' for i in range(16)]
#     inp_arr = df[input_keys].values
#     return np.concatenate([df[input_keys].values, matched_codes], 1)

# def input_from_df(df, code_ref, targets, from_matches=True):

#     df_str = '_pred' if from_matches else  ''
#     df = get_code_from_ints(df, code_ref, targets, int_str=df_str)
#     matched_codes = code_ref[df['code_inds'].values]

#     input_keys = ['prob'+df_str,'x_sig'+df_str,'y_sig'+df_str, 'code_err'] #+ ['rec_rmses'] + [f'int_sig_{i}{df_str}' for i in range(16)]
#     inp_arr = df[input_keys].values
#     int_sum = df[[f'int_{i}{df_str}' for i in range(16)]].values.sum(-1)[:,None]
#     ints_sum = df[[f'int_sig_{i}{df_str}' for i in range(16)]].values.sum(-1)[:,None]

#     return np.concatenate([inp_arr, int_sum, ints_sum], 1)

def input_from_df(df, code_ref):

    input_keys = ['prob','x_sig','y_sig','code_err', 'prob'] + [f'int_sig_{i}' for i in range(16)]  + [f'int_{i}' for i in range(16)] + [f'int_p_{i}' for i in range(16)]
    inp_arr = df[input_keys].values

    codes = code_ref[df['code_inds'].values]

    return np.concatenate([inp_arr, codes], 1)
#     int_sum = df[[f'int_{i}' for i in range(16)]].values.sum(-1)[:,None]
#     ints_sum = df[[f'int_sig_{i}' for i in range(16)]].values.sum(-1)[:,None]

#     return np.concatenate([inp_arr, int_sum, ints_sum], 1)



# def target_from_matches(matches_df, code_ref, targets):

#     matches_df = get_code_from_ints(matches_df, code_ref, targets, int_str='_pred')
#     matched_codes = code_ref[matches_df['code_inds'].values]

# #     int_arr = matches_df[[f'int_{i}_tar' for i in range(16)]]
# #     tar_code = np.where(int_arr>0,1,0)

#     int_arr = matches_df[[f'int_{i}_tar' for i in range(16)]].values
#     s_arr = np.sort(int_arr)
#     lim = s_arr[:,-5]
#     tar_code = np.stack([np.where(i>l,1,0) for i,l in zip(int_arr, lim)])
#     matches_df[[f'int_{i}_tar' for i in range(16)]] = tar_code
#     matches_df = get_code_from_ints(matches_df, code_ref, targets, int_str='_tar')
#     tar_code = code_ref[matches_df['code_inds'].values]

#     return  1 - abs(np.array(matched_codes, dtype='int') - np.array(tar_code, dtype='int')).max(1)

def extract_rmses(vol, ixy_coords, size_xy = 10, px_size=100):

    rmses = []

    for k in range(len(ixy_coords)):

        i, x, y = ixy_coords[k]
        crop = np.s_[int(i),:, np.max([0,int(y/px_size-size_xy)]): int(y/px_size+size_xy+1), np.max([0,int(x/px_size-size_xy)]): int(x/px_size+size_xy+1)]

        rmses.append(vol[crop].mean().item())

    return rmses

# Cell
class code_net(nn.Module):

    def __init__(self, n_inputs=69, n_outputs=1):
        super(code_net, self).__init__()

        self.fc1 = nn.Linear(n_inputs, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 32)
        self.fc4 = nn.Linear(32, n_outputs)

    def forward(self, x):
        x = F.elu(self.fc1(x))
        x = F.elu(self.fc2(x))
        x = F.elu(self.fc3(x))
        x = self.fc4(x)
        return x

net = code_net().cuda()

# Cell
def make_roc(df, var='code_err', ascending=True, n_max=30000):

    if n_max is None:
        n_max = len(df)
    x = np.arange(1000,n_max,100)
    df = df.sort_values(var, ascending=ascending)
    n_blanks = []
    for i in x:
        n_blanks.append((df[:i]['gt_match'] == 0).sum())

    return x, n_blanks