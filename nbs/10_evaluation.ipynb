{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from decode_fish.funcs.output_trafo import SIPostProcess\n",
    "from  decode_fish.funcs.emitter_io import *\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def matching(target_df, pred_df, tolerance=1000, print_res=True, eff_const=0.5, match_genes=True, self_match=False, allow_multiple_matches=False):\n",
    "    \"\"\"Matches localizations to ground truth positions and provides assessment metrics used in the SMLM2016 challenge.\n",
    "    (see http://bigwww.epfl.ch/smlm/challenge2016/index.html?p=methods#6)\n",
    "    When using default parameters exactly reproduces the procedure used for the challenge (i.e. produces same numbers as the localization tool).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_csv: str or list\n",
    "        Ground truth positions with columns: 'localization', 'frame', 'x', 'y', 'z'\n",
    "        Either list or str with locations of csv file.\n",
    "    pred_inp: list\n",
    "        List of localizations\n",
    "    size_xy: list of floats\n",
    "        Size of processed recording in nano meters\n",
    "    tolerance: float\n",
    "        Localizations are matched when they are within a circle of the given radius.\n",
    "    tolerance_ax: float\n",
    "        Localizations are matched when they are closer than this value in z direction. Should be ininity for 2D recordings. 500nm is used for 3D recordings in the challenge.\n",
    "    border: float\n",
    "        Localizations that are close to the edge of the recording are excluded because they often suffer from artifacts.\n",
    "    print_res: bool\n",
    "        If true prints a list of assessment metrics.\n",
    "    min_int: bool\n",
    "        If true only uses the brightest 75% of ground truth locations.\n",
    "        This is the setting used in the leaderboard of the challenge. However this implementation does not exactly match the method used in the localization tool.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    perf_dict, matches: dict, list\n",
    "        Dictionary of perfomance metrics.\n",
    "        List of all matches localizations for further evaluation in format: 'localization', 'frame', 'x_true', 'y_true', 'z_true', 'x_pred', 'y_pred', 'z_pred', 'int_true', 'x_sig', 'y_sig', 'z_sig'\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    perf_dict = None\n",
    "    match_df = pd.DataFrame()\n",
    "    TP = 0\n",
    "    FP = 0.0001\n",
    "    FN = 0.0001\n",
    "    MSE_vol = 0\n",
    "\n",
    "    match_list = []\n",
    "    tar_cols = target_df.keys()\n",
    "    pred_cols = pred_df.keys()\n",
    "\n",
    "    if len(pred_df):\n",
    "\n",
    "        for i in range(0, pred_df['frame_idx'].max() + 1):\n",
    "\n",
    "            FC = 0\n",
    "            sub_tar = target_df[target_df['frame_idx']==i].reset_index()\n",
    "            sub_pred = pred_df[pred_df['frame_idx']==i].reset_index()\n",
    "            \n",
    "            tar_xyz = sub_tar[['x','y','z']]\n",
    "            pred_xyz = sub_pred[['x','y','z']]\n",
    "            \n",
    "            if match_genes:\n",
    "                tar_gene = sub_tar['code_inds']\n",
    "                pred_gene = sub_pred['code_inds']\n",
    "            \n",
    "            u_dists = []\n",
    "            u_p_inds = []\n",
    "            u_t_inds = []\n",
    "            \n",
    "            if len(tar_xyz) and len(pred_xyz):\n",
    "            \n",
    "                tar_tree = cKDTree(tar_xyz)\n",
    "                pred_tree = cKDTree(pred_xyz)\n",
    "                sdm = tar_tree.sparse_distance_matrix(pred_tree, tolerance, output_type='ndarray')\n",
    "\n",
    "                sort_inds = np.argsort(sdm['v'])\n",
    "                dists = sdm['v'][sort_inds]\n",
    "                t_inds = sdm['i'][sort_inds]\n",
    "                p_inds = sdm['j'][sort_inds]\n",
    "\n",
    "                for d,p,t in zip(dists, p_inds, t_inds):\n",
    "                    \n",
    "                    if allow_multiple_matches is False:\n",
    "                        condition = p not in u_p_inds and t not in u_t_inds\n",
    "                    else:   \n",
    "                        condition = p not in u_p_inds\n",
    "                    if self_match:\n",
    "                        condition = p not in u_p_inds and p not in u_t_inds and d>0\n",
    "                        \n",
    "                    if condition:\n",
    "                        if match_genes:\n",
    "                            if pred_gene[p] != tar_gene[t]:\n",
    "                                continue\n",
    "                         \n",
    "                        u_dists.append(d)\n",
    "                        u_p_inds.append(p)\n",
    "                        u_t_inds.append(t)\n",
    "                    \n",
    "            MSE_vol += (np.array(u_dists) ** 2).sum()\n",
    "\n",
    "            TP += len(u_t_inds)\n",
    "\n",
    "            FP += len(pred_xyz) - len(u_t_inds)\n",
    "            FN += len(tar_xyz) - len(u_t_inds)\n",
    "            \n",
    "            if len(u_t_inds): match_list.append(np.concatenate([sub_tar.loc[u_t_inds,tar_cols].values, sub_pred.loc[u_p_inds,pred_cols].values], 1))\n",
    "\n",
    "    if len(match_list): match_list = np.concatenate(match_list, 0) \n",
    "    \n",
    "    match_df = pd.DataFrame(match_list, columns = [k+'_tar' for k in tar_cols] + [k+'_pred' for k in pred_cols])\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    jaccard = TP / (TP + FP + FN)\n",
    "\n",
    "    rmse_vol = np.sqrt(MSE_vol / (TP + 0.00001))\n",
    "\n",
    "    eff_3d = 100-np.sqrt((100-100*jaccard)**2 + eff_const**2 * rmse_vol**2)\n",
    "\n",
    "    rmse_x = np.nan\n",
    "    rmse_y = np.nan\n",
    "    rmse_z = np.nan\n",
    "\n",
    "    x_s = np.nan\n",
    "    y_s = np.nan\n",
    "    z_s = np.nan\n",
    "\n",
    "    if len(match_df):\n",
    "        rmse_x = np.sqrt(((match_df['x_tar']-match_df['x_pred'])**2).mean())\n",
    "        rmse_y = np.sqrt(((match_df['y_tar']-match_df['y_pred'])**2).mean())\n",
    "        rmse_z = np.sqrt(((match_df['z_tar']-match_df['z_pred'])**2).mean())\n",
    "\n",
    "        x_s = (match_df['x_tar']-match_df['x_pred']).mean()\n",
    "        y_s = (match_df['y_tar']-match_df['y_pred']).mean()\n",
    "        z_s = (match_df['z_tar']-match_df['z_pred']).mean()\n",
    "\n",
    "    if print_res:\n",
    "        print('{}{:0.3f}'.format('Recall: ', recall))\n",
    "        print('{}{:0.3f}'.format('Precision: ', precision))\n",
    "        print('{}{:0.3f}'.format('Jaccard: ', 100 * jaccard))\n",
    "        print('{}{:0.3f}'.format('RMSE_vol: ', rmse_vol))\n",
    "        print('{}{:0.3f}'.format('Eff_3d: ', eff_3d))\n",
    "        print('FN: ' + str(np.round(FN)) + ' FP: ' + str(np.round(FP)))\n",
    "        print('{}{:0.3f}'.format('Num. matches: ', len(match_df)))\n",
    "\n",
    "        print(f'Shift: {x_s:.2f},{y_s:.2f},{z_s:.2f}')\n",
    "\n",
    "    perf_dict = {'recall': recall, 'precision': precision, 'jaccard': jaccard, 'rmse_vol': rmse_vol,\n",
    "            'rmse_x': rmse_x, 'rmse_y': rmse_y,  'rmse_z': rmse_z, 'eff_3d': eff_3d, 'n_matches':len(match_df)}\n",
    "\n",
    "    return perf_dict, match_df, [x_s,y_s,z_s]\n",
    "\n",
    "#export\n",
    "def remove_doublets(pred_df, tolerance=300):\n",
    "    _, matches, _ = matching(pred_df, pred_df, tolerance=300, match_genes=True, allow_multiple_matches=True, self_match=True, print_res=False)\n",
    "    return pred_df.loc[~pred_df['loc_idx'].isin(matches['loc_idx_pred'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '/groups/turaga/home/speisera/share_TUM/FishSIM/sim_density_fac1_2/'\n",
    "from decode_fish.funcs.file_io import load_sim_fish\n",
    "img, gt_df, fq_nog_df, fq_gmm_df = load_sim_fish(basedir, 2000, 'random', 'NR', 0)\n",
    "# model_out = torch.load('../data/model_output.pt')\n",
    "# model_preds = SIPostProcpx_size_zyx=size=[100, 100, 300]).forward(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.717\n",
      "Precision: 0.933\n",
      "Jaccard: 68.175\n",
      "RMSE_vol: 132.084\n",
      "Eff_3d: 26.690\n",
      "FN: 381.0 FP: 69.0\n",
      "Shift: 4.83,5.59,8.72\n"
     ]
    }
   ],
   "source": [
    "# preds = fq_gmm_df\n",
    "\n",
    "perf_df, matches, _ = matching(gt_df, fq_gmm_df, tolerance=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.958\n",
      "Precision: 0.974\n",
      "Jaccard: 93.388\n",
      "RMSE_vol: 116.393\n",
      "Eff_3d: 41.429\n",
      "FN: 10.0 FP: 6.0\n",
      "Shift: -32.13,-32.89,-98.43\n"
     ]
    }
   ],
   "source": [
    "preds = fq_gmm_df\n",
    "perf_df, matches, _ = matching(gt_df, preds, tolerance=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 20_MERFISH_visualization.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode_fish_dev2]",
   "language": "python",
   "name": "conda-env-decode_fish_dev2-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
