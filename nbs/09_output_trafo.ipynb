{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.output_trafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport -decode_fish.engine.place_psfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations of sampled data and model output into emitter dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from decode_fish.funcs.utils import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sample_to_df(locs, x_os, y_os, z_os, ints, codes, px_size_zyx=[100,100,100]):\n",
    "    \n",
    "    x = locs[-1] + x_os + 0.5 \n",
    "    y = locs[-2] + y_os + 0.5 \n",
    "    z = locs[-3] + z_os + 0.5 \n",
    "    \n",
    "    n_gt = len(x)\n",
    "    channels = ints.shape[1]\n",
    "    \n",
    "    frame_idx = locs[0]\n",
    "    \n",
    "    df = DF({'loc_idx': torch.arange(n_gt),\n",
    "             'frame_idx': frame_idx.cpu(),\n",
    "             'x': x.cpu()*px_size_zyx[2],\n",
    "             'y': y.cpu()*px_size_zyx[1], \n",
    "             'z': z.cpu()*px_size_zyx[0]}) \n",
    "    \n",
    "    for i in range(channels):\n",
    "        df[f'int_{i}'] = ints[:,i].cpu()\n",
    "        \n",
    "    df['code_inds'] = cpu(codes)\n",
    "    df['ints'] = ints.sum(-1).cpu()\n",
    "\n",
    "    return df\n",
    "\n",
    "# def df_to_micro(df, px_size_zyx=[100,100,100]):\n",
    "    \n",
    "#     locs = tuple([torch.tensor(df['frame_idx'],dtype=torch.int64).cuda(),\n",
    "#                  torch.zeros(len(df),dtype=torch.int64).cuda(),\n",
    "#                  torch.tensor((df['z']/px_size_zyx[0] + 0.5),dtype=torch.int64).cuda(),\n",
    "#                  torch.tensor((df['y']/px_size_zyx[1] + 0.5),dtype=torch.int64).cuda(),\n",
    "#                  torch.tensor((df['x']/px_size_zyx[2] + 0.5),dtype=torch.int64).cuda()])\n",
    "#     z = (torch.tensor(df['z'],dtype=torch.float32).cuda()-locs[2]*px_size_zyx[0])/px_size_zyx[0] - 0.5\n",
    "#     y = (torch.tensor(df['y'],dtype=torch.float32).cuda()-locs[3]*px_size_zyx[1])/px_size_zyx[1] - 0.5\n",
    "#     x = (torch.tensor(df['x'],dtype=torch.float32).cuda()-locs[4]*px_size_zyx[2])/px_size_zyx[2] - 0.5\n",
    "#     ints = torch.tensor(df['int']).cuda()\n",
    "\n",
    "#     return locs, x, y, z, ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.funcs.exp_specific import get_starfish_codebook\n",
    "codebook, targets = get_starfish_codebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.engine.point_process import PointProcessUniform\n",
    "point_process = PointProcessUniform(int_conc=3, int_rate=1, int_loc=1, sim_iters=1, n_channels=16, codebook=torch.tensor(codebook, dtype=torch.bool), int_option=1)\n",
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, codes = point_process.sample(local_rate = torch.ones([7,1,48,48]).cuda()*.1, from_code_book=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_idx</th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>int_0</th>\n",
       "      <th>int_1</th>\n",
       "      <th>int_2</th>\n",
       "      <th>int_3</th>\n",
       "      <th>int_4</th>\n",
       "      <th>...</th>\n",
       "      <th>int_8</th>\n",
       "      <th>int_9</th>\n",
       "      <th>int_10</th>\n",
       "      <th>int_11</th>\n",
       "      <th>int_12</th>\n",
       "      <th>int_13</th>\n",
       "      <th>int_14</th>\n",
       "      <th>int_15</th>\n",
       "      <th>code_inds</th>\n",
       "      <th>ints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>602.444519</td>\n",
       "      <td>94.020721</td>\n",
       "      <td>41.264355</td>\n",
       "      <td>2.261528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.041451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.316419</td>\n",
       "      <td>5.905613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59</td>\n",
       "      <td>14.525011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>755.175110</td>\n",
       "      <td>81.307144</td>\n",
       "      <td>67.976311</td>\n",
       "      <td>2.649300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.590044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.832100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>131</td>\n",
       "      <td>16.074507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2165.647461</td>\n",
       "      <td>46.984226</td>\n",
       "      <td>116.434586</td>\n",
       "      <td>2.366854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.431772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.247006</td>\n",
       "      <td>3.214121</td>\n",
       "      <td>48</td>\n",
       "      <td>11.259754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4207.121094</td>\n",
       "      <td>48.784954</td>\n",
       "      <td>120.563210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.064821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.461357</td>\n",
       "      <td>3.610906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.229338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>15.366423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3085.540039</td>\n",
       "      <td>107.486343</td>\n",
       "      <td>-38.294731</td>\n",
       "      <td>6.519287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.707895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.992783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>14.966919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>1570</td>\n",
       "      <td>6</td>\n",
       "      <td>1017.610840</td>\n",
       "      <td>4715.620605</td>\n",
       "      <td>65.084099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.406691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.465253</td>\n",
       "      <td>...</td>\n",
       "      <td>4.033400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.135442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93</td>\n",
       "      <td>19.040787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>1571</td>\n",
       "      <td>6</td>\n",
       "      <td>1300.200562</td>\n",
       "      <td>4748.441895</td>\n",
       "      <td>139.291428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.711392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.876353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>17.138813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>1572</td>\n",
       "      <td>6</td>\n",
       "      <td>1535.519653</td>\n",
       "      <td>4787.458008</td>\n",
       "      <td>-28.025579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.678063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.952571</td>\n",
       "      <td>3.991022</td>\n",
       "      <td>77</td>\n",
       "      <td>15.006134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>1573</td>\n",
       "      <td>6</td>\n",
       "      <td>1770.533569</td>\n",
       "      <td>4752.785645</td>\n",
       "      <td>118.339600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.301468</td>\n",
       "      <td>4.808718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.232765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47</td>\n",
       "      <td>15.245344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>1574</td>\n",
       "      <td>6</td>\n",
       "      <td>3105.295166</td>\n",
       "      <td>4772.733398</td>\n",
       "      <td>-22.288132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.382092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.644301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105</td>\n",
       "      <td>13.797544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1575 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      loc_idx  frame_idx            x            y           z     int_0  \\\n",
       "0           0          0   602.444519    94.020721   41.264355  2.261528   \n",
       "1           1          0   755.175110    81.307144   67.976311  2.649300   \n",
       "2           2          0  2165.647461    46.984226  116.434586  2.366854   \n",
       "3           3          0  4207.121094    48.784954  120.563210  0.000000   \n",
       "4           4          0  3085.540039   107.486343  -38.294731  6.519287   \n",
       "...       ...        ...          ...          ...         ...       ...   \n",
       "1570     1570          6  1017.610840  4715.620605   65.084099  0.000000   \n",
       "1571     1571          6  1300.200562  4748.441895  139.291428  0.000000   \n",
       "1572     1572          6  1535.519653  4787.458008  -28.025579  0.000000   \n",
       "1573     1573          6  1770.533569  4752.785645  118.339600  0.000000   \n",
       "1574     1574          6  3105.295166  4772.733398  -22.288132  0.000000   \n",
       "\n",
       "         int_1     int_2     int_3     int_4  ...     int_8     int_9  \\\n",
       "0     0.000000  4.041451  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "1     0.000000  0.000000  6.590044  0.000000  ...  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  0.000000  ...  0.000000  2.431772   \n",
       "3     3.064821  0.000000  0.000000  0.000000  ...  6.461357  3.610906   \n",
       "4     0.000000  4.707895  0.000000  0.000000  ...  1.992783  0.000000   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "1570  0.000000  6.406691  0.000000  5.465253  ...  4.033400  0.000000   \n",
       "1571  0.000000  0.000000  0.000000  3.711392  ...  0.000000  4.876353   \n",
       "1572  0.000000  3.678063  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "1573  0.000000  0.000000  0.000000  0.000000  ...  0.000000  2.301468   \n",
       "1574  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "\n",
       "        int_10    int_11    int_12    int_13    int_14    int_15  code_inds  \\\n",
       "0     0.000000  0.000000  0.000000  2.316419  5.905613  0.000000         59   \n",
       "1     0.000000  1.832100  0.000000  0.000000  0.000000  0.000000        131   \n",
       "2     0.000000  0.000000  0.000000  0.000000  3.247006  3.214121         48   \n",
       "3     0.000000  0.000000  0.000000  2.229338  0.000000  0.000000         30   \n",
       "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000         40   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "1570  0.000000  3.135442  0.000000  0.000000  0.000000  0.000000         93   \n",
       "1571  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000         16   \n",
       "1572  0.000000  0.000000  0.000000  0.000000  2.952571  3.991022         77   \n",
       "1573  4.808718  0.000000  5.232765  0.000000  0.000000  0.000000         47   \n",
       "1574  0.000000  6.382092  0.000000  0.000000  3.644301  0.000000        105   \n",
       "\n",
       "           ints  \n",
       "0     14.525011  \n",
       "1     16.074507  \n",
       "2     11.259754  \n",
       "3     15.366423  \n",
       "4     14.966919  \n",
       "...         ...  \n",
       "1570  19.040787  \n",
       "1571  17.138813  \n",
       "1572  15.006134  \n",
       "1573  15.245344  \n",
       "1574  13.797544  \n",
       "\n",
       "[1575 rows x 23 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = sample_to_df(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, codes)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SIPostProcess(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, m1_threshold:float = 0.03, m2_threshold:float = 0.3, samp_threshold=0.1, px_size_zyx=[100,100,100], diag=0):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.m1_threshold = m1_threshold\n",
    "        self.m2_threshold = m2_threshold\n",
    "        self.samp_threshold = samp_threshold\n",
    "        self.diag = diag\n",
    "        self.px_size_zyx = px_size_zyx\n",
    "        self.codebook = False\n",
    "        \n",
    "        if not diag:\n",
    "            d1 = 0; d2 = 0\n",
    "        else:\n",
    "            d1 = 1/np.sqrt(2); d2 = 1/np.sqrt(3)\n",
    "#             d1 = 1; d2 = 1\n",
    "        self.filt = torch.FloatTensor([[[d2,d1,d2],[d1,1,d1],[d2,d1,d2]],\n",
    "                                       [[d1, 1,d1],[1, 1, 1],[d1, 1,d1]],\n",
    "                                       [[d2,d1,d2],[d1,1,d1],[d2,d1,d2]]])[None,None]\n",
    "        \n",
    "    def forward(self, logits):\n",
    "\n",
    "        device = logits.device\n",
    "        p = torch.sigmoid(logits)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            p_copy = p + 0\n",
    "\n",
    "            # probability values > threshold are regarded as possible locations\n",
    "            p_clip = torch.where(p>self.m1_threshold,p,torch.zeros_like(p))\n",
    "\n",
    "            # localize maximum values within a 3x3 patch\n",
    "            pool = F.max_pool3d(p_clip,3,1,padding=1)\n",
    "            max_mask1 = torch.eq(p, pool).float()\n",
    "\n",
    "            # Add probability values from the 4 adjacent pixels\n",
    "            conv = F.conv3d(p, self.filt.to(device) ,padding=1)\n",
    "            p_ps1 = (max_mask1 * conv)\n",
    "\n",
    "            # In order do be able to identify two fluorophores in adjacent pixels we look for probablity values > 0.5 that are not part of the first mask\n",
    "\n",
    "            p_copy *= (1-max_mask1)\n",
    "            p_clip = torch.where(p_copy>self.m2_threshold, p_copy,torch.zeros_like(p_copy))\n",
    "            max_mask2 = torch.where(p_copy>self.m2_threshold, torch.ones_like(p_copy),torch.zeros_like(p_copy))\n",
    "            p_ps2 = max_mask2*conv\n",
    "\n",
    "            # This is our final clustered probablity which we then threshold (normally > 0.7) to get our final discrete locations \n",
    "            p_ps = p_ps1 + p_ps2        \n",
    "\n",
    "            return p_ps\n",
    "        \n",
    "    def get_si_resdict(self, res_dict, p_si=None):\n",
    "        \n",
    "        if p_si is None:\n",
    "            p_si = self.forward(res_dict['logits'])\n",
    "            \n",
    "        res_dict['Probs_si'] = p_si\n",
    "        res_dict['Samples_si'] = torch.where(res_dict['Probs_si'] > self.samp_threshold, torch.ones_like(res_dict['Probs_si']), torch.zeros_like(res_dict['Probs_si']))\n",
    "        \n",
    "        return res_dict\n",
    "        \n",
    "    def get_df(self, res_dict, p_si=None, softmax=False):\n",
    "        \n",
    "        res_dict = self.get_si_resdict(res_dict, p_si)\n",
    "        \n",
    "        res_dict = {k:v.cpu() for (k,v) in res_dict.items()}\n",
    "        locations = res_dict['Samples_si'].nonzero(as_tuple=True)\n",
    "        ch0_locs = locations[0], locations[1]*0, locations[2] ,locations[3], locations[4]\n",
    "\n",
    "        pos_x, pos_y, pos_z = locations[-1] ,locations[-2], locations[-3]\n",
    "        \n",
    "        x = pos_x + res_dict['xyzi_mu'][:,[0]][ch0_locs] + 0.5 \n",
    "        y = pos_y + res_dict['xyzi_mu'][:,[1]][ch0_locs] + 0.5 \n",
    "        z = pos_z + res_dict['xyzi_mu'][:,[2]][ch0_locs] + 0.5\n",
    "\n",
    "        loc_idx = torch.arange(len(x))\n",
    "        frame_idx = locations[0]\n",
    "\n",
    "        df = DF({'loc_idx': loc_idx,\n",
    "                 'frame_idx': frame_idx,\n",
    "                 'code_inds': locations[1],\n",
    "                 'x': x*self.px_size_zyx[2],\n",
    "                 'y': y*self.px_size_zyx[1], \n",
    "                 'z': z*self.px_size_zyx[0], \n",
    "                 'prob': res_dict['Probs_si'][locations], \n",
    "                 'x_sig': res_dict['xyzi_sigma'][:,[0]][ch0_locs]*self.px_size_zyx[0], \n",
    "                 'y_sig': res_dict['xyzi_sigma'][:,[1]][ch0_locs]*self.px_size_zyx[1], \n",
    "                 'z_sig': res_dict['xyzi_sigma'][:,[2]][ch0_locs]*self.px_size_zyx[2],\n",
    "                 'comb_sig': torch.sqrt(res_dict['xyzi_sigma'][:,[0]][ch0_locs]**2\n",
    "                                       +res_dict['xyzi_sigma'][:,[1]][ch0_locs]**2\n",
    "                                       +res_dict['xyzi_sigma'][:,[2]][ch0_locs]**2)})\n",
    "        \n",
    "        for i in range(res_dict['xyzi_mu'].shape[1]-3):\n",
    "            df[f'int_{i}'] = res_dict['xyzi_mu'][:,[3+i]][ch0_locs]\n",
    "            df[f'int_sig_{i}'] = res_dict['xyzi_sigma'][:,[3+i]][ch0_locs]\n",
    "            \n",
    "        return df\n",
    "        \n",
    "    def get_micro_inp(self, res_dict, p_si=None):\n",
    "\n",
    "        channels = self.codebook.shape[1]\n",
    "        n_bits = (1.*self.codebook.sum(1)).mean()\n",
    "        res_dict = self.get_si_resdict(res_dict, p_si)\n",
    "        locations = res_dict['Samples_si'].nonzero(as_tuple=True)\n",
    "        \n",
    "        n_int = res_dict['xyzi_mu'].shape[1] - 3\n",
    "\n",
    "        xyzi_ix = [locations[0],locations[2],locations[3], locations[4]]\n",
    "        x_os_3d = res_dict['xyzi_mu'][:,0][xyzi_ix]\n",
    "        y_os_3d = res_dict['xyzi_mu'][:,1][xyzi_ix]\n",
    "        z_os_3d = res_dict['xyzi_mu'][:,2][xyzi_ix]\n",
    "        \n",
    "        if n_int == 1:\n",
    "            ints_3d = res_dict['xyzi_mu'][:,3][xyzi_ix]\n",
    "            ints_3d = ints_3d/n_bits\n",
    "            ints_ret = ints_3d[:,None].repeat_interleave(channels, 1)\n",
    "            ch_bin = self.codebook.to(ints_ret.device)[locations[1]]\n",
    "            ints_ret = ints_ret*ch_bin\n",
    "        \n",
    "        if n_int == n_bits:\n",
    "            code_inds = self.codebook.nonzero(as_tuple=True)[1].reshape([self.codebook.shape[0], -1])\n",
    "            ints_3d = res_dict['xyzi_mu'][:,3:][locations[0],:,locations[2],locations[3], locations[4]]\n",
    "            ints_ret = torch.zeros(ints_3d.shape[0], channels).to(ints_3d.device)\n",
    "            ints_ret.scatter_(index=code_inds.to(ints_ret.device)[locations[1]], dim=1, src=ints_3d)\n",
    "            \n",
    "        if n_int == channels:\n",
    "            ints_ret = res_dict['xyzi_mu'][:,3:][locations[0],:,locations[2],locations[3], locations[4]]\n",
    "            ints_ret *= self.codebook.to(ints_ret.device)[locations[1]].ne(0)\n",
    "        \n",
    "        output_shape  = res_dict['Samples_si'].shape\n",
    "        output_shape  = torch.Size([output_shape[0],channels,output_shape[2],output_shape[3],output_shape[4]])\n",
    "\n",
    "        return xyzi_ix, x_os_3d, y_os_3d, z_os_3d, ints_ret, output_shape\n",
    "# p_col = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ISIPostProcess(SIPostProcess):\n",
    "    \n",
    "    def __init__(self, m1_threshold:float = 0.1, samp_threshold=0.1, px_size_zyx=[100,100,100], diag=False):\n",
    "        \n",
    "        super().__init__(m1_threshold = m1_threshold, samp_threshold=samp_threshold, px_size_zyx=px_size_zyx, diag=diag)\n",
    "        self.m2_threshold = None\n",
    "        \n",
    "    def forward(self, logits):\n",
    "\n",
    "        device = logits.device\n",
    "        p = torch.sigmoid(logits)\n",
    "        \n",
    "        batch_size = p.shape[0]\n",
    "        n_codes = p.shape[1]\n",
    "        \n",
    "        p = p.reshape(batch_size*n_codes,1,*p.shape[-3:])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            p_SI = 0\n",
    "            tot_mask = torch.ones_like(p)\n",
    "            max_mask = torch.ones_like(p)\n",
    "            \n",
    "            while max_mask.sum():\n",
    "                \n",
    "                # voxels with probability values > threshold,\n",
    "                # and which where not previously counted as locations, are canditates\n",
    "                p_cand = torch.where(p>self.m1_threshold, p, torch.zeros_like(p)) * tot_mask\n",
    "\n",
    "                # localize maximum (nonzero) values within a 3x3x3 volume\n",
    "                p_cand = F.max_pool3d(p_cand,3,1,padding=1)\n",
    "                max_mask = torch.eq(p, p_cand).float()\n",
    "                max_mask[p==0] = 0\n",
    "                \n",
    "                # Add up probability values from the adjacent pixels\n",
    "                conv = F.conv3d(p, self.filt.to(device), padding=1)\n",
    "                p_sum = max_mask * conv\n",
    "                \n",
    "                # Add the integrated probabilities to the return tensor. \n",
    "                p_SI += torch.clamp_max(p_sum, 1) \n",
    "                # Voxels that where added can not be added again\n",
    "                tot_mask *= (torch.ones_like(max_mask) - max_mask)\n",
    "                \n",
    "                # The probability mass that contributed to p_sum is removed.\n",
    "                p_fac = 1/p_sum\n",
    "                p_fac[torch.isinf(p_fac)] = 0\n",
    "                p_fac = torch.clamp_max(p_fac, 1) \n",
    "                p_proc = F.conv3d(p_fac, self.filt.to(device),padding=1)*p\n",
    "\n",
    "                p = p - p_proc\n",
    "                torch.clamp_min_(p, 0)\n",
    "            \n",
    "            return p_SI.reshape(batch_size,n_codes,*p.shape[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from decode_fish.funcs.matching import *\n",
    "\n",
    "post_proc1 = SIPostProcess(m1_threshold=0.03, m2_threshold=0.25, samp_threshold=0.6, px_size_zyx=[100,100,100], diag=True)\n",
    "post_proc2 = ISIPostProcess(m1_threshold=0.03, samp_threshold=0.5, px_size_zyx=[100,100,100], diag=True)\n",
    "\n",
    "# matching(px_to_nm(gt_df),  post_proc1.forward(model_out, ret='df'), tolerance=500, print_res=True)\n",
    "# _=matching(px_to_nm(gt_df),  post_proc2.forward(model_out, ret='df'), tolerance=500, print_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "model_out = torch.load('../data/model_batch_output_class.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.funcs.exp_specific import get_starfish_codebook\n",
    "codebook, targets = get_starfish_codebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_proc2 = ISIPostProcess(m1_threshold=0.03, samp_threshold=0.5, px_size_zyx=[100,100,100], diag=True)\n",
    "post_proc2.codebook = torch.tensor(codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 44.00 MiB (GPU 0; 11.78 GiB total capacity; 491.93 MiB already allocated; 26.75 MiB free; 502.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tra \u001b[38;5;241m=\u001b[39m \u001b[43mpost_proc2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_micro_inp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m ints \u001b[38;5;241m=\u001b[39m tra[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mSIPostProcess.get_micro_inp\u001b[0;34m(self, res_dict, p_si)\u001b[0m\n\u001b[1;32m    106\u001b[0m channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebook\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    107\u001b[0m n_bits \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebook\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m--> 108\u001b[0m res_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_si_resdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_si\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m locations \u001b[38;5;241m=\u001b[39m res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSamples_si\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnonzero(as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    111\u001b[0m n_int \u001b[38;5;241m=\u001b[39m res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxyzi_mu\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mSIPostProcess.get_si_resdict\u001b[0;34m(self, res_dict, p_si)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_si_resdict\u001b[39m(\u001b[38;5;28mself\u001b[39m, res_dict, p_si\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p_si \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         p_si \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbs_si\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m p_si\n\u001b[1;32m     61\u001b[0m     res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSamples_si\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbs_si\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamp_threshold, torch\u001b[38;5;241m.\u001b[39mones_like(res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbs_si\u001b[39m\u001b[38;5;124m'\u001b[39m]), torch\u001b[38;5;241m.\u001b[39mzeros_like(res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbs_si\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mISIPostProcess.forward\u001b[0;34m(self, logits)\u001b[0m\n\u001b[1;32m     41\u001b[0m p_SI \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp_max(p_sum, \u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Voxels that where added can not be added again\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m tot_mask \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_mask\u001b[49m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# The probability mass that contributed to p_sum is removed.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m p_fac \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mp_sum\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 44.00 MiB (GPU 0; 11.78 GiB total capacity; 491.93 MiB already allocated; 26.75 MiB free; 502.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "tra = post_proc2.get_micro_inp(model_out)\n",
    "ints = tra[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1589, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff9cc54ac70>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cpu(ints[:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_idx</th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>code_inds</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>prob</th>\n",
       "      <th>x_sig</th>\n",
       "      <th>y_sig</th>\n",
       "      <th>z_sig</th>\n",
       "      <th>comb_sig</th>\n",
       "      <th>int_0</th>\n",
       "      <th>int_sig_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9969.679688</td>\n",
       "      <td>5539.490234</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.472965</td>\n",
       "      <td>6.863564</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.004441</td>\n",
       "      <td>4.360867</td>\n",
       "      <td>0.161154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5426.773438</td>\n",
       "      <td>9837.857422</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>4.044147</td>\n",
       "      <td>4.181149</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.001691</td>\n",
       "      <td>6.776411</td>\n",
       "      <td>0.155932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10535.931641</td>\n",
       "      <td>1685.684814</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.024311</td>\n",
       "      <td>8.992360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.007236</td>\n",
       "      <td>3.783238</td>\n",
       "      <td>0.205821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10535.046875</td>\n",
       "      <td>1692.849976</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>8.388150</td>\n",
       "      <td>9.016668</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.007555</td>\n",
       "      <td>4.017369</td>\n",
       "      <td>0.203333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6632.651367</td>\n",
       "      <td>3835.316895</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.403131</td>\n",
       "      <td>9.706549</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.009090</td>\n",
       "      <td>3.856926</td>\n",
       "      <td>0.211836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>1584</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>6737.703125</td>\n",
       "      <td>9106.716797</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.765403</td>\n",
       "      <td>5.649927</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.003877</td>\n",
       "      <td>4.813341</td>\n",
       "      <td>0.172729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>1585</td>\n",
       "      <td>4</td>\n",
       "      <td>137</td>\n",
       "      <td>9255.159180</td>\n",
       "      <td>4070.848145</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.793556</td>\n",
       "      <td>10.889218</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.012801</td>\n",
       "      <td>2.470911</td>\n",
       "      <td>0.157625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1586</td>\n",
       "      <td>4</td>\n",
       "      <td>137</td>\n",
       "      <td>9098.880859</td>\n",
       "      <td>9725.834961</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.979847</td>\n",
       "      <td>7.186817</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.004361</td>\n",
       "      <td>5.093824</td>\n",
       "      <td>0.195249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>1587</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>30.406862</td>\n",
       "      <td>17.821413</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.672839</td>\n",
       "      <td>29.970043</td>\n",
       "      <td>27.259970</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.078949</td>\n",
       "      <td>2.169087</td>\n",
       "      <td>0.231742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1588</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>5857.324219</td>\n",
       "      <td>12752.199219</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.772907</td>\n",
       "      <td>11.981318</td>\n",
       "      <td>17.209620</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.021750</td>\n",
       "      <td>2.567536</td>\n",
       "      <td>0.175653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1589 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      loc_idx  frame_idx  code_inds             x             y     z  \\\n",
       "0           0          0          0   9969.679688   5539.490234  50.0   \n",
       "1           1          0          0   5426.773438   9837.857422  50.0   \n",
       "2           2          0          1  10535.931641   1685.684814  50.0   \n",
       "3           3          0          1  10535.046875   1692.849976  50.0   \n",
       "4           4          0          1   6632.651367   3835.316895  50.0   \n",
       "...       ...        ...        ...           ...           ...   ...   \n",
       "1584     1584          4        136   6737.703125   9106.716797  50.0   \n",
       "1585     1585          4        137   9255.159180   4070.848145  50.0   \n",
       "1586     1586          4        137   9098.880859   9725.834961  50.0   \n",
       "1587     1587          4        138     30.406862     17.821413  50.0   \n",
       "1588     1588          4        138   5857.324219  12752.199219  50.0   \n",
       "\n",
       "          prob      x_sig      y_sig  z_sig  comb_sig     int_0  int_sig_0  \n",
       "0     1.000000   6.472965   6.863564  100.0  1.004441  4.360867   0.161154  \n",
       "1     0.999985   4.044147   4.181149  100.0  1.001691  6.776411   0.155932  \n",
       "2     1.000000   8.024311   8.992360  100.0  1.007236  3.783238   0.205821  \n",
       "3     0.624437   8.388150   9.016668  100.0  1.007555  4.017369   0.203333  \n",
       "4     1.000000   9.403131   9.706549  100.0  1.009090  3.856926   0.211836  \n",
       "...        ...        ...        ...    ...       ...       ...        ...  \n",
       "1584  1.000000   6.765403   5.649927  100.0  1.003877  4.813341   0.172729  \n",
       "1585  1.000000  11.793556  10.889218  100.0  1.012801  2.470911   0.157625  \n",
       "1586  1.000000   5.979847   7.186817  100.0  1.004361  5.093824   0.195249  \n",
       "1587  0.672839  29.970043  27.259970  100.0  1.078949  2.169087   0.231742  \n",
       "1588  0.772907  11.981318  17.209620  100.0  1.021750  2.567536   0.175653  \n",
       "\n",
       "[1589 rows x 13 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_proc2.get_df(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_matching.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted 25_ensembling.ipynb.\n",
      "Converted 26_gen_train.ipynb.\n",
      "Converted 27_testtime_rescale.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode_fish_dev2]",
   "language": "python",
   "name": "conda-env-decode_fish_dev2-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
