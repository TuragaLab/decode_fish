{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from typing import Union\n",
    "import skimage.measure\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import inspect\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from decode_fish.funcs.utils import *\n",
    "from perlin_numpy import generate_fractal_noise_3d, generate_perlin_noise_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DecodeDataset:\n",
    "\n",
    "    def __init__(self, volumes: list,\n",
    "                 dataset_tfms: list, \n",
    "                 rate_tfms: list, \n",
    "                 bg_tfms: list, \n",
    "                 num_iter: int = 5000, \n",
    "                 device: str = 'cpu'):\n",
    "        \"\"\"\n",
    "        Basic Dataset\n",
    "\n",
    "        Args:\n",
    "            path (str): [image_path]\n",
    "            dataset_tfms (list): transformation specific to dataset\n",
    "            rate_tfms ([type]): transformation for rate generation\n",
    "            bg_transform ([type]): background transformation\n",
    "            num_iter (int, optional):define lenth of dataset. Defaults to 5000.\n",
    "            device (str, optional): device cpu or gpu]. Defaults to 'cpu'.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.volumes = volumes\n",
    "        self.dataset_tfms = dataset_tfms\n",
    "        self.num_iter = num_iter\n",
    "        self.rate_tfms = rate_tfms\n",
    "        self.bg_tfms = bg_tfms\n",
    "        self.device = device\n",
    "        \n",
    "        print(f'{len(self.volumes)} volumes')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_iter\n",
    "\n",
    "    def __getitem__(self, _):\n",
    "        i = random.randint(0,len(self.volumes)-1)\n",
    "        x = self.volumes[i][None] # Adding dimension here to get to 4.\n",
    "        x = self._compose(x, self.dataset_tfms, ind = i)\n",
    "        local_rate = self._compose(x, self.rate_tfms, ind = i)\n",
    "        background = self._compose(x, self.bg_tfms)\n",
    "        return x.to(self.device), local_rate.to(self.device), background.to(self.device)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        print (f'{self.__class__.__name__} Summary:')\n",
    "        print (f'Dataset tfms: {len(self.dataset_tfms)}')\n",
    "        for i in self.dataset_tfms:\n",
    "            print (f'\\n-->')\n",
    "            f\"{i}\"\n",
    "        return ''\n",
    "    \n",
    "    @staticmethod\n",
    "    def _compose(x, list_func, **kwargs):\n",
    "        if not list_func: list_func.append(lambda x: x)\n",
    "        for func in list_func:\n",
    "            x = func(x, **kwargs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def print_class_signature(self, nms):\n",
    "    \"print class signature\"\n",
    "    mod = inspect.currentframe().f_back.f_locals\n",
    "    for n in nms:\n",
    "        print(f'{n}: {getattr(self,n)}')\n",
    "#export\n",
    "class TransformBase:\n",
    "    '''\n",
    "    All transformations optionally must be inherited from this class for nice\n",
    "    representations and checks if input to given transformations is a tensor\n",
    "\n",
    "    '''\n",
    "    def __repr__(self):\n",
    "        print (f'Transform({self.__class__.__name__})')\n",
    "        name = inspect.signature(self.__class__).parameters.keys()\n",
    "        print_class_signature(self, name)\n",
    "        return ''\n",
    "\n",
    "    def __call__(self, x, **kwargs):\n",
    "        assert isinstance(x, torch.Tensor), f'must be torch.tensor not {type(x)}'\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_device(x):\n",
    "        return getattr(x, 'device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ScaleTensor(TransformBase):\n",
    "    \"\"\"\n",
    "    \\nScales given `torch.Tensor` between `low` and `high`\n",
    "\n",
    "    \\nParameters:\n",
    "    \\n`low`     : lower bound\n",
    "    \\n`high`    : upper bound\n",
    "    \\n`data_min`: max value of data\n",
    "    \\n`data_max`: min value of main data\n",
    "\n",
    "    \\nReturns:\n",
    "    \\nScaled tensor\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, low: float=0., high: float=1.):\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "\n",
    "    def __call__(self, x, **kwargs) -> torch.Tensor:\n",
    "        super().__call__(x)\n",
    "        ratio = (self.high-self.low) / (x.max()-x.min() + 1)\n",
    "        return ratio * (x - x.min() + 1) + self.low\n",
    "    \n",
    "class RandScale(TransformBase):\n",
    "\n",
    "    def __init__(self, low: float, high: float):\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "\n",
    "    def __call__(self, x, **kwargs) -> torch.Tensor:\n",
    "        super().__call__(x)\n",
    "        ratio = torch.distributions.Uniform(self.low, self.high).sample()\n",
    "        return ratio * x\n",
    "    \n",
    "class UniformValue(TransformBase):\n",
    "    def __init__(self, min_val, max_val):\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "    \n",
    "    def __call__(self, image, **kwargs):\n",
    "        rand_val = torch.distributions.Uniform(self.min_val, self.max_val).sample([1])\n",
    "        return torch.ones_like(image)*rand_val\n",
    "    \n",
    "def get_forward_scaling(img):\n",
    "    \n",
    "    offset = np.median(img)\n",
    "    scale = np.max(np.array(img))/3\n",
    "    return offset, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RandomCrop3D(TransformBase):\n",
    "    \"\"\"\n",
    "    Ramdomly Crops 3D tensor.\n",
    "\n",
    "    \\nThis class will generate random crop of `crop_sz`. This class is initialized\n",
    "    with `img_sz` which should be a demension of 4 [Channel, Height, Width, Depth] and\n",
    "    a `crop_sz` dimesnion of 3 [Height, Width, Depth] of desired crop. For each crop\n",
    "    dimension `_get_slice` function will calculate random int ranging from 0 to (img_sz-crop_sz).\n",
    "    and return tuple of containing two slice intergers. If one dimension of `img_sz` matches\n",
    "    one dimension of `crop_sz` the resulting tuple will be `(None, None)` which will result\n",
    "    in not croping this particular dimension.\n",
    "\n",
    "\n",
    "    \\nParameters:\n",
    "    \\n`crop_sz`    : Size of the 3D crop  `(H, W, D)`\n",
    "\n",
    "    \\nReturns:\n",
    "    \\nCroped 3D image of the given `crop_sz`\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, crop_sz, roi_masks):\n",
    "        assert len(crop_sz) == 3 , f'Lenth of crop_sz should be 3 not {len(crop_sz)}'\n",
    "        self.crop_sz = tuple(crop_sz)\n",
    "        self.crop_prod = crop_sz[0]*crop_sz[1]*crop_sz[2]\n",
    "        self.roi_masks = roi_masks\n",
    "\n",
    "    def __call__(self, x, **kwargs):\n",
    "        _, h, w, d = x.shape\n",
    "        img_sz  = tuple((h, w, d))\n",
    "        assert (img_sz) >  self.crop_sz\n",
    "        super().__call__(x, **kwargs)\n",
    "        slice_hwd = [self._get_slice(i, k) for i, k in zip(img_sz, self.crop_sz)]\n",
    "        if 'ind' in kwargs:\n",
    "            while self._crop(self.roi_masks[kwargs['ind']][None], *slice_hwd).sum()/self.crop_prod < 0.5:\n",
    "                slice_hwd = [self._get_slice(i, k) for i, k in zip(img_sz, self.crop_sz)]\n",
    "        return self._crop(x, *slice_hwd)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_slice(sz, crop_sz):\n",
    "        up_bound = sz-crop_sz\n",
    "        if  up_bound == 0:\n",
    "            return None, None\n",
    "        else:\n",
    "            l_bound = torch.randint(up_bound, (1,))\n",
    "        return l_bound, l_bound + crop_sz\n",
    "\n",
    "    @staticmethod\n",
    "    def _crop(x, slice_h, slice_w, slice_d):\n",
    "        return x[:, slice_h[0]:slice_h[1], slice_w[0]:slice_w[1], slice_d[0]:slice_d[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AddFoci(TransformBase):\n",
    "    \n",
    "    def __init__(self, n_foci_avg: float, rad_range: tuple, n_mol_range: tuple, px_size_zyx: tuple=(100,100,100), mode='gaussian'):\n",
    "        \n",
    "        self.n_foci_avg = n_foci_avg\n",
    "        self.rad_range = rad_range\n",
    "        self.n_mol_range = n_mol_range\n",
    "        self.px_size_zyx = px_size_zyx\n",
    "        self.mode = mode\n",
    "        \n",
    "    def binary_sphere(self, shape, radius, position):\n",
    "        grid = [slice(-x0, dim - x0) for x0, dim in zip(position, shape)]\n",
    "        position = np.ogrid[grid]\n",
    "        arr = np.zeros(shape, dtype=float)\n",
    "        for x_i, semisize in zip(position, radius):\n",
    "            arr += (x_i / semisize) ** 2\n",
    "\n",
    "        return arr <= 1.0\n",
    "    \n",
    "    def gaussian_sphere(self, shape, radius, position):\n",
    "        grid = [slice(-x0, dim - x0) for x0, dim in zip(position, shape)]\n",
    "        position = np.ogrid[grid]\n",
    "        arr = np.exp(-position[0]**2 / (2 * (radius[0] ** 2))) * np.exp(-position[1]**2 / (2 * (radius[1] ** 2))) * np.exp(-position[2]**2 / (2 * (radius[2] ** 2))) / (2 * np.pi * (radius[0] * radius[1] * radius[2]))\n",
    "        return arr\n",
    "    \n",
    "    def __call__(self, x, **kwargs) -> torch.Tensor:\n",
    "        super().__call__(x)\n",
    "        \n",
    "        prob = self.n_foci_avg/torch.numel(x[0])\n",
    "        locations = torch.distributions.Bernoulli(torch.ones_like(x)*prob).sample()\n",
    "        xwf = x + 0\n",
    "        \n",
    "        for inds in torch.nonzero(locations, as_tuple=False):\n",
    "            rad = torch.distributions.Uniform(*self.rad_range).sample().item()\n",
    "            rads = [rad/pxs for pxs in self.px_size_zyx]\n",
    "            n_mol = torch.distributions.Uniform(*self.n_mol_range).sample().item()\n",
    "            center = inds[-3:].cpu().numpy()\n",
    "            size = list(x.shape[-3:])\n",
    "            if 'gaus' in self.mode:\n",
    "                foci = torch.tensor(self.gaussian_sphere(list(x.shape[-3:]), rads, center))\n",
    "            if 'bin' in self.mode:\n",
    "                foci = torch.tensor(self.binary_sphere(list(x.shape[-3:]), rads, center))\n",
    "            foci = foci * (n_mol / foci.sum())\n",
    "            xwf[inds[0]] += foci.to(x.device)\n",
    "        \n",
    "        return xwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GaussianSmoothing(TransformBase):\n",
    "    def __init__(self, smoothing_filter_size, div_factor=1):\n",
    "        self.smoothing_filter_size = smoothing_filter_size\n",
    "        self.div_factor = div_factor\n",
    "    \n",
    "    def __call__(self, image, **kwargs):\n",
    "        background = gaussian_filter(image, self.smoothing_filter_size)/self.div_factor\n",
    "        #background.clamp_min_(1.)\n",
    "        return torch.tensor(background)\n",
    "    \n",
    "class AddPerlinNoise(TransformBase):\n",
    "    def __init__(self, shape, res, octaves, scale=1, persistence=0.5, lacunarity=2):\n",
    "        self.shape = shape\n",
    "        self.res = res\n",
    "        self.scale = scale\n",
    "        self.octaves = octaves\n",
    "        self.persistence = persistence\n",
    "        self.lacunarity = lacunarity\n",
    "    \n",
    "    def __call__(self, image, **kwargs):\n",
    "        assert all(i <= self.shape for i in image.shape[-3:])\n",
    "        bs = len(image)\n",
    "        fractal_noise = [generate_fractal_noise_3d(shape=(self.shape,self.shape,self.shape), \n",
    "                                                  res=self.res, octaves=self.octaves, \n",
    "                                                  tileable=(False, False, False), persistence=self.persistence) for _ in range(bs)]\n",
    "        fractal_noise = torch.FloatTensor(fractal_noise).to(image.device)\n",
    "        fractal_noise = fractal_noise[:,:image.shape[-3],:image.shape[-2],:image.shape[-1]]\n",
    "        return image + self.scale*fractal_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = generate_fractal_noise_3d(\n",
    "#     (48, 48, 48), (4, 8, 8), 2, tileable=(False, False, False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_roi_mask(img, pool_size=(10,10,10), percentile=50):\n",
    "    mp_img = skimage.measure.block_reduce(img, pool_size, np.max)\n",
    "    thresh = np.percentile(mp_img,percentile)\n",
    "    mp_img = np.where(mp_img>thresh,1,0)\n",
    "    mp_img = np.kron(mp_img, np.ones((pool_size), dtype=mp_img.dtype))\n",
    "    mp_img = mp_img[:img.shape[0], :img.shape[1], :img.shape[2]] \n",
    "    return mp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.funcs.file_io import load_psf_noise_micro\n",
    "from decode_fish.engine.point_process import PointProcessUniform\n",
    "from decode_fish.funcs.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = '/groups/turaga/home/speisera/share_TUM/FishSIM/sim_density_fac1_1/mRNAlevel_500/random/NR/w1_HelaKyoto_Gapdh_2597_p01_cy3__Cell_CP_10__random__1.tif'\n",
    "pdir = '/groups/turaga/home/speisera/share_TUM/FishSIM/sim_density_fac1_1/mRNAlevel_500/random/NR/w1*.tif'\n",
    "pdir = '/groups/turaga/home/speisera/share_TUM/FishSIM/sim_foci_fac1_1/mRNAlevel_500/foci/strong/w1*.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_3d        = [load_tiff_image(f)[0] for f in glob.glob(pdir)]\n",
    "smoothing      = GaussianSmoothing(smoothing_filter_size=20, div_factor=1)\n",
    "roi_masks      = [get_roi_mask(img, pool_size=(10,10,10), percentile=70) for img in imgs_3d]\n",
    "rand_crop      = RandomCrop3D((48,48,48), roi_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probmap_generator = UniformValue(0.0001, 0.0005)\n",
    "\n",
    "focifier = AddFoci(n_foci_avg=5, \n",
    "                   rad_range=(100,500), \n",
    "                   n_mol_range=(5.,30.), \n",
    "                   px_size_zyx =(100,100,100),\n",
    "                   mode='bin')\n",
    "\n",
    "fractal_noise = AddPerlinNoise(48, (3,6,6), 3, scale=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 volumes\n"
     ]
    }
   ],
   "source": [
    "ds = DecodeDataset(volumes = imgs_3d,\n",
    "                   dataset_tfms =  [rand_crop], \n",
    "                   rate_tfms = [probmap_generator, focifier], \n",
    "                   bg_tfms = [smoothing, fractal_noise], \n",
    "                   device='cuda:0', \n",
    "                   num_iter=100 * 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_dl = DataLoader(ds, batch_size=2, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_3d_projections(generate_fractal_noise_3d(shape=(48,48,48), res=(3,6,6), octaves=3, tileable=(False, False, False), persistence=.75, lacunarity=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 69, 286, 370])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/turaga/home/speisera/anaconda3/envs/decode2_dev/lib/python3.7/site-packages/torch/cuda/__init__.py:81: UserWarning: \n",
      "    Found GPU2 NVS 510 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 69, 232, 181])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 907.2x864 with 6 Axes>,\n",
       " [<AxesSubplot:ylabel='y'>,\n",
       "  <AxesSubplot:xlabel='x', ylabel='z'>,\n",
       "  <AxesSubplot:xlabel='z'>])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 907.2x864 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, local_rate, background = next(iter(decode_dl))\n",
    "plot_3d_projections(local_rate[0,0], proj_func=np.mean)\n",
    "# plot_3d_projections(x[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode2_dev]",
   "language": "python",
   "name": "conda-env-decode2_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
