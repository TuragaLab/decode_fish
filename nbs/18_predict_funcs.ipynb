{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from decode_fish.imports import *\n",
    "from decode_fish.funcs.file_io import *\n",
    "from decode_fish.funcs.emitter_io import *\n",
    "from decode_fish.funcs.utils import *\n",
    "from monai.inferers import sliding_window_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(f'../config/experiment/msp300_1.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/turaga/home/speisera/anaconda3/envs/decode2_dev/lib/python3.7/site-packages/torch/cuda/__init__.py:81: UserWarning: \n",
      "    Found GPU2 NVS 510 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop size larger than volume in at least one dimension. Crop size changed to (37, 48, 48)\n",
      "1 volumes\n"
     ]
    }
   ],
   "source": [
    "model, post_proc, micro, img_3d, decode_dl = load_all(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-portable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/datasets/CodFish/smFISH_data_Titlow/msp300_smFISH_1.tif',\n",
       " '/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/datasets/CodFish/smFISH_data_Titlow/msp300_smFISH_2.tif',\n",
       " '/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/datasets/CodFish/smFISH_data_Titlow/msp300_smFISH_3.tif',\n",
       " '/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/datasets/CodFish/smFISH_data_Titlow/msp300_smFISH_4.tif']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = sorted(glob.glob(str(Path(cfg.data_path.image_path).parent)+'/msp300*.tif'))\n",
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def predict(model, post_proc, image_paths, window_size=[128,256,256], device='cuda'):\n",
    "    \n",
    "    pred_df = DF()\n",
    "    with torch.no_grad():\n",
    "        for p in tqdm(image_paths):\n",
    "            print(p.split('/')[-1])\n",
    "            img = load_tiff_image(p)\n",
    "            z,y,x = img.shape[-3:]\n",
    "            img = img.reshape(-1,z,y,x)\n",
    "            for i in range(len(img)):\n",
    "                print(img[i][None,None].shape)\n",
    "                output = sliding_window_inference(img[i][None,None], window_size, 1, model.to(device), overlap=0.2, sw_device=device, device='cpu', mode='gaussian')\n",
    "                # output = model.cpu()(img[i][None,None])\n",
    "                output = model.tensor_to_dict(output)\n",
    "                p_si = sliding_window_inference(output['logits'], window_size, 1, post_proc, overlap=0.2, sw_device=device, device='cpu', mode='gaussian')\n",
    "                i_df = post_proc.get_df(output, p_si)\n",
    "                print('N. emitters: ', len(i_df))\n",
    "                pred_df = append_emitter_df(pred_df, i_df)\n",
    "                free_mem()\n",
    "            \n",
    "        return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-efficiency",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msp300_smFISH_1.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:18<00:55, 18.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. emitters:  63639\n",
      "msp300_smFISH_2.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:29<01:27, 29.07s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2e7dde5e8975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_proc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-1fd05d463ee8>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, post_proc, image_paths, window_size, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliding_window_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mp_si\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliding_window_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_proc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/decode2_dev/lib/python3.7/site-packages/monai/inferers/utils.py\u001b[0m in \u001b[0;36msliding_window_inference\u001b[0;34m(inputs, roi_size, sw_batch_size, predictor, overlap, mode, sigma_scale, padding_mode, cval, sw_device, device, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# store the result in the proper location of the full output. Apply weights from importance map.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munravel_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0moutput_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moriginal_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimportance_map\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mseg_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mslice_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mcount_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moriginal_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimportance_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred_df = predict(model, post_proc, image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = sliding_window_inference(img[None], [37,128,128], 1, model.cuda(), overlap=0.2, sw_device ='cuda', device='cpu', mode='gaussian')\n",
    "    output = model.tensor_to_dict(output)\n",
    "    p_si = sliding_window_inference(output['logits'], [37,128,128], 1, post_proc, overlap=0.2, sw_device ='cuda', device='cpu', mode='gaussian')\n",
    "    pred_df = post_proc.get_df(output, p_si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.cpu()\n",
    "    res = model.tensor_to_dict(model(img[None]))\n",
    "    gt_df = post_proc.get_df(res)\n",
    "    free_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gt_df))\n",
    "print(len(pred_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-force",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-retreat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode2_dev]",
   "language": "python",
   "name": "conda-env-decode2_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
