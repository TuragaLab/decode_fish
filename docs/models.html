---

title: DECODE Network


keywords: fastai
sidebar: home_sidebar

summary: "Definition of the classes and modules we use to build our 3D UNet"
description: "Definition of the classes and modules we use to build our 3D UNet"
nb_path: "nbs/00_models.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/00_models.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nbdev.showdoc</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="init_func" class="doc_header"><code>init_func</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L20" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>init_func</code>(<strong><code>m</code></strong>, <strong><code>func</code></strong>=<em><code>kaiming_normal_</code></em>)</p>
</blockquote>

<pre><code>Initialize pytorch model `m` weights with `func`</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="layer_types" class="doc_header"><code>layer_types</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L26" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>layer_types</code>(<strong><code>m</code></strong>)</p>
</blockquote>

<pre><code>returns list of pytorch models type</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="extract_layer" class="doc_header"><code>extract_layer</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L32" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>extract_layer</code>(<strong><code>m</code></strong>, <strong><code>name</code></strong>=<em><code>Conv3d</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="number_of_features_per_level" class="doc_header"><code>number_of_features_per_level</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L41" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>number_of_features_per_level</code>(<strong><code>init_channel_number</code></strong>, <strong><code>num_levels</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SingleConv" class="doc_header"><code>class</code> <code>SingleConv</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L45" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SingleConv</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>kernel_size</code></strong>=<em><code>3</code></em>, <strong><code>order</code></strong>=<em><code>'gcr'</code></em>, <strong><code>num_groups</code></strong>=<em><code>8</code></em>, <strong><code>padding</code></strong>=<em><code>1</code></em>) :: <code>Sequential</code></p>
</blockquote>

<pre><code>Basic convolutional module consisting of a Conv3d, non-linearity and optional batchnorm/groupnorm. The order
of operations can be specified via the `order` parameter
Args:
    in_channels (int): number of input channels
    out_channels (int): number of output channels
    kernel_size (int or tuple): size of the convolving kernel
    order (string): determines the order of layers, e.g.
        'cr' -&gt; conv + ReLU
        'crg' -&gt; conv + ReLU + groupnorm
        'cl' -&gt; conv + LeakyReLU
        'ce' -&gt; conv + ELU
    num_groups (int): number of groups for the GroupNorm
    padding (int or tuple):</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DoubleConv" class="doc_header"><code>class</code> <code>DoubleConv</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L69" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DoubleConv</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>encoder</code></strong>, <strong><code>kernel_size</code></strong>=<em><code>3</code></em>, <strong><code>order</code></strong>=<em><code>'gcr'</code></em>, <strong><code>num_groups</code></strong>=<em><code>8</code></em>, <strong><code>padding</code></strong>=<em><code>1</code></em>) :: <code>Sequential</code></p>
</blockquote>

<pre><code>A module consisting of two consecutive convolution layers (e.g. BatchNorm3d+ReLU+Conv3d).
We use (Conv3d+ReLU+GroupNorm3d) by default.
This can be changed however by providing the 'order' argument, e.g. in order
to change to Conv3d+BatchNorm3d+ELU use order='cbe'.
Use padded convolutions to make sure that the output (H_out, W_out) is the same
as (H_in, W_in), so that you don't have to crop in the decoder path.
Args:
    in_channels (int): number of input channels
    out_channels (int): number of output channels
    encoder (bool): if True we're in the encoder path, otherwise we're in the decoder
    kernel_size (int or tuple): size of the convolving kernel
    order (string): determines the order of layers, e.g.
        'cr' -&gt; conv + ReLU
        'crg' -&gt; conv + ReLU + groupnorm
        'cl' -&gt; conv + LeakyReLU
        'ce' -&gt; conv + ELU
    num_groups (int): number of groups for the GroupNorm
    padding (int or tuple): add zero-padding added to all three sides of the input</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Upsampling" class="doc_header"><code>class</code> <code>Upsampling</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L115" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Upsampling</code>(<strong><code>transposed_conv</code></strong>, <strong><code>in_channels</code></strong>=<em><code>None</code></em>, <strong><code>out_channels</code></strong>=<em><code>None</code></em>, <strong><code>kernel_size</code></strong>=<em><code>3</code></em>, <strong><code>scale_factor</code></strong>=<em><code>(2, 2, 2)</code></em>, <strong><code>mode</code></strong>=<em><code>'nearest'</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>Upsamples a given multi-channel 3D data using either interpolation or learned transposed convolution.
Args:
    transposed_conv (bool): if True uses ConvTranspose3d for upsampling, otherwise uses interpolation
    in_channels (int): number of input channels for transposed conv
        used only if transposed_conv is True
    out_channels (int): number of output channels for transpose conv
        used only if transposed_conv is True
    kernel_size (int or tuple): size of the convolving kernel
        used only if transposed_conv is True
    scale_factor (int or tuple): stride of the convolution
        used only if transposed_conv is True
    mode (str): algorithm used for upsampling:
        'nearest' | 'linear' | 'bilinear' | 'trilinear' | 'area'. Default: 'nearest'
        used only if transposed_conv is False</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Encoder" class="doc_header"><code>class</code> <code>Encoder</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L154" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Encoder</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>conv_kernel_size</code></strong>=<em><code>3</code></em>, <strong><code>apply_pooling</code></strong>=<em><code>True</code></em>, <strong><code>pool_kernel_size</code></strong>=<em><code>2</code></em>, <strong><code>pool_type</code></strong>=<em><code>'max'</code></em>, <strong><code>basic_module</code></strong>=<em><code>DoubleConv</code></em>, <strong><code>conv_layer_order</code></strong>=<em><code>'gcr'</code></em>, <strong><code>num_groups</code></strong>=<em><code>8</code></em>, <strong><code>padding</code></strong>=<em><code>1</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>A single module from the encoder path consisting of the optional max
pooling layer (one may specify the MaxPool kernel_size to be different
than the standard (2,2,2), e.g. if the volumetric data is anisotropic
(make sure to use complementary scale_factor in the decoder path) followed by
a DoubleConv module.
Args:
    in_channels (int): number of input channels
    out_channels (int): number of output channels
    conv_kernel_size (int or tuple): size of the convolving kernel
    apply_pooling (bool): if True use MaxPool3d before DoubleConv
    pool_kernel_size (int or tuple): the size of the window
    pool_type (str): pooling layer: 'max' or 'avg'
    basic_module(nn.Module): either ResNetBlock or DoubleConv
    conv_layer_order (string): determines the order of layers
        in `DoubleConv` module. See `DoubleConv` for more info.
    num_groups (int): number of groups for the GroupNorm
    padding (int or tuple): add zero-padding added to all three sides of the input</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Decoder" class="doc_header"><code>class</code> <code>Decoder</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L202" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Decoder</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>conv_kernel_size</code></strong>=<em><code>3</code></em>, <strong><code>scale_factor</code></strong>=<em><code>(2, 2, 2)</code></em>, <strong><code>basic_module</code></strong>=<em><code>DoubleConv</code></em>, <strong><code>conv_layer_order</code></strong>=<em><code>'gcr'</code></em>, <strong><code>num_groups</code></strong>=<em><code>8</code></em>, <strong><code>mode</code></strong>=<em><code>'nearest'</code></em>, <strong><code>padding</code></strong>=<em><code>1</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>A single module for decoder path consisting of the upsampling layer
(either learned ConvTranspose3d or nearest neighbor interpolation) followed by a basic module (DoubleConv or ExtResNetBlock).
Args:
    in_channels (int): number of input channels
    out_channels (int): number of output channels
    conv_kernel_size (int or tuple): size of the convolving kernel
    scale_factor (tuple): used as the multiplier for the image H/W/D in
        case of nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation
        from the corresponding encoder
    basic_module(nn.Module): either ResNetBlock or DoubleConv
    conv_layer_order (string): determines the order of layers
        in `DoubleConv` module. See `DoubleConv` for more info.
    num_groups (int): number of groups for the GroupNorm
    padding (int or tuple): add zero-padding added to all three sides of the input</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="conv3d" class="doc_header"><code>conv3d</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L259" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>conv3d</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>kernel_size</code></strong>, <strong><code>bias</code></strong>, <strong><code>padding</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="create_conv" class="doc_header"><code>create_conv</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L262" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>create_conv</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>kernel_size</code></strong>, <strong><code>order</code></strong>, <strong><code>num_groups</code></strong>, <strong><code>padding</code></strong>)</p>
</blockquote>

<pre><code>Create a list of modules with together constitute a single conv layer with non-linearity
and optional batchnorm/groupnorm.
Args:
    in_channels (int): number of input channels
    out_channels (int): number of output channels
    kernel_size(int or tuple): size of the convolving kernel
    order (string): order of things, e.g.
        'cr' -&gt; conv + ReLU
        'gcr' -&gt; groupnorm + conv + ReLU
        'cl' -&gt; conv + LeakyReLU
        'ce' -&gt; conv + ELU
        'bcr' -&gt; batchnorm + conv + ReLU
    num_groups (int): number of groups for the GroupNorm
    padding (int or tuple): add zero-padding added to all three sides of the input
Return:
    list of tuple (name, module)</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Abstract3DUNet" class="doc_header"><code>class</code> <code>Abstract3DUNet</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L321" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Abstract3DUNet</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>final_sigmoid</code></strong>, <strong><code>basic_module</code></strong>, <strong><code>f_maps</code></strong>=<em><code>64</code></em>, <strong><code>layer_order</code></strong>=<em><code>'gcr'</code></em>, <strong><code>num_groups</code></strong>=<em><code>8</code></em>, <strong><code>num_levels</code></strong>=<em><code>4</code></em>, <strong><code>is_segmentation</code></strong>=<em><code>True</code></em>, <strong><code>testing</code></strong>=<em><code>False</code></em>, <strong><code>conv_kernel_size</code></strong>=<em><code>3</code></em>, <strong><code>pool_kernel_size</code></strong>=<em><code>2</code></em>, <strong><code>conv_padding</code></strong>=<em><code>1</code></em>, <strong><code>inp_scale</code></strong>=<em><code>1</code></em>, <strong><code>inp_offset</code></strong>=<em><code>0</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>

<pre><code>Base class for standard and residual UNet.
Args:
    in_channels (int): number of input channels
    out_channels (int): number of output segmentation masks;
        Note that that the of out_channels might correspond to either
        different semantic classes or to different binary segmentation mask.
        It's up to the user of the class to interpret the out_channels and
        use the proper loss criterion during training (i.e. CrossEntropyLoss (multi-class)
        or BCEWithLogitsLoss (two-class) respectively)
    f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number
        of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4
    final_sigmoid (bool): if True apply element-wise nn.Sigmoid after the
        final 1x1 convolution, otherwise apply nn.Softmax. MUST be True if nn.BCELoss (two-class) is used
        to train the model. MUST be False if nn.CrossEntropyLoss (multi-class) is used to train the model.
    basic_module: basic model for the encoder/decoder (DoubleConv, ExtResNetBlock, ....)
    layer_order (string): determines the order of layers
        in `SingleConv` module. e.g. 'crg' stands for Conv3d+ReLU+GroupNorm3d.
        See `SingleConv` for more info
    f_maps (int, tuple): if int: number of feature maps in the first conv layer of the encoder (default: 64);
        if tuple: number of feature maps at each level
    num_groups (int): number of groups for the GroupNorm
    num_levels (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)
    is_segmentation (bool): if True (semantic segmentation problem) Sigmoid/Softmax normalization is applied
        after the final convolution; if False (regression problem) the normalization layer is skipped at the end
    testing (bool): if True (testing mode) the `final_activation` (if present, i.e. `is_segmentation=true`)
        will be applied as the last operation during the forward pass; if False the model is in training mode
        and the `final_activation` (even if present) won't be applied; default: False
    conv_kernel_size (int or tuple): size of the convolving kernel in the basic_module
    pool_kernel_size (int or tuple): the size of the window
    conv_padding (int or tuple): add zero-padding added to all three sides of the input</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UNet3D" class="doc_header"><code>class</code> <code>UNet3D</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L457" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UNet3D</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>final_sigmoid</code></strong>=<em><code>True</code></em>, <strong><code>f_maps</code></strong>=<em><code>64</code></em>, <strong><code>layer_order</code></strong>=<em><code>'gcr'</code></em>, <strong><code>num_groups</code></strong>=<em><code>8</code></em>, <strong><code>num_levels</code></strong>=<em><code>4</code></em>, <strong><code>is_segmentation</code></strong>=<em><code>True</code></em>, <strong><code>conv_padding</code></strong>=<em><code>1</code></em>, <strong><code>inp_scale</code></strong>=<em><code>1</code></em>, <strong><code>inp_offset</code></strong>=<em><code>0</code></em>, <strong>**<code>kwargs</code></strong>) :: <a href="/decode_fish/models.html#Abstract3DUNet"><code>Abstract3DUNet</code></a></p>
</blockquote>

<pre><code>3DUnet model from
`"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation"
    &lt;https://arxiv.org/pdf/1606.06650.pdf&gt;`.
Uses `DoubleConv` as a basic_module and nearest neighbor upsampling in the decoder</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UnetDecodeNoBn" class="doc_header"><code>class</code> <code>UnetDecodeNoBn</code><a href="https://github.com/TuragaLab/decode_fish/tree/master/decode_fish/engine/model.py#L473" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UnetDecodeNoBn</code>(<strong><code>ch_in</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>ch_out</code></strong>:<code>int</code>=<em><code>10</code></em>, <strong><code>final_sigmoid</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>depth</code></strong>:<code>int</code>=<em><code>3</code></em>, <strong><code>inp_scale</code></strong>:<code>float</code>=<em><code>1.0</code></em>, <strong><code>inp_offset</code></strong>:<code>float</code>=<em><code>0.0</code></em>, <strong><code>order</code></strong>=<em><code>'bcr'</code></em>, <strong><code>f_maps</code></strong>=<em><code>64</code></em>, <strong><code>p_offset</code></strong>=<em><code>-5.0</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>Base class for all neural network modules.

Your models should also subclass this class.

Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::

    import torch.nn as nn
    import torch.nn.functional as F

    class Model(nn.Module):
        def __init__(self):
            super(Model, self).__init__()
            self.conv1 = nn.Conv2d(1, 20, 5)
            self.conv2 = nn.Conv2d(20, 20, 5)

        def forward(self, x):
            x = F.relu(self.conv1(x))
            return F.relu(self.conv2(x))

Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:`to`, etc.

:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">UnetDecodeNoBn</span><span class="p">(</span><span class="n">order</span><span class="o">=</span> <span class="s1">&#39;ce&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">]))</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>dict_keys([&#39;logits&#39;, &#39;xyzi_mu&#39;, &#39;xyzi_sigma&#39;, &#39;background&#39;])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>nbdev_build_lib
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Converted 00_models.ipynb.
Converted index.ipynb.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

