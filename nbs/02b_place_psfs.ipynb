{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp engine.place_psfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSF placement function\n",
    "\n",
    "> Belongs to the microscope forward function, but given that I use custom cuda functions it deserves its own Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch.jit import script\n",
    "import numba\n",
    "from numba import cuda\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=numba.errors.NumbaPerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@cuda.jit\n",
    "def place_roi(frames: torch.float32, roi_grads: torch.float32, frame_s_b: int, frame_s_c: int, frame_s_z: int, frame_s_y: int, frame_s_x: int, rois: torch.float32, \n",
    "              roi_s_n: int, roi_s_z: int, roi_s_y: int, roi_s_x: int, b: torch.int64, c: torch.int64, z: torch.int64, y: torch.int64, x: torch.int64):\n",
    "    \n",
    "    kx = cuda.grid(1)\n",
    "    # One thread for every pixel in the roi stack. Exit if outside\n",
    "    if kx >= roi_s_n * roi_s_z * roi_s_y * roi_s_x: \n",
    "        return\n",
    "    \n",
    "    # roi index\n",
    "    xir = kx % roi_s_x; kx = kx // roi_s_x\n",
    "    yir = kx % roi_s_y; kx = kx // roi_s_y\n",
    "    zir = kx % roi_s_z; kx = kx // roi_s_z\n",
    "    nir = kx % roi_s_n \n",
    "    \n",
    "    # frame index\n",
    "    bif = b[nir]\n",
    "    cif = c[nir]\n",
    "    zif = z[nir] + zir\n",
    "    yif = y[nir] + yir\n",
    "    xif = x[nir] + xir\n",
    "    \n",
    "    if ((bif < 0) or (bif >= frame_s_b)): return\n",
    "    if ((cif < 0) or (cif >= frame_s_c)): return\n",
    "    if ((zif < 0) or (zif >= frame_s_z)): return\n",
    "    if ((yif < 0) or (yif >= frame_s_y)): return\n",
    "    if ((xif < 0) or (xif >= frame_s_x)): return\n",
    "    \n",
    "    cuda.atomic.add(frames, (bif, cif, zif, yif, xif), rois[nir, zir, yir, xir])\n",
    "    # The gradients for the ROIs are just one if they are inside the frames and 0 otherwise. Easy to do here and then just ship to the backward function\n",
    "    roi_grads[nir, zir, yir, xir] = 1\n",
    "    # Alternative to atomic.add. No difference in speed\n",
    "#     frames[bif, cif, zif, yif, xif] += rois[nir, zir, yir, xir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\"\"\"THIS FUNCTION BREAKS AUTORELOAD FOR SOME REASON? https://discuss.pytorch.org/t/class-autograd-function-in-module-cause-autoreload-fail-in-jupyter-lab/96250/2\"\"\"\n",
    "class CudaPlaceROI(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, rois, frame_s_b, frame_s_c, frame_s_z, frame_s_y, frame_s_x, roi_s_n, roi_s_z, roi_s_y, roi_s_x, b, c, z, y, x):\n",
    "\n",
    "        frames = torch.zeros([frame_s_b, frame_s_c, frame_s_z, frame_s_y, frame_s_x]).to('cuda')\n",
    "        rois_grads = torch.zeros([roi_s_n, roi_s_z, roi_s_y, roi_s_x]).to('cuda')\n",
    "        \n",
    "        threadsperblock = 256\n",
    "        blocks = ((roi_s_n * roi_s_z * roi_s_y * roi_s_x) + (threadsperblock - 1)) // threadsperblock\n",
    "\n",
    "        place_roi[blocks, threadsperblock](frames, rois_grads, frame_s_b, frame_s_c, frame_s_z, frame_s_y, frame_s_x, rois.detach(), roi_s_n, roi_s_z, roi_s_y, roi_s_x, b, c, z, y, x)\n",
    "        \n",
    "        ctx.save_for_backward(rois_grads)\n",
    "        \n",
    "        return frames\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        rois_grads, = ctx.saved_tensors\n",
    "        return rois_grads, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@script\n",
    "def _place_psf(psf_vols, b, ch, z, y, x, output_shape):\n",
    "    \n",
    "    \"\"\"jit function for placing PSFs\n",
    "    1) This function will add padding to coordinates (z, y, x) (we need padding in order to place psf on the edges)\n",
    "    afterwards we will just crop out to original shape\n",
    "    2) Create empty tensor with paddings loc3d_like\n",
    "    3) place each individual PSFs in to the corresponding cordinates in loc3d_like\n",
    "    4) unpad to original output shape\n",
    "\n",
    "    Args:\n",
    "        psf_vols:   torch.Tensor\n",
    "        b:        torch.Tensor\n",
    "        c:        torch.Tensor\n",
    "        h:        torch.Tensor\n",
    "        w:        torch.Tensor\n",
    "        d:        torch.Tensor\n",
    "        szs:      torch.Tensor\n",
    "        \n",
    "    Shape:\n",
    "        psf_vols: (Num_E, C, PSF_SZ_X, PSF_SZ_Y, PSF_SZ_Z)\n",
    "        b:  (Num_E,)\n",
    "        c:  (Num_E,)\n",
    "        h:  (Num_E,)\n",
    "        w:  (Num_E,)\n",
    "        d:  (Num_E,)\n",
    "        output_shape:  (BS, Frames, H, W, D)\n",
    "        \n",
    "    -Output: placed_psf: (BS, Frames, H, W, D)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    psf_b, psf_c, psf_d, psf_h, psf_w = psf_vols.shape\n",
    "    pad_zyx = [psf_d//2, psf_h//2, psf_w//2]\n",
    "    #add padding to z, y, x \n",
    "    \n",
    "    z = z + pad_zyx[0]\n",
    "    y = y + pad_zyx[1]\n",
    "    x = x + pad_zyx[2]\n",
    "\n",
    "    #create padded tensor (bs, frame, c, h, w) We will need pad_size * 2 since we are padding from both size\n",
    "    loc3d_like = torch.zeros(output_shape[0], \n",
    "                             output_shape[1], \n",
    "                             output_shape[2] + 2*(pad_zyx[0]), \n",
    "                             output_shape[3] + 2*(pad_zyx[1]), \n",
    "                             output_shape[4] + 2*(pad_zyx[2])).to(x.device)\n",
    "    \n",
    "    if psf_c == 2:\n",
    "        psf_ch_ind = torch.where(ch >= 8, 1, 0)\n",
    "        psf_vols = psf_vols[torch.arange(len(psf_ch_ind)),psf_ch_ind]\n",
    "    if output_shape[1] == 1:\n",
    "        ch = torch.zeros_like(ch)\n",
    "        \n",
    "    psf_vols = psf_vols.reshape(-1, psf_d, psf_h, psf_w)\n",
    "    \n",
    "    # Take limit calculation out of the loop for 30% speed up\n",
    "    z_l = z - pad_zyx[0]\n",
    "    y_l = y - pad_zyx[1]\n",
    "    x_l = x - pad_zyx[2]\n",
    "    \n",
    "    z_h = z + pad_zyx[0] + 1\n",
    "    y_h = y + pad_zyx[1] + 1\n",
    "    x_h = x + pad_zyx[2] + 1\n",
    "    \n",
    "    for idx in range(x.shape[0]):\n",
    "        loc3d_like[b[idx], ch[idx],\n",
    "        z_l[idx] : z_h[idx],\n",
    "        y_l[idx] : y_h[idx],\n",
    "        x_l[idx] : x_h[idx]] += psf_vols[idx]\n",
    "\n",
    "    # unpad to original size\n",
    "    b_sz, ch_sz, h_sz, w_sz, d_sz = loc3d_like.shape\n",
    "    \n",
    "    placed_psf = loc3d_like[:, :, pad_zyx[0]: h_sz - pad_zyx[0],\n",
    "                                  pad_zyx[1]: w_sz - pad_zyx[1],\n",
    "                                  pad_zyx[2]: d_sz - pad_zyx[2]]\n",
    "    return placed_psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_psfs = 1000\n",
    "psf_size = (5,11,11)\n",
    "output_shape = [5,22,11,40,40]\n",
    "\n",
    "psf_vals = torch.randn(size=[N_psfs,psf_size[0],psf_size[1],psf_size[2]])\n",
    "psfs_cu = torch.autograd.Variable(psf_vals.to('cuda'), requires_grad=True)\n",
    "psfs_py = torch.autograd.Variable(psf_vals.to('cuda'), requires_grad=True)\n",
    "psf_grad = torch.zeros(psf_vals.shape).to('cuda')\n",
    "b = torch.randint(0, output_shape[0], size=[N_psfs]).to('cuda')\n",
    "c = torch.randint(0, output_shape[1], size=[N_psfs]).to('cuda')\n",
    "z = torch.randint(0, output_shape[2], size=[N_psfs]).to('cuda')\n",
    "y = torch.randint(0, output_shape[3], size=[N_psfs]).to('cuda')\n",
    "x = torch.randint(0, output_shape[4], size=[N_psfs]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_cuda = CudaPlaceROI.apply(psfs_cu, output_shape[0], output_shape[1], output_shape[2], output_shape[3], output_shape[4], N_psfs, psf_size[0], psf_size[1], psf_size[2], b, c, z-psf_size[0]//2, y-psf_size[1]//2, x-psf_size[2]//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_py = _place_psf(psfs_py[:,None], b, c, z, y, x, torch.tensor(output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(cpu(frames_cuda), cpu(frames_py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_cuda.sum().backward()\n",
    "frames_py.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(cpu(psfs_cu.grad), cpu(psfs_py.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.96 ms ± 200 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "frames_cuda = CudaPlaceROI.apply(psfs_cu, output_shape[0], output_shape[1], output_shape[2], output_shape[3], output_shape[4], N_psfs, psf_size[0], psf_size[1], psf_size[2], b, c, z-psf_size[0]//2, y-psf_size[1]//2, x-psf_size[2]//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 ms ± 2.51 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "frames_py = _place_psf(psfs_py[:,None], b, c, z, y, x, torch.tensor(output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted 25_ensembling.ipynb.\n",
      "Converted 26_gen_train.ipynb.\n",
      "Converted 27_testtime_rescale.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode_fish_dev2]",
   "language": "python",
   "name": "conda-env-decode_fish_dev2-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
