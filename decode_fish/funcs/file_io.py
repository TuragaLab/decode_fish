# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/07_file_io.ipynb (unless otherwise specified).

__all__ = ['load_model_state', 'swap_psf_vol', 'get_gaussian_psf', 'get_vol_psf', 'load_psf', 'load_psf_noise_micro',
           'load_post_proc', 'get_dataloader', 'load_all']

# Cell
from ..imports import *
from .utils import *
from tifffile import imread
from ..engine.microscope import Microscope
from ..engine.psf import crop_psf
from ..engine.psf import LinearInterpolatedPSF
from .emitter_io import *
from .dataset import *
from torch.utils.data import DataLoader
from collections.abc import MutableSequence

# Cell
def load_model_state(model, path):
    """
    Loads the network parameters, the intensity parameters and the scaling into model given a path.
    """
    model_dict = torch.load(path)
    model.load_state_dict(model_dict['state_dict'])
    model.inp_scale = model_dict['scaling'][0]
    model.inp_offset = model_dict['scaling'][1]
    return model

# Cell
def swap_psf_vol(psf, vol):
    state_dict = psf.state_dict()
    if len(vol) == 1:
        for i in range(len(state_dict['psf_volume'])):
            state_dict['psf_volume'][i] = torch.cuda.FloatTensor(torch.Tensor(vol).cuda())
    else:
        state_dict['psf_volume'] = torch.cuda.FloatTensor(torch.Tensor(vol).cuda())
    psf.load_state_dict(state_dict)
    return psf

def get_gaussian_psf(size_zyx, radii, pred_z, n_cols=1):

    if not pred_z:
        size_zyx[0] = 1

    if not isinstance(radii, MutableSequence):
        radii = 3*[radii]

    psf = LinearInterpolatedPSF(size_zyx, device='cuda', n_cols=n_cols)
    gauss_vol = gaussian_sphere(size_zyx, radii, [size_zyx[0]//2,size_zyx[1]//2,size_zyx[2]//2])
    gauss_vol = gauss_vol/gauss_vol.max()

    psf = swap_psf_vol(psf, gauss_vol)
    return psf

def get_vol_psf(filename, device='cuda', psf_extent_zyx=None, n_cols=1):

    if 'tif' in filename:
        psf_vol = load_tiff_image(filename)
        psf_vol = psf_vol/psf_vol.max()
        psf = LinearInterpolatedPSF(psf_vol.shape[-3:], device=device, n_cols=n_cols)
        if psf_vol.ndim == 3: psf_vol = psf_vol[None]
        psf = swap_psf_vol(psf, psf_vol)

    else:
        psf_state = torch.load(filename)
        psf = LinearInterpolatedPSF(psf_state['psf_volume'].shape[-3:], device=device, n_cols=n_cols)
        psf.load_state_dict(psf_state)

        if psf_extent_zyx:
            psf = crop_psf(psf,psf_extent_zyx)

    return psf

def load_psf(cfg):

    if cfg.data_path.psf_path:
        psf = get_vol_psf(cfg.data_path.psf_path,cfg.genm.PSF.device, cfg.genm.PSF.psf_extent_zyx, cfg.genm.PSF.n_cols)
    else:
        psf = get_gaussian_psf(cfg.genm.PSF.psf_extent_zyx, cfg.genm.PSF.gauss_radii, cfg.genm.exp_type.pred_z, cfg.genm.PSF.n_cols)

    return psf

def load_psf_noise_micro(cfg):

    psf = load_psf(cfg)
    noise = hydra.utils.instantiate(cfg.genm.noise)
    micro = hydra.utils.instantiate(cfg.genm.microscope, psf=psf, noise=noise).cuda()

    return psf, noise, micro

def load_post_proc(cfg):
    if cfg.other.pp == 'si':
        return hydra.utils.instantiate(cfg.post_proc_si)
    if cfg.other.pp == 'isi':
        return hydra.utils.instantiate(cfg.post_proc_isi)

def get_dataloader(cfg):

    sim = True if cfg.data_path.image_path is None else False
    sl = eval(cfg.data_path.image_proc.crop_sl,{'__builtins__': None},{'s_': np.s_})

    if not sim:
        if 'override' in cfg.data_path.image_proc:
            imgs_5d = torch.cat([hydra.utils.instantiate(cfg.data_path.image_proc.override, image_path=f) for f in sorted(glob.glob(cfg.data_path.image_path))], 0)
        else:
            imgs_5d   = torch.cat([load_tiff_image(f)[None] for f in sorted(glob.glob(cfg.data_path.image_path))], 0)

        imgs_5d       = torch.cat([img.permute(*cfg.data_path.image_proc.swap_dim)[sl][None] for img in imgs_5d], 0)
        roi_masks     = [get_roi_mask(img, tuple(cfg.sim.roi_mask.pool_size), percentile= cfg.sim.roi_mask.percentile) for img in imgs_5d]
    else:
        imgs_5d       = torch.cat([torch.empty(list(cfg.data_path.image_shape))], 0)
        roi_masks     = None
        gen_bg        = [hydra.utils.instantiate(cfg.sim.bg_estimation.uniform)]
        dataset_tfms  = []

    min_shape = tuple(np.stack([v.shape for v in imgs_5d]).min(0)[-3:])
    crop_zyx = (cfg.sim.random_crop.crop_sz, cfg.sim.random_crop.crop_sz,cfg.sim.random_crop.crop_sz)
    if crop_zyx > min_shape:
        crop_zyx = tuple(np.stack([min_shape, crop_zyx]).min(0))
        print('Crop size larger than volume in at least one dimension. Crop size changed to', crop_zyx)

    if not sim:
        gen_bg        = [hydra.utils.instantiate(cfg.sim.bg_estimation.smoothing, z_size=crop_zyx[0])]
        rand_crop = RandomCrop3D(crop_zyx, roi_masks)
        dataset_tfms  = [rand_crop]

    if cfg.sim.bg_estimation.fractal.scale:
        gen_bg.append(hydra.utils.instantiate(cfg.sim.bg_estimation.fractal))

    probmap_generator = UniformValue(cfg.genm.prob_generator.low, cfg.genm.prob_generator.high)
    rate_tfms = [probmap_generator]

    if cfg.genm.foci.n_foci_avg > 0:
        rate_tfms.append(hydra.utils.instantiate(cfg.genm.foci))

    ds = DecodeDataset(volumes = imgs_5d,
                       dataset_tfms =  dataset_tfms,
                       rate_tfms = rate_tfms,
                       bg_tfms = gen_bg,
                       device='cuda:0',
                       num_iter=(cfg.training.num_iters) * cfg.training.bs)

    decode_dl = DataLoader(ds, batch_size=cfg.training.bs, num_workers=0)

    return imgs_5d, decode_dl

def load_all(cfg):

    path = Path(cfg.output.save_dir)
    model = hydra.utils.instantiate(cfg.network)
    model = load_model_state(model, path/'model.pkl')
    post_proc = hydra.utils.instantiate(cfg.post_proc_isi, samp_threshold=0.5)
    _, noise, micro = load_psf_noise_micro(cfg)
    micro.load_state_dict(torch.load(path/'microscope.pkl'))
    imgs_5d, decode_dl = get_dataloader(cfg)

    return model, post_proc, micro, imgs_5d, decode_dl