{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from decode_fish.funcs.output_trafo import SIPostProcess\n",
    "from scipy.spatial.distance import cdist\n",
    "from  decode_fish.funcs.emitter_io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def matching(target_df, pred_df, tolerance=500, print_res=True, eff_const=0.5):\n",
    "    \"\"\"Matches localizations to ground truth positions and provides assessment metrics used in the SMLM2016 challenge. \n",
    "    (see http://bigwww.epfl.ch/smlm/challenge2016/index.html?p=methods#6)\n",
    "    When using default parameters exactly reproduces the procedure used for the challenge (i.e. produces same numbers as the localization tool). \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_csv: str or list\n",
    "        Ground truth positions with columns: 'localization', 'frame', 'x', 'y', 'z'\n",
    "        Either list or str with locations of csv file. \n",
    "    pred_inp: list\n",
    "        List of localizations\n",
    "    size_xy: list of floats\n",
    "        Size of processed recording in nano meters\n",
    "    tolerance: float\n",
    "        Localizations are matched when they are within a circle of the given radius. \n",
    "    tolerance_ax: float\n",
    "        Localizations are matched when they are closer than this value in z direction. Should be ininity for 2D recordings. 500nm is used for 3D recordings in the challenge.\n",
    "    border: float\n",
    "        Localizations that are close to the edge of the recording are excluded because they often suffer from artifacts. \n",
    "    print_res: bool\n",
    "        If true prints a list of assessment metrics.\n",
    "    min_int: bool\n",
    "        If true only uses the brightest 75% of ground truth locations. \n",
    "        This is the setting used in the leaderboard of the challenge. However this implementation does not exactly match the method used in the localization tool.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    perf_dict, matches: dict, list\n",
    "        Dictionary of perfomance metrics.\n",
    "        List of all matches localizations for further evaluation in format: 'localization', 'frame', 'x_true', 'y_true', 'z_true', 'x_pred', 'y_pred', 'z_pred', 'int_true', 'x_sig', 'y_sig', 'z_sig'\n",
    "        \n",
    "    \"\"\"          \n",
    "\n",
    "    perf_dict = None\n",
    "    match_df = pd.DataFrame()\n",
    "    TP = 0\n",
    "    FP = 0.0001\n",
    "    FN = 0.0001\n",
    "    MSE_vol = 0\n",
    "    \n",
    "    match_list = []\n",
    "    \n",
    "    tar_cols = ['loc_idx', 'frame_idx', 'x', 'y', 'z', 'int']\n",
    "    pred_cols = ['loc_idx', 'prob', 'x', 'y', 'z', 'int','x_sig', 'y_sig', 'z_sig', 'int_sig']\n",
    "    \n",
    "    if len(pred_df):\n",
    "\n",
    "        for i in range(0, pred_df['frame_idx'].max() + 1):\n",
    "\n",
    "            FC = 0\n",
    "            sub_tar = target_df[target_df['frame_idx']==i].reset_index()\n",
    "            sub_pred = pred_df[pred_df['frame_idx']==i].reset_index()\n",
    "            tar_xyz = sub_tar[['x','y','z']]\n",
    "            pred_xyz = sub_pred[['x','y','z']]\n",
    "\n",
    "            dist_arr = cdist(tar_xyz,pred_xyz)\n",
    "            \n",
    "            if dist_arr.size > 0:\n",
    "                r, c = np.unravel_index(dist_arr.argmin(), dist_arr.shape)\n",
    "\n",
    "                while dist_arr[r,c] < tolerance:\n",
    "\n",
    "                    MSE_vol += dist_arr[r, c] ** 2 \n",
    "                    TP += 1\n",
    "                    FC += 1\n",
    "                    \n",
    "                    match_list.append(list(sub_tar.loc[r,tar_cols].values) + list(sub_pred.loc[c,pred_cols].values))\n",
    "\n",
    "                    dist_arr[r, :] = np.inf\n",
    "                    dist_arr[:, c] = np.inf\n",
    "        \n",
    "                    r, c = np.unravel_index(dist_arr.argmin(), dist_arr.shape)\n",
    "\n",
    "            FP += len(pred_xyz) - FC\n",
    "            FN += len(tar_xyz) - FC\n",
    "            \n",
    "    match_df = pd.DataFrame(match_list, columns = ['tar_idx', 'frame_idx', 'x_tar', 'y_tar', 'z_tar', 'int_tar',\n",
    "                                                   'pred_idx','prob_pred', 'x_pred','y_pred','z_pred','int_pred','x_sig_pred','y_sig_pred','z_sig_pred','int_sig_pred'])\n",
    "    \n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    jaccard = TP / (TP + FP + FN)\n",
    "    \n",
    "    rmse_vol = np.sqrt(MSE_vol / (TP + 0.00001))\n",
    "\n",
    "    eff_3d = 100-np.sqrt((100-100*jaccard)**2 + eff_const**2 * rmse_vol**2)\n",
    "\n",
    "    rmse_x = np.nan\n",
    "    rmse_y = np.nan\n",
    "    rmse_z = np.nan\n",
    "    \n",
    "    x_s = np.nan\n",
    "    y_s = np.nan\n",
    "    z_s = np.nan\n",
    "    \n",
    "    if len(match_df):\n",
    "        rmse_x = np.sqrt(((match_df['x_tar']-match_df['x_pred'])**2).mean())\n",
    "        rmse_y = np.sqrt(((match_df['y_tar']-match_df['y_pred'])**2).mean())\n",
    "        rmse_z = np.sqrt(((match_df['z_tar']-match_df['z_pred'])**2).mean())\n",
    "        \n",
    "        x_s = (match_df['x_tar']-match_df['x_pred']).mean()\n",
    "        y_s = (match_df['y_tar']-match_df['y_pred']).mean()\n",
    "        z_s = (match_df['z_tar']-match_df['z_pred']).mean()\n",
    "\n",
    "    if print_res:\n",
    "        print('{}{:0.3f}'.format('Recall: ', recall))\n",
    "        print('{}{:0.3f}'.format('Precision: ', precision))\n",
    "        print('{}{:0.3f}'.format('Jaccard: ', 100 * jaccard))\n",
    "        print('{}{:0.3f}'.format('RMSE_vol: ', rmse_vol))\n",
    "        print('{}{:0.3f}'.format('Eff_3d: ', eff_3d))\n",
    "        print('FN: ' + str(np.round(FN)) + ' FP: ' + str(np.round(FP)))\n",
    "        \n",
    "        print(f'Shift: {x_s:.2f},{y_s:.2f},{z_s:.2f}')\n",
    "\n",
    "    perf_dict = {'recall': recall, 'precision': precision, 'jaccard': jaccard, 'rmse_vol': rmse_vol, \n",
    "            'rmse_x': rmse_x, 'rmse_y': rmse_y,  'rmse_z': rmse_z, 'eff_3d': eff_3d}\n",
    "                \n",
    "    return perf_dict, match_df, [x_s,y_s,z_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '/groups/turaga/home/speisera/share_TUM/FishSIM/sim_density_fac1_2/'\n",
    "from decode_fish.funcs.file_io import load_sim_fish\n",
    "img, gt_df, fq_nog_df, fq_gmm_df = load_sim_fish(basedir, 2000, 'random', 'NR', 0)\n",
    "# model_out = torch.load('../data/model_output.pt')\n",
    "# model_preds = SIPostProcpx_size_zyx=size=[100, 100, 300]).forward(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.717\n",
      "Precision: 0.933\n",
      "Jaccard: 68.175\n",
      "RMSE_vol: 132.084\n",
      "Eff_3d: 26.690\n",
      "FN: 381.0 FP: 69.0\n",
      "Shift: 4.83,5.59,8.72\n"
     ]
    }
   ],
   "source": [
    "# preds = fq_gmm_df\n",
    "\n",
    "perf_df, matches, _ = matching(gt_df, fq_gmm_df, tolerance=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.958\n",
      "Precision: 0.974\n",
      "Jaccard: 93.388\n",
      "RMSE_vol: 116.393\n",
      "Eff_3d: 41.429\n",
      "FN: 10.0 FP: 6.0\n",
      "Shift: -32.13,-32.89,-98.43\n"
     ]
    }
   ],
   "source": [
    "preds = fq_gmm_df\n",
    "perf_df, matches, _ = matching(gt_df, preds, tolerance=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode2_dev]",
   "language": "python",
   "name": "conda-env-decode2_dev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
