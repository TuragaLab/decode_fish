{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp engine.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECODE Network\n",
    "\n",
    "> Definition of the classes and modules we use to build our DECODE network\n",
    "\n",
    "ToDo: Lots of bloat. Different normalizations aren't needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "import torch.nn as nn\n",
    "import types\n",
    "from functools import partial\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def number_of_features_per_level(init_channel_number, num_levels):\n",
    "    return [init_channel_number * 2 ** k for k in range(num_levels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding):\n",
    "    \"\"\"\n",
    "    Create a list of modules with together constitute a single conv layer with non-linearity\n",
    "    and optional batchnorm/groupnorm.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size(int or tuple): size of the convolving kernel\n",
    "        order (string): order of things, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'gcr' -> groupnorm + conv + ReLU\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "            'bcr' -> batchnorm + conv + ReLU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    Return:\n",
    "        list of tuple (name, module)\n",
    "    \"\"\"\n",
    "    assert 'c' in order, \"Conv layer MUST be present\"\n",
    "    assert order[0] not in 'rle', 'Non-linearity cannot be the first operation in the layer'\n",
    "\n",
    "    modules = []\n",
    "    for i, char in enumerate(order):\n",
    "        if char == 'r':\n",
    "            modules.append(('ReLU', nn.ReLU(inplace=True)))\n",
    "        elif char == 'l':\n",
    "            modules.append(('LeakyReLU', nn.LeakyReLU(negative_slope=0.1, inplace=True)))\n",
    "        elif char == 'e':\n",
    "            modules.append(('ELU', nn.ELU(inplace=True)))\n",
    "        elif char == 'c':\n",
    "            # add learnable bias only in the absence of batchnorm/groupnorm\n",
    "            bias = not ('g' in order or 'b' in order)\n",
    "            modules.append(('conv', nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding, bias=bias, padding_mode='replicate')))\n",
    "        elif char == 'g':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                num_channels = in_channels\n",
    "            else:\n",
    "                num_channels = out_channels\n",
    "\n",
    "            # use only one group if the given number of groups is greater than the number of channels\n",
    "            if num_channels < num_groups:\n",
    "                num_groups = 1\n",
    "\n",
    "            assert num_channels % num_groups == 0, f'Expected number of channels in input to be divisible by num_groups. num_channels={num_channels}, num_groups={num_groups}'\n",
    "            modules.append(('groupnorm', nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)))\n",
    "        elif char == 'b':\n",
    "            is_before_conv = i < order.index('c')\n",
    "            if is_before_conv:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(in_channels)))\n",
    "            else:\n",
    "                modules.append(('batchnorm', nn.BatchNorm3d(out_channels)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported layer type '{char}'. MUST be one of ['b', 'g', 'r', 'l', 'e', 'c']\")\n",
    "\n",
    "    return modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SingleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Basic convolutional module consisting of a Conv3d, non-linearity and optional batchnorm/groupnorm. The order\n",
    "    of operations can be specified via the `order` parameter\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple):\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
    "        super(SingleConv, self).__init__()\n",
    "\n",
    "        for name, module in create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding=padding):\n",
    "            self.add_module(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DoubleConv(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A module consisting of two consecutive convolution layers (e.g. BatchNorm3d+ReLU+Conv3d).\n",
    "    We use (Conv3d+ReLU+GroupNorm3d) by default.\n",
    "    This can be changed however by providing the 'order' argument, e.g. in order\n",
    "    to change to Conv3d+BatchNorm3d+ELU use order='cbe'.\n",
    "    Use padded convolutions to make sure that the output (H_out, W_out) is the same\n",
    "    as (H_in, W_in), so that you don't have to crop in the decoder path.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        encoder (bool): if True we're in the encoder path, otherwise we're in the decoder\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "        order (string): determines the order of layers, e.g.\n",
    "            'cr' -> conv + ReLU\n",
    "            'crg' -> conv + ReLU + groupnorm\n",
    "            'cl' -> conv + LeakyReLU\n",
    "            'ce' -> conv + ELU\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, encoder, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        if encoder:\n",
    "            # we're in the encoder path\n",
    "            conv1_in_channels = in_channels\n",
    "            conv1_out_channels = out_channels // 2\n",
    "            if conv1_out_channels < in_channels:\n",
    "                conv1_out_channels = in_channels\n",
    "            conv2_in_channels, conv2_out_channels = conv1_out_channels, out_channels\n",
    "        else:\n",
    "            # we're in the decoder path, decrease the number of channels in the 1st convolution\n",
    "            conv1_in_channels, conv1_out_channels = in_channels, out_channels\n",
    "            conv2_in_channels, conv2_out_channels = out_channels, out_channels\n",
    "\n",
    "        # conv1\n",
    "        self.add_module('SingleConv1',\n",
    "                        SingleConv(conv1_in_channels, conv1_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding))\n",
    "        # conv2\n",
    "        self.add_module('SingleConv2',\n",
    "                        SingleConv(conv2_in_channels, conv2_out_channels, kernel_size, order, num_groups,\n",
    "                                   padding=padding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Upsampling(nn.Module):\n",
    "    \"\"\"\n",
    "    Upsamples a given multi-channel 3D data using either interpolation or learned transposed convolution.\n",
    "    Args:\n",
    "        transposed_conv (bool): if True uses ConvTranspose3d for upsampling, otherwise uses interpolation\n",
    "        in_channels (int): number of input channels for transposed conv\n",
    "            used only if transposed_conv is True\n",
    "        out_channels (int): number of output channels for transpose conv\n",
    "            used only if transposed_conv is True\n",
    "        kernel_size (int or tuple): size of the convolving kernel\n",
    "            used only if transposed_conv is True\n",
    "        scale_factor (int or tuple): stride of the convolution\n",
    "            used only if transposed_conv is True\n",
    "        mode (str): algorithm used for upsampling:\n",
    "            'nearest' | 'linear' | 'bilinear' | 'trilinear' | 'area'. Default: 'nearest'\n",
    "            used only if transposed_conv is False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transposed_conv, in_channels=None, out_channels=None, kernel_size=3,\n",
    "                 scale_factor=(2, 2, 2), mode='nearest'):\n",
    "        super(Upsampling, self).__init__()\n",
    "\n",
    "        if transposed_conv:\n",
    "            # make sure that the output size reverses the MaxPool3d from the corresponding encoder\n",
    "            # (D_out = (D_in − 1) ×  stride[0] − 2 ×  padding[0] +  kernel_size[0] +  output_padding[0])\n",
    "            self.upsample = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=kernel_size, stride=scale_factor,\n",
    "                                               padding=1)\n",
    "        else:\n",
    "            self.upsample = partial(self._interpolate, mode=mode)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        output_size = encoder_features.size()[2:]\n",
    "        return self.upsample(x, output_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def _interpolate(x, size, mode):\n",
    "        return F.interpolate(x, size=size, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module from the encoder path consisting of the optional max\n",
    "    pooling layer (one may specify the MaxPool kernel_size to be different\n",
    "    than the standard (2,2,2), e.g. if the volumetric data is anisotropic\n",
    "    (make sure to use complementary scale_factor in the decoder path) followed by\n",
    "    a DoubleConv module.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        apply_pooling (bool): if True use MaxPool3d before DoubleConv\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        pool_type (str): pooling layer: 'max' or 'avg'\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, apply_pooling=True,\n",
    "                 pool_kernel_size=2, pool_type='max', basic_module=DoubleConv, conv_layer_order='gcr',\n",
    "                 num_groups=8, padding=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        assert pool_type in ['max', 'avg']\n",
    "        if apply_pooling:\n",
    "            if pool_type == 'max':\n",
    "                self.pooling = nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
    "            else:\n",
    "                self.pooling = nn.AvgPool3d(kernel_size=pool_kernel_size)\n",
    "        else:\n",
    "            self.pooling = None\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=True,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.pooling is not None:\n",
    "            x = self.pooling(x)\n",
    "        x = self.basic_module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A single module for decoder path consisting of the upsampling layer\n",
    "    (either learned ConvTranspose3d or nearest neighbor interpolation) followed by a basic module (DoubleConv or ExtResNetBlock).\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        out_channels (int): number of output channels\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
    "        scale_factor (tuple): used as the multiplier for the image H/W/D in\n",
    "            case of nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation\n",
    "            from the corresponding encoder\n",
    "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
    "        conv_layer_order (string): determines the order of layers\n",
    "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, scale_factor=(2, 2, 2), basic_module=DoubleConv,\n",
    "                 conv_layer_order='gcr', num_groups=8, mode='nearest', padding=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        if basic_module == DoubleConv:\n",
    "            # if DoubleConv is the basic_module use interpolation for upsampling and concatenation joining\n",
    "            self.upsampling = Upsampling(transposed_conv=False, in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=conv_kernel_size, scale_factor=scale_factor, mode=mode)\n",
    "            # concat joining\n",
    "            self.joining = partial(self._joining, concat=True)\n",
    "        else:\n",
    "            # if basic_module=ExtResNetBlock use transposed convolution upsampling and summation joining\n",
    "            self.upsampling = Upsampling(transposed_conv=True, in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernel_size=conv_kernel_size, scale_factor=scale_factor, mode=mode)\n",
    "            # sum joining\n",
    "            self.joining = partial(self._joining, concat=False)\n",
    "            # adapt the number of in_channels for the ExtResNetBlock\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.basic_module = basic_module(in_channels, out_channels,\n",
    "                                         encoder=False,\n",
    "                                         kernel_size=conv_kernel_size,\n",
    "                                         order=conv_layer_order,\n",
    "                                         num_groups=num_groups,\n",
    "                                         padding=padding)\n",
    "\n",
    "    def forward(self, encoder_features, x):\n",
    "        x = self.upsampling(encoder_features=encoder_features, x=x)\n",
    "        x = self.joining(encoder_features, x)\n",
    "        x = self.basic_module(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _joining(encoder_features, x, concat):\n",
    "        if concat:\n",
    "            return torch.cat((encoder_features, x), dim=1)\n",
    "        else:\n",
    "            return encoder_features + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Abstract3DUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for standard and residual UNet.\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        final_sigmoid (bool): if True apply element-wise nn.Sigmoid after the\n",
    "            final 1x1 convolution, otherwise apply nn.Softmax. MUST be True if nn.BCELoss (two-class) is used\n",
    "            to train the model. MUST be False if nn.CrossEntropyLoss (multi-class) is used to train the model.\n",
    "        basic_module: basic model for the encoder/decoder (DoubleConv, ExtResNetBlock, ....)\n",
    "        layer_order (string): determines the order of layers\n",
    "            in `SingleConv` module. e.g. 'crg' stands for Conv3d+ReLU+GroupNorm3d.\n",
    "            See `SingleConv` for more info\n",
    "        f_maps (int, tuple): if int: number of feature maps in the first conv layer of the encoder (default: 64);\n",
    "            if tuple: number of feature maps at each level\n",
    "        num_groups (int): number of groups for the GroupNorm\n",
    "        num_levels (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
    "        is_segmentation (bool): if True (semantic segmentation problem) Sigmoid/Softmax normalization is applied\n",
    "            after the final convolution; if False (regression problem) the normalization layer is skipped at the end\n",
    "        testing (bool): if True (testing mode) the `final_activation` (if present, i.e. `is_segmentation=true`)\n",
    "            will be applied as the last operation during the forward pass; if False the model is in training mode\n",
    "            and the `final_activation` (even if present) won't be applied; default: False\n",
    "        conv_kernel_size (int or tuple): size of the convolving kernel in the basic_module\n",
    "        pool_kernel_size (int or tuple): the size of the window\n",
    "        conv_padding (int or tuple): add zero-padding added to all three sides of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, final_sigmoid, basic_module, f_maps=64, is_2D=False, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, testing=False,\n",
    "                 conv_kernel_size=3, pool_kernel_size=2, conv_padding=1, **kwargs):\n",
    "        super(Abstract3DUNet, self).__init__()\n",
    "\n",
    "        self.testing = testing\n",
    "        if is_2D:\n",
    "            conv_kernel_size = [1, conv_kernel_size, conv_kernel_size]\n",
    "            pool_kernel_size = [1, pool_kernel_size, pool_kernel_size]\n",
    "            conv_padding = [0, conv_padding, conv_padding]\n",
    "\n",
    "        if isinstance(f_maps, int):\n",
    "            f_maps = number_of_features_per_level(f_maps, num_levels=num_levels)\n",
    "\n",
    "        # create encoder path consisting of Encoder modules. Depth of the encoder is equal to `len(f_maps)`\n",
    "        encoders = []\n",
    "        for i, out_feature_num in enumerate(f_maps):\n",
    "            if i == 0:\n",
    "                encoder = Encoder(in_channels, out_feature_num,\n",
    "                                  apply_pooling=False,  # skip pooling in the firs encoder\n",
    "                                  basic_module=basic_module,\n",
    "                                  conv_layer_order=layer_order,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  num_groups=num_groups,\n",
    "                                  padding=conv_padding)\n",
    "            else:\n",
    "                # TODO: adapt for anisotropy in the data, i.e. use proper pooling kernel to make the data isotropic after 1-2 pooling operations\n",
    "                encoder = Encoder(f_maps[i - 1], out_feature_num,\n",
    "                                  basic_module=basic_module,\n",
    "                                  conv_layer_order=layer_order,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  num_groups=num_groups,\n",
    "                                  pool_kernel_size=pool_kernel_size,\n",
    "                                  padding=conv_padding)\n",
    "\n",
    "            encoders.append(encoder)\n",
    "\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "\n",
    "        # create decoder path consisting of the Decoder modules. The length of the decoder is equal to `len(f_maps) - 1`\n",
    "        decoders = []\n",
    "        reversed_f_maps = list(reversed(f_maps))\n",
    "        for i in range(len(reversed_f_maps) - 1):\n",
    "            if basic_module == DoubleConv:\n",
    "                in_feature_num = reversed_f_maps[i] + reversed_f_maps[i + 1]\n",
    "            else:\n",
    "                in_feature_num = reversed_f_maps[i]\n",
    "\n",
    "            out_feature_num = reversed_f_maps[i + 1]\n",
    "            # TODO: if non-standard pooling was used, make sure to use correct striding for transpose conv\n",
    "            # currently strides with a constant stride: (2, 2, 2)\n",
    "            decoder = Decoder(in_feature_num, out_feature_num,\n",
    "                              basic_module=basic_module,\n",
    "                              conv_layer_order=layer_order,\n",
    "                              conv_kernel_size=conv_kernel_size,\n",
    "                              num_groups=num_groups,\n",
    "                              padding=conv_padding)\n",
    "            decoders.append(decoder)\n",
    "\n",
    "        self.decoders = nn.ModuleList(decoders)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder part\n",
    "        encoders_features = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            # reverse the encoder outputs to be aligned with the decoder\n",
    "            encoders_features.insert(0, x)\n",
    "\n",
    "        # remove the last encoder's output from the list\n",
    "        # !!remember: it's the 1st in the list\n",
    "        encoders_features = encoders_features[1:]\n",
    "\n",
    "        # decoder part\n",
    "        for decoder, encoder_features in zip(self.decoders, encoders_features):\n",
    "            # pass the output from the corresponding encoder and the output\n",
    "            # of the previous decoder\n",
    "            x = decoder(encoder_features, x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UNet3D(Abstract3DUNet):\n",
    "    \"\"\"\n",
    "    3DUnet model from\n",
    "    `\"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation\"\n",
    "        <https://arxiv.org/pdf/1606.06650.pdf>`.\n",
    "    Uses `DoubleConv` as a basic_module and nearest neighbor upsampling in the decoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, final_sigmoid=True, f_maps=64, is_2D=False, layer_order='gcr',\n",
    "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1,  **kwargs):\n",
    "        super(UNet3D, self).__init__(in_channels=in_channels, final_sigmoid=final_sigmoid,\n",
    "                                     basic_module=DoubleConv, f_maps=f_maps, is_2D=is_2D, layer_order=layer_order,\n",
    "                                     num_groups=num_groups, num_levels=num_levels, is_segmentation=is_segmentation,\n",
    "                                     conv_padding=conv_padding, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IntensityDist(nn.Module):\n",
    "    \"\"\"\n",
    "    Stores the three parameters that determine the distribution of intensities for simulator learning (and which are optimized during autoencoder learning)\n",
    "    Args:\n",
    "        int_conc, int_rate: parameters of the torch.distributions.gamma class.\n",
    "        int_loc: shift parameter. \n",
    "    \"\"\"\n",
    "    def __init__(self, int_conc, int_rate, int_loc):\n",
    "        super().__init__()\n",
    "        self.int_conc = torch.nn.Parameter(torch.tensor(float(int_conc)))\n",
    "        self.int_rate = torch.nn.Parameter(torch.tensor(float(int_rate)))\n",
    "        self.int_loc = torch.nn.Parameter(torch.tensor(float(int_loc)))  \n",
    "        \n",
    "class OutputNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes the output maps from the U-net and processes them seperately, using two conv3D layers for each group (xyzi_mean, xyzi_sigma, probability, background)\n",
    "    Args:\n",
    "        f_maps: number of channels of the U-net output\n",
    "        p_offset: probability channel bias \n",
    "        is_2D: whether the input is 1D in the z dimension\n",
    "        n_p_ch: Number probability channels (number of genes)\n",
    "        n_bg_ch: Number background channels (number of channels or 1)\n",
    "        n_int_ch: Number intensity channels (number of channels)\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, f_maps=64, p_offset=-5., is_2D=False, n_p_ch=1, n_bg_ch=1, n_int_ch=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.is_2D = is_2D\n",
    "        self.n_p_ch = n_p_ch\n",
    "        self.n_bg_ch = n_bg_ch\n",
    "        self.n_int_ch = n_int_ch\n",
    "        \n",
    "        xyzi_dim = 3 + n_int_ch\n",
    "        \n",
    "        kernel_size = [1,3,3] if is_2D else [3,3,3]\n",
    "        padding = [0,1,1] if is_2D else [1,1,1]\n",
    "\n",
    "        self.p_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.p_out2 = nn.Conv3d(f_maps, n_p_ch, kernel_size=1, padding=0)\n",
    "        nn.init.constant_(self.p_out2.bias,p_offset)\n",
    "        \n",
    "        self.xyzi_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.xyzi_out2 = nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.xyzis_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.xyzis_out2 = nn.Conv3d(f_maps, xyzi_dim, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.bg_out1 = nn.Conv3d(f_maps, f_maps, kernel_size=kernel_size, padding=padding, padding_mode='replicate')\n",
    "        self.bg_out2 = nn.Conv3d(f_maps, n_bg_ch, kernel_size=1, padding=0)\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.p_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.p_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.xyzi_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.xyzi_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.xyzis_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.xyzis_out2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.kaiming_normal_(self.bg_out1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.bg_out2.weight, mode='fan_in', nonlinearity='linear')    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        logit    = F.elu(self.p_out1(x))\n",
    "        logit    = self.p_out2(logit)\n",
    "        logit    = torch.clamp(logit, -20., 20)\n",
    "        \n",
    "        xyzi = F.elu(self.xyzi_out1(x))\n",
    "        xyzi = self.xyzi_out2(xyzi)\n",
    "\n",
    "        xyz_mu   = torch.tanh(xyzi[:, :3])\n",
    "\n",
    "        i_mu     = F.softplus(xyzi[:, 3:])\n",
    "        xyzi_mu = torch.cat((xyz_mu, i_mu), dim=1)\n",
    "        \n",
    "        xyzis = F.elu(self.xyzis_out1(x))\n",
    "        xyzis = self.xyzis_out2(xyzis)\n",
    "        xyzi_sig = F.softplus(xyzis) + 0.01\n",
    "        \n",
    "        background = F.elu(self.bg_out1(x))\n",
    "        background = self.bg_out2(background)\n",
    "        background = F.softplus(background)\n",
    "        return torch.cat([logit,xyzi_mu,xyzi_sig,background],1)\n",
    "            \n",
    "\n",
    "class UnetDecodeNoBn(nn.Module):\n",
    "    \"\"\"\n",
    "    Our DECODE network consists of a 3D U-net, and an output net module.\n",
    "    The network parameters can be accessed through model.network\n",
    "    \n",
    "    We also store the parameters of the intensity distribution here for easier access. (model.int_dist)\n",
    "    \n",
    "    The forward function returns a tensor batch_size x n_output_channel tensor to make it compatible with the monai.inferers.sliding_window_inference function.\n",
    "    \n",
    "    To get the final output dictionary one has to also apply the tensor_to_dict function.\n",
    "    \n",
    "    Args:\n",
    "        ch_in (int): number of input channels (i.e. n_rounds * n_colors)\n",
    "        depth (int): number of levels in the encoder/decoder path\n",
    "        inp_offset, inp_scale (float): Values used for normalizing the input. \n",
    "        order (string): determines the order of layers\n",
    "            in `SingleConv` module. e.g. 'ce' stands for Conv3d+ELU.\n",
    "            See `SingleConv` for more info\n",
    "            Before the input is given to the network is is normalized using these variables.\n",
    "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
    "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
    "        is_2D: whether the input is 1D in the z dimension\n",
    "        pred_z: setting to false will disable inference of the z position\n",
    "        p_offset (float):\n",
    "            bias of the probabilty channel. The negative value avoids very high rates at the start of the training which might cause memory issues.\n",
    "        int_conc, int_rate (float): parameters of the torch.distributions.gamma class.\n",
    "        int_loc (float): shift parameter. \n",
    "        p_offset: probability channel bias \n",
    "        n_p_ch: Number probability channels (number of genes)\n",
    "        n_bg_ch: Number background channels (number of channels or 1)\n",
    "        n_int_ch: Number intensity channels (number of channels)\n",
    "        chrom_map: whether the network using the chromatic abberation map as an additional input    \n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in=1, depth=3, inp_scale=1., inp_offset=0., order='ce', f_maps=64, \n",
    "                 is_2D=False, pred_z=True, p_offset=-5., int_conc=4., int_rate=1., int_loc=1., n_p_ch=1, n_bg_ch=1, n_int_ch=1, chrom_map=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.inp_scale = inp_scale\n",
    "        self.inp_offset = inp_offset\n",
    "        \n",
    "        self.chrom_map = chrom_map\n",
    "        if chrom_map:\n",
    "            ch_in = ch_in + 2\n",
    "        \n",
    "        self.ch_in = ch_in\n",
    "        self.is_2D = is_2D\n",
    "        self.pred_z = pred_z\n",
    "        self.n_p_ch = n_p_ch\n",
    "        self.n_bg_ch = n_bg_ch\n",
    "        self.n_int_ch = n_int_ch\n",
    "        \n",
    "        self.unet = UNet3D(ch_in, final_sigmoid=False, num_levels=depth, is_2D=is_2D,\n",
    "                           layer_order = order, f_maps=f_maps)\n",
    "        self.outnet = OutputNet(f_maps=f_maps, p_offset=p_offset, is_2D=is_2D, n_p_ch=n_p_ch, n_bg_ch=n_bg_ch, n_int_ch=n_int_ch)\n",
    "        \n",
    "        self.network = nn.ModuleList([self.unet, self.outnet])\n",
    "        self.int_dist = IntensityDist(int_conc, int_rate, int_loc)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.chrom_map:\n",
    "            # Don't scale chrom. map input\n",
    "            x[:,:-2] = (x[:,:-2]-self.inp_offset) / self.inp_scale\n",
    "        else:\n",
    "            x = (x-self.inp_offset) / self.inp_scale\n",
    "        \n",
    "        for net in self.network:\n",
    "            x = net(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "    def tensor_to_dict(self, x):\n",
    "        \n",
    "        logits = x[:, 0:self.n_p_ch]\n",
    "        xyzi_mu = x[:, self.n_p_ch:self.n_p_ch+3+self.n_int_ch]\n",
    "        xyzi_sig = x[:, self.n_p_ch+3+self.n_int_ch:self.n_p_ch+2*(3+self.n_int_ch)]\n",
    "        bg = x[:, self.n_p_ch+2*(3+self.n_int_ch):self.n_p_ch+2*(3+self.n_int_ch)+self.n_bg_ch]\n",
    "        \n",
    "        # Scale bg output\n",
    "        bg = bg * self.inp_scale #[None,:,None,None,None].to(bg.device)\n",
    "    \n",
    "        if not self.pred_z:\n",
    "        \n",
    "            xyzi_mu[:,3] *= 0\n",
    "            xyzi_sig[:,3] *= 0\n",
    "            xyzi_sig[:,3] += 1\n",
    "\n",
    "        ret_dict = {'logits': logits, \n",
    "                    'xyzi_mu': xyzi_mu, \n",
    "                    'xyzi_sigma': xyzi_sig, \n",
    "                    'background': bg}\n",
    "        \n",
    "        return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn([2,9,37,48,48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([3, 252, 7, 48, 48])\n",
      "xyzi_mu torch.Size([3, 25, 7, 48, 48])\n",
      "xyzi_sigma torch.Size([3, 25, 7, 48, 48])\n",
      "background torch.Size([3, 22, 7, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "model = UnetDecodeNoBn(order= 'ce', ch_in=22, f_maps=256, depth=2, is_2D=False, pred_z=False, n_p_ch=252, n_bg_ch=22, n_int_ch=22)\n",
    "output = model.tensor_to_dict(model(torch.randn([3,22,7,48,48])))\n",
    "# output = model.tensor_to_dict(model(torch.randn([7,16,1,48,48]), shuffle_ch=True))\n",
    "\n",
    "for k in output.keys():\n",
    "    print(k, output[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f7f84d862e0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((output['logits'])[0,0,0].detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(output, '../data/model_batch_output_class2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = OmegaConf.load('../config/experiment/msp300_n2.yaml')\n",
    "# model = hydra.utils.instantiate(cfg.model, inp_scale=float(5), inp_offset=float(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20510916"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 20_MERFISH_visualization.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted 25_ensembling.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decode_fish_dev2",
   "language": "python",
   "name": "decode_fish_dev2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
