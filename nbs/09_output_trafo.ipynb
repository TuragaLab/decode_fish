{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.output_trafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations of sampled data and model output into emitter dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from decode_fish.funcs.utils import *\n",
    "import torch.nn.functional as F\n",
    "from decode_fish.funcs.plotting import *\n",
    "from decode_fish.funcs.emitter_io import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sample_to_df(locs, x_os, y_os, z_os, ints, codes, px_size_zyx=[100,100,100]):\n",
    "    \n",
    "    x = locs[-1] + x_os + 0.5 \n",
    "    y = locs[-2] + y_os + 0.5 \n",
    "    z = locs[-3] + z_os + 0.5 \n",
    "    \n",
    "    n_gt = len(x)\n",
    "    channels = ints.shape[1]\n",
    "    \n",
    "    frame_idx = locs[0]\n",
    "    \n",
    "    df = DF({'loc_idx': torch.arange(n_gt),\n",
    "             'frame_idx': frame_idx.cpu(),\n",
    "             'x': x.cpu()*px_size_zyx[2],\n",
    "             'y': y.cpu()*px_size_zyx[1], \n",
    "             'z': z.cpu()*px_size_zyx[0]}) \n",
    "    \n",
    "    for i in range(channels):\n",
    "        df[f'int_{i}'] = ints[:,i].cpu()\n",
    "        \n",
    "    df['code_inds'] = codes\n",
    "    df['ints'] = ints.sum(-1).cpu()\n",
    "\n",
    "    return df\n",
    "\n",
    "def df_to_micro(df, px_size_zyx=[100,100,100]):\n",
    "    \n",
    "    locs = tuple([torch.tensor(df['frame_idx'],dtype=torch.int64).cuda(),\n",
    "                 torch.zeros(len(df),dtype=torch.int64).cuda(),\n",
    "                 torch.tensor((df['z']/px_size_zyx[0] + 0.5),dtype=torch.int64).cuda(),\n",
    "                 torch.tensor((df['y']/px_size_zyx[1] + 0.5),dtype=torch.int64).cuda(),\n",
    "                 torch.tensor((df['x']/px_size_zyx[2] + 0.5),dtype=torch.int64).cuda()])\n",
    "    z = (torch.tensor(df['z'],dtype=torch.float32).cuda()-locs[2]*px_size_zyx[0])/px_size_zyx[0] - 0.5\n",
    "    y = (torch.tensor(df['y'],dtype=torch.float32).cuda()-locs[3]*px_size_zyx[1])/px_size_zyx[1] - 0.5\n",
    "    x = (torch.tensor(df['x'],dtype=torch.float32).cuda()-locs[4]*px_size_zyx[2])/px_size_zyx[2] - 0.5\n",
    "    ints = torch.tensor(df['int']).cuda()\n",
    "\n",
    "    return locs, x, y, z, ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13832\n"
     ]
    }
   ],
   "source": [
    "from decode_fish.funcs.exp_specific import get_benchmark\n",
    "bench_df, code_ref, targets = get_benchmark()\n",
    "code_inds = np.stack([np.nonzero(c)[0] for c in code_ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/torch/cuda/__init__.py:81: UserWarning: \n",
      "    Found GPU2 NVS 510 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "from decode_fish.engine.point_process import PointProcessUniform\n",
    "point_process = PointProcessUniform(local_rate = torch.ones([7,1,48,48]).cuda()*.3, int_conc=3, int_rate=1, int_loc=1, sim_iters=1, channels=16, n_bits=4, codebook=torch.tensor(code_ref, dtype=torch.bool), int_option=1)\n",
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, codes = point_process.sample(from_code_book=True, phasing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SIPostProcess(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, m1_threshold:float = 0.03, m2_threshold:float = 0.3, samp_threshold=0.1, px_size_zyx=[100,100,100], diag=0):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.m1_threshold = m1_threshold\n",
    "        self.m2_threshold = m2_threshold\n",
    "        self.samp_threshold = samp_threshold\n",
    "        self.diag = diag\n",
    "        self.px_size_zyx = px_size_zyx\n",
    "        self.codebook = False\n",
    "        \n",
    "        if not diag:\n",
    "            d1 = 0; d2 = 0\n",
    "        else:\n",
    "            d1 = 1/np.sqrt(2); d2 = 1/np.sqrt(3)\n",
    "#             d1 = 1; d2 = 1\n",
    "        self.filt = torch.FloatTensor([[[d2,d1,d2],[d1,1,d1],[d2,d1,d2]],\n",
    "                                       [[d1, 1,d1],[1, 1, 1],[d1, 1,d1]],\n",
    "                                       [[d2,d1,d2],[d1,1,d1],[d2,d1,d2]]])[None,None]\n",
    "        \n",
    "    def forward(self, logits):\n",
    "\n",
    "        device = logits.device\n",
    "        p = torch.sigmoid(logits)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            p_copy = p + 0\n",
    "\n",
    "            # probability values > threshold are regarded as possible locations\n",
    "            p_clip = torch.where(p>self.m1_threshold,p,torch.zeros_like(p))\n",
    "\n",
    "            # localize maximum values within a 3x3 patch\n",
    "            pool = F.max_pool3d(p_clip,3,1,padding=1)\n",
    "            max_mask1 = torch.eq(p, pool).float()\n",
    "\n",
    "            # Add probability values from the 4 adjacent pixels\n",
    "            conv = F.conv3d(p, self.filt.to(device) ,padding=1)\n",
    "            p_ps1 = (max_mask1 * conv)\n",
    "\n",
    "            # In order do be able to identify two fluorophores in adjacent pixels we look for probablity values > 0.5 that are not part of the first mask\n",
    "\n",
    "            p_copy *= (1-max_mask1)\n",
    "            p_clip = torch.where(p_copy>self.m2_threshold, p_copy,torch.zeros_like(p_copy))\n",
    "            max_mask2 = torch.where(p_copy>self.m2_threshold, torch.ones_like(p_copy),torch.zeros_like(p_copy))\n",
    "            p_ps2 = max_mask2*conv\n",
    "\n",
    "            # This is our final clustered probablity which we then threshold (normally > 0.7) to get our final discrete locations \n",
    "            p_ps = p_ps1 + p_ps2        \n",
    "\n",
    "            return p_ps\n",
    "        \n",
    "    def get_si_resdict(self, res_dict, p_si=None):\n",
    "        \n",
    "        if p_si is None:\n",
    "            p_si = self.forward(res_dict['logits'])\n",
    "            \n",
    "        res_dict['Probs_si'] = p_si\n",
    "        res_dict['Samples_si'] = torch.where(res_dict['Probs_si'] > self.samp_threshold, torch.ones_like(res_dict['Probs_si']), torch.zeros_like(res_dict['Probs_si']))\n",
    "        \n",
    "        return res_dict\n",
    "        \n",
    "    def get_df(self, res_dict, p_si=None, softmax=False):\n",
    "        \n",
    "        res_dict = self.get_si_resdict(res_dict, p_si)\n",
    "        \n",
    "        res_dict = {k:v.cpu() for (k,v) in res_dict.items()}\n",
    "        locations = res_dict['Samples_si'].nonzero(as_tuple=True)\n",
    "        ch0_locs = locations[0], locations[1]*0, locations[2] ,locations[3], locations[4]\n",
    "\n",
    "        pos_x, pos_y, pos_z = locations[-1] ,locations[-2], locations[-3]\n",
    "        \n",
    "        x = pos_x + res_dict['xyzi_mu'][:,[0]][ch0_locs] + 0.5 \n",
    "        y = pos_y + res_dict['xyzi_mu'][:,[1]][ch0_locs] + 0.5 \n",
    "        z = pos_z + res_dict['xyzi_mu'][:,[2]][ch0_locs] + 0.5\n",
    "\n",
    "        loc_idx = torch.arange(len(x))\n",
    "        frame_idx = locations[0]\n",
    "\n",
    "        df = DF({'loc_idx': loc_idx,\n",
    "                 'frame_idx': frame_idx,\n",
    "                 'code_inds': locations[1],\n",
    "                 'x': x*self.px_size_zyx[2],\n",
    "                 'y': y*self.px_size_zyx[1], \n",
    "                 'z': z*self.px_size_zyx[0], \n",
    "                 'prob': res_dict['Probs_si'][locations], \n",
    "#                  'int': res_dict['xyzi_mu'][:,[3]][ch0_locs], \n",
    "#                  'int_sig': res_dict['xyzi_sigma'][:,[3]][ch0_locs], \n",
    "                 'x_sig': res_dict['xyzi_sigma'][:,[0]][ch0_locs]*self.px_size_zyx[0], \n",
    "                 'y_sig': res_dict['xyzi_sigma'][:,[1]][ch0_locs]*self.px_size_zyx[1], \n",
    "                 'z_sig': res_dict['xyzi_sigma'][:,[2]][ch0_locs]*self.px_size_zyx[2],\n",
    "                 'comb_sig': torch.sqrt(res_dict['xyzi_sigma'][:,[0]][ch0_locs]**2\n",
    "                                       +res_dict['xyzi_sigma'][:,[1]][ch0_locs]**2\n",
    "                                       +res_dict['xyzi_sigma'][:,[2]][ch0_locs]**2)})\n",
    "        \n",
    "        for i in range(res_dict['xyzi_mu'].shape[1]-3):\n",
    "            df[f'int_{i}'] = res_dict['xyzi_mu'][:,[3+i]][ch0_locs]\n",
    "            df[f'int_sig_{i}'] = res_dict['xyzi_sigma'][:,[3+i]][ch0_locs]\n",
    "            \n",
    "        return df\n",
    "        \n",
    "    def get_micro_inp(self, res_dict, p_si=None):\n",
    "\n",
    "        channels = self.codebook.shape[1]\n",
    "        n_bits = (1.*self.codebook.sum(1)).mean()\n",
    "        res_dict = self.get_si_resdict(res_dict, p_si)\n",
    "        locations = res_dict['Samples_si'].nonzero(as_tuple=True)\n",
    "        \n",
    "        n_int = res_dict['xyzi_mu'].shape[1] - 3\n",
    "\n",
    "        xyzi_ix = [locations[0],locations[2],locations[3], locations[4]]\n",
    "        x_os_3d = res_dict['xyzi_mu'][:,0][xyzi_ix]\n",
    "        y_os_3d = res_dict['xyzi_mu'][:,1][xyzi_ix]\n",
    "        z_os_3d = res_dict['xyzi_mu'][:,2][xyzi_ix]\n",
    "        \n",
    "        if n_int == 1:\n",
    "            ints_3d = res_dict['xyzi_mu'][:,3][xyzi_ix]\n",
    "            ints_3d = ints_3d/n_bits\n",
    "            ints_ret = ints_3d[:,None].repeat_interleave(channels, 1)\n",
    "            ch_bin = self.codebook.to(ints_ret.device)[locations[1]]\n",
    "            ints_ret = ints_ret*ch_bin\n",
    "        \n",
    "        if n_int == n_bits:\n",
    "            code_inds = self.codebook.nonzero(as_tuple=True)[1].reshape([self.codebook.shape[0], -1])\n",
    "            ints_3d = res_dict['xyzi_mu'][:,3:][locations[0],:,locations[2],locations[3], locations[4]]\n",
    "            ints_ret = torch.zeros(ints_3d.shape[0], channels).to(ints_3d.device)\n",
    "            ints_ret.scatter_(index=code_inds.to(ints_ret.device)[locations[1]], dim=1, src=ints_3d)\n",
    "            \n",
    "        if n_int == channels:\n",
    "            ints_ret = res_dict['xyzi_mu'][:,3:][locations[0],:,locations[2],locations[3], locations[4]]\n",
    "            ints_ret *= self.codebook.to(ints_ret.device)[locations[1]].ne(0)\n",
    "        \n",
    "        output_shape  = res_dict['Samples_si'].shape\n",
    "        output_shape  = torch.Size([output_shape[0],channels,output_shape[2],output_shape[3],output_shape[4]])\n",
    "\n",
    "        return xyzi_ix, x_os_3d, y_os_3d, z_os_3d, ints_ret, output_shape\n",
    "# p_col = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ISIPostProcess(SIPostProcess):\n",
    "    \n",
    "    def __init__(self, m1_threshold:float = 0.1, samp_threshold=0.1, px_size_zyx=[100,100,100], diag=False):\n",
    "        \n",
    "        super().__init__(m1_threshold = m1_threshold, samp_threshold=samp_threshold, px_size_zyx=px_size_zyx, diag=diag)\n",
    "        self.m2_threshold = None\n",
    "        \n",
    "    def forward(self, logits):\n",
    "\n",
    "        device = logits.device\n",
    "        p = torch.sigmoid(logits)\n",
    "        \n",
    "        batch_size = p.shape[0]\n",
    "        n_codes = p.shape[1]\n",
    "        \n",
    "        p = p.reshape(batch_size*n_codes,1,*p.shape[-3:])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            p_SI = 0\n",
    "            tot_mask = torch.ones_like(p)\n",
    "            max_mask = torch.ones_like(p)\n",
    "            \n",
    "            while max_mask.sum():\n",
    "                \n",
    "                # voxels with probability values > threshold,\n",
    "                # and which where not previously counted as locations, are canditates\n",
    "                p_cand = torch.where(p>self.m1_threshold, p, torch.zeros_like(p)) * tot_mask\n",
    "\n",
    "                # localize maximum (nonzero) values within a 3x3x3 volume\n",
    "                p_cand = F.max_pool3d(p_cand,3,1,padding=1)\n",
    "                max_mask = torch.eq(p, p_cand).float()\n",
    "                max_mask[p==0] = 0\n",
    "                \n",
    "                # Add up probability values from the adjacent pixels\n",
    "                conv = F.conv3d(p, self.filt.to(device), padding=1)\n",
    "                p_sum = max_mask * conv\n",
    "                \n",
    "                # Add the integrated probabilities to the return tensor. \n",
    "                p_SI += torch.clamp_max(p_sum, 1) \n",
    "                # Voxels that where added can not be added again\n",
    "                tot_mask *= (torch.ones_like(max_mask) - max_mask)\n",
    "                \n",
    "                # The probability mass that contributed to p_sum is removed.\n",
    "                p_fac = 1/p_sum\n",
    "                p_fac[torch.isinf(p_fac)] = 0\n",
    "                p_fac = torch.clamp_max(p_fac, 1) \n",
    "                p_proc = F.conv3d(p_fac, self.filt.to(device),padding=1)*p\n",
    "\n",
    "                p = p - p_proc\n",
    "                torch.clamp_min_(p, 0)\n",
    "            \n",
    "            return p_SI.reshape(batch_size,n_codes,*p.shape[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from decode_fish.funcs.evaluation import *\n",
    "\n",
    "post_proc1 = SIPostProcess(m1_threshold=0.03, m2_threshold=0.25, samp_threshold=0.6, px_size_zyx=[100,100,100], diag=True)\n",
    "post_proc2 = ISIPostProcess(m1_threshold=0.03, samp_threshold=0.5, px_size_zyx=[100,100,100], diag=True)\n",
    "\n",
    "# matching(px_to_nm(gt_df),  post_proc1.forward(model_out, ret='df'), tolerance=500, print_res=True)\n",
    "# _=matching(px_to_nm(gt_df),  post_proc2.forward(model_out, ret='df'), tolerance=500, print_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from decode_fish.funcs.utils import *\n",
    "# model_out = torch.load('../data/model_output.pt')\n",
    "# probs_inp = torch.sigmoid(model_out['logits'])[:,:,:,250:300,200:250]\n",
    "\n",
    "# model_out = torch.load('../data/model_batch_output.pt')\n",
    "# probs_inp = torch.sigmoid(model_out['logits'])\n",
    "\n",
    "# model_out = torch.load('../data/model_output_t.pt')\n",
    "# probs_inp = torch.sigmoid(model_out['logits'])[:,:,:,:,:]\n",
    "\n",
    "# model_out = torch.load('../data/model_output_2d.pt')\n",
    "# probs_inp = torch.sigmoid(model_out['logits'])\n",
    "model_out = torch.load('../data/model_batch_output_class.pt')\n",
    "# for m in model_out:\n",
    "#     model_out[m] =model_out[m].detach() \n",
    "# gt_df = torch.load('../data/gt_1.pt')\n",
    "# len(gt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_out['xyzi_mu'] = torch.cat([model_out['xyzi_mu'],model_out['xyzi_mu'][:,3:]*0.75,model_out['xyzi_mu'][:,3:]*0.5,model_out['xyzi_mu'][:,3:]*0.25], 1)\n",
    "model_out['xyzi_mu'] = torch.cat([model_out['xyzi_mu'],model_out['xyzi_mu'][:,3:].repeat_interleave(15,1)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13832\n"
     ]
    }
   ],
   "source": [
    "from decode_fish.funcs.exp_specific import get_benchmark\n",
    "bench_df, code_ref, targets = get_benchmark()\n",
    "code_inds = np.stack([np.nonzero(c)[0] for c in code_ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_proc2 = ISIPostProcess(m1_threshold=0.03, samp_threshold=0.5, px_size_zyx=[100,100,100], diag=True)\n",
    "post_proc2.codebook = torch.tensor(code_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra = post_proc2.get_micro_inp(model_out)\n",
    "ints = tra[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1589, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2a14363050>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cpu(ints[:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2a9414ef10>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cpu(ints[:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out['logits'] = model_2d['logits'].expand(-1,140,-1,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra1 = post_proc2(model_out['logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra2 = post_proc2(model_out['logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cpu(tra2)[0,0,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_proc2.get_df(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs_inp = probs_inp[:,:,10:11]\n",
    "# for k in model_out:\n",
    "#     model_out[k] = model_out[k][:,:,10:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# print(len(gt_df))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(231)\n",
    "probs = cpu(probs_inp[0,0])\n",
    "probsf = probs + 0\n",
    "probsf[probsf<0.01] = 0\n",
    "im = plt.imshow(probs.sum(0))\n",
    "# plt.scatter(gt_df['x'],gt_df['y'], color='red', s=5.)\n",
    "plt.title(f'Net output {probs.sum().item():.1f} and {probsf.sum().item():.1f}'.format())\n",
    "add_colorbar(im)\n",
    "\n",
    "recs = post_proc1.get_si_resdict(model_out)\n",
    "plt.subplot(232)\n",
    "im = plt.imshow(cpu(recs['Probs_si'][0,0]).max(0))\n",
    "add_colorbar(im)\n",
    "N = cpu(recs['Probs_si'][0,0]).sum().item()\n",
    "plt.title(f'SI Probs SI {N:.1f}')\n",
    "\n",
    "plt.subplot(235)\n",
    "im = plt.imshow(cpu(recs['Samples_si'][0,0]).sum(0))\n",
    "add_colorbar(im)\n",
    "plt.title(cpu(recs['Samples_si'][0,0]).sum().item())\n",
    "\n",
    "recs = post_proc2.get_si_resdict(model_out)\n",
    "plt.subplot(233)\n",
    "im = plt.imshow(cpu(recs['Probs_si'][0,0]).max(0))\n",
    "add_colorbar(im)\n",
    "N = cpu(recs['Probs_si'][0,0]).sum().item()\n",
    "plt.title(f'ISI Probs SI {N:.1f}')\n",
    "\n",
    "plt.subplot(236)\n",
    "im = plt.imshow(cpu(recs['Samples_si'][0,0]).sum(0))\n",
    "add_colorbar(im)\n",
    "plt.title(cpu(recs['Samples_si'][0,0]).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = np.s_[:,:10,35:45,20:30]\n",
    "gt_sub = crop_df(gt_df, sl)\n",
    "p_sub = crop_df(nm_to_px(post_proc2.forward(model_out, ret='df')), sl)\n",
    "axes=plot_3d_projections(probs[sl[1:]], 'max', size=15)\n",
    "# print(probs[sl[1:]].sum(), len(gt_sub), len(p_sub))\n",
    "# axes[0].scatter(gt_sub['x'],gt_sub['y'], color='red', s=5.)\n",
    "# axes[1].scatter(gt_sub['x'],gt_sub['z'], color='red', s=5.)\n",
    "# axes[2].scatter(gt_sub['y'],gt_sub['z'], color='red', s=5.)\n",
    "\n",
    "axes[0].scatter(p_sub['x'],p_sub['y'], color='red', s=15.)\n",
    "axes[1].scatter(p_sub['x'],p_sub['z'], color='red', s=15.)\n",
    "axes[2].scatter(p_sub['y'],p_sub['z'], color='red', s=15.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in p_col:\n",
    "    plt.imshow(cpu(p[0,0][sl[1:]]).max(0))\n",
    "#     plt.title(cpu(p[0,0][sl[1:]]).sum())\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cpu(p[0,0][sl[1:]]).max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(probs.reshape(-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_si = post_proc.spatial_integration(probs_inp)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "probs = probs_inp[0,0].detach().cpu()\n",
    "# probs[probs<0.01] = 0\n",
    "im = plt.imshow(probs.max(dim=0).values)\n",
    "plt.title(probs.sum().item())\n",
    "add_colorbar(im)\n",
    "plt.subplot(122)\n",
    "im = plt.imshow(probs_si[0,0].cpu().max(dim=0).values, vmax=1)\n",
    "add_colorbar(im)\n",
    "plt.title(probs_si[0].sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = torch.load('../data/model_output_1.pt')\n",
    "out_df = post_proc2(model_out)\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(121)\n",
    "im = plt.imshow(probs_inp[0,0].cpu().max(dim=0).values)\n",
    "add_colorbar(im)\n",
    "plt.title(len(out_df))\n",
    "plt.scatter(out_df['x']/100,out_df['y']/100, color='red', s=5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = torch.load('../data/model_batch_output.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.engine.psf import LinearInterpolatedPSF\n",
    "from decode_fish.engine.noise import sCMOS\n",
    "from decode_fish.engine.point_process import PointProcessUniform\n",
    "from decode_fish.funcs.plotting import plot_3d_projections\n",
    "from decode_fish.engine.microscope import Microscope\n",
    "\n",
    "psf_state = torch.load('/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/fishcod/simfish_psf.pkl')\n",
    "_,xs,ys,zs = psf_state['psf_volume'].shape\n",
    "psf = LinearInterpolatedPSF(fs_x=xs, fs_y=ys, fs_z=zs, upsample_factor= 1)\n",
    "psf.load_state_dict(psf_state)\n",
    "\n",
    "noise = sCMOS()\n",
    "\n",
    "micro = Microscope(parametric_psf=[psf], noise=noise, multipl=10000).cuda()\n",
    "\n",
    "point_process = PointProcessUniform(local_rate = torch.ones([1,1,48,48,48]).cuda()*.0001, min_int = 0.5)\n",
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape = point_process.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsim = micro(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape)\n",
    "xrec = micro(locs_mod, x_os_mod, y_os_mod, z_os_mod, ints_mod, output_shape_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_projections(xsim[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_projections(xrec[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 20_MERFISH_visualization.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode_fish_dev2]",
   "language": "python",
   "name": "conda-env-decode_fish_dev2-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
