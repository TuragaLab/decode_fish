# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/09_output_trafo.ipynb (unless otherwise specified).

__all__ = ['sample_to_df', 'df_to_micro', 'SIPostProcess', 'ISIPostProcess']

# Cell
from ..imports import *
from .utils import *
import torch.nn.functional as F
from .plotting import *
from .emitter_io import *

# Cell
def sample_to_df(locs, x_os, y_os, z_os, ints, codes, px_size_zyx=[100,100,100]):

    x = locs[-1] + x_os + 0.5
    y = locs[-2] + y_os + 0.5
    z = locs[-3] + z_os + 0.5

    n_gt = len(x)
    channels = ints.shape[1]

    frame_idx = locs[0]

    df = DF({'loc_idx': torch.arange(n_gt),
             'frame_idx': frame_idx.cpu(),
             'x': x.cpu()*px_size_zyx[2],
             'y': y.cpu()*px_size_zyx[1],
             'z': z.cpu()*px_size_zyx[0]})

    for i in range(channels):
        df[f'int_{i}'] = ints[:,i].cpu()

    df['code_inds'] = codes
    df['ints'] = ints.sum(-1).cpu()

    return df

def df_to_micro(df, px_size_zyx=[100,100,100]):

    locs = tuple([torch.tensor(df['frame_idx'],dtype=torch.int64).cuda(),
                 torch.zeros(len(df),dtype=torch.int64).cuda(),
                 torch.tensor((df['z']/px_size_zyx[0] + 0.5),dtype=torch.int64).cuda(),
                 torch.tensor((df['y']/px_size_zyx[1] + 0.5),dtype=torch.int64).cuda(),
                 torch.tensor((df['x']/px_size_zyx[2] + 0.5),dtype=torch.int64).cuda()])
    z = (torch.tensor(df['z'],dtype=torch.float32).cuda()-locs[2]*px_size_zyx[0])/px_size_zyx[0] - 0.5
    y = (torch.tensor(df['y'],dtype=torch.float32).cuda()-locs[3]*px_size_zyx[1])/px_size_zyx[1] - 0.5
    x = (torch.tensor(df['x'],dtype=torch.float32).cuda()-locs[4]*px_size_zyx[2])/px_size_zyx[2] - 0.5
    ints = torch.tensor(df['int']).cuda()

    return locs, x, y, z, ints

# Cell
class SIPostProcess(torch.nn.Module):

    def __init__(self, m1_threshold:float = 0.03, m2_threshold:float = 0.3, samp_threshold=0.1, px_size_zyx=[100,100,100], diag=0):

        super().__init__()
        self.m1_threshold = m1_threshold
        self.m2_threshold = m2_threshold
        self.samp_threshold = samp_threshold
        self.diag = diag
        self.px_size_zyx = px_size_zyx
        self.codebook = False

        if not diag:
            d1 = 0; d2 = 0
        else:
            d1 = 1/np.sqrt(2); d2 = 1/np.sqrt(3)
#             d1 = 1; d2 = 1
        self.filt = torch.FloatTensor([[[d2,d1,d2],[d1,1,d1],[d2,d1,d2]],
                                       [[d1, 1,d1],[1, 1, 1],[d1, 1,d1]],
                                       [[d2,d1,d2],[d1,1,d1],[d2,d1,d2]]])[None,None]

    def forward(self, logits):

        device = logits.device
        p = torch.sigmoid(logits)

        with torch.no_grad():

            p_copy = p + 0

            # probability values > threshold are regarded as possible locations
            p_clip = torch.where(p>self.m1_threshold,p,torch.zeros_like(p))

            # localize maximum values within a 3x3 patch
            pool = F.max_pool3d(p_clip,3,1,padding=1)
            max_mask1 = torch.eq(p, pool).float()

            # Add probability values from the 4 adjacent pixels
            conv = F.conv3d(p, self.filt.to(device) ,padding=1)
            p_ps1 = (max_mask1 * conv)

            # In order do be able to identify two fluorophores in adjacent pixels we look for probablity values > 0.5 that are not part of the first mask

            p_copy *= (1-max_mask1)
            p_clip = torch.where(p_copy>self.m2_threshold, p_copy,torch.zeros_like(p_copy))
            max_mask2 = torch.where(p_copy>self.m2_threshold, torch.ones_like(p_copy),torch.zeros_like(p_copy))
            p_ps2 = max_mask2*conv

            # This is our final clustered probablity which we then threshold (normally > 0.7) to get our final discrete locations
            p_ps = p_ps1 + p_ps2

            return p_ps

    def get_si_resdict(self, res_dict, p_si=None):

        if p_si is None:
            p_si = self.forward(res_dict['logits'])

        res_dict['Probs_si'] = p_si
        res_dict['Samples_si'] = torch.where(res_dict['Probs_si'] > self.samp_threshold, torch.ones_like(res_dict['Probs_si']), torch.zeros_like(res_dict['Probs_si']))

        return res_dict

    def get_df(self, res_dict, p_si=None, softmax=False):

        res_dict = self.get_si_resdict(res_dict, p_si)

        res_dict = {k:v.cpu() for (k,v) in res_dict.items()}
        locations = res_dict['Samples_si'].nonzero(as_tuple=True)
        ch0_locs = locations[0], locations[1]*0, locations[2] ,locations[3], locations[4]

        pos_x, pos_y, pos_z = locations[-1] ,locations[-2], locations[-3]

        x = pos_x + res_dict['xyzi_mu'][:,[0]][ch0_locs] + 0.5
        y = pos_y + res_dict['xyzi_mu'][:,[1]][ch0_locs] + 0.5
        z = pos_z + res_dict['xyzi_mu'][:,[2]][ch0_locs] + 0.5

        loc_idx = torch.arange(len(x))
        frame_idx = locations[0]

        df = DF({'loc_idx': loc_idx,
                 'frame_idx': frame_idx,
                 'code_inds': locations[1],
                 'x': x*self.px_size_zyx[2],
                 'y': y*self.px_size_zyx[1],
                 'z': z*self.px_size_zyx[0],
                 'prob': res_dict['Probs_si'][locations],
#                  'int': res_dict['xyzi_mu'][:,[3]][ch0_locs],
#                  'int_sig': res_dict['xyzi_sigma'][:,[3]][ch0_locs],
                 'x_sig': res_dict['xyzi_sigma'][:,[0]][ch0_locs]*self.px_size_zyx[0],
                 'y_sig': res_dict['xyzi_sigma'][:,[1]][ch0_locs]*self.px_size_zyx[1],
                 'z_sig': res_dict['xyzi_sigma'][:,[2]][ch0_locs]*self.px_size_zyx[2],
                 'comb_sig': torch.sqrt(res_dict['xyzi_sigma'][:,[0]][ch0_locs]**2
                                       +res_dict['xyzi_sigma'][:,[1]][ch0_locs]**2
                                       +res_dict['xyzi_sigma'][:,[2]][ch0_locs]**2)})

        for i in range(res_dict['xyzi_mu'].shape[1]-3):
            df[f'int_{i}'] = res_dict['xyzi_mu'][:,[3+i]][ch0_locs]
            df[f'int_sig_{i}'] = res_dict['xyzi_sigma'][:,[3+i]][ch0_locs]

        return df

    def get_micro_inp(self, res_dict, p_si=None):

        channels = self.codebook.shape[1]
        n_bits = (1.*self.codebook.sum(1)).mean()
        res_dict = self.get_si_resdict(res_dict, p_si)
        locations = res_dict['Samples_si'].nonzero(as_tuple=True)

        n_int = res_dict['xyzi_mu'].shape[1] - 3

        xyzi_ix = [locations[0],locations[2],locations[3], locations[4]]
        x_os_3d = res_dict['xyzi_mu'][:,0][xyzi_ix]
        y_os_3d = res_dict['xyzi_mu'][:,1][xyzi_ix]
        z_os_3d = res_dict['xyzi_mu'][:,2][xyzi_ix]

        if n_int == 1:
            ints_3d = res_dict['xyzi_mu'][:,3][xyzi_ix]
            ints_3d = ints_3d/n_bits
            ints_ret = ints_3d[:,None].repeat_interleave(channels, 1)
            ch_bin = self.codebook.to(ints_ret.device)[locations[1]]
            ints_ret = ints_ret*ch_bin

        if n_int == n_bits:
            code_inds = self.codebook.nonzero(as_tuple=True)[1].reshape([self.codebook.shape[0], -1])
            ints_3d = res_dict['xyzi_mu'][:,3:][locations[0],:,locations[2],locations[3], locations[4]]
            ints_ret = torch.zeros(ints_3d.shape[0], channels).to(ints_3d.device)
            ints_ret.scatter_(index=code_inds.to(ints_ret.device)[locations[1]], dim=1, src=ints_3d)

        if n_int == channels:
            ints_ret = res_dict['xyzi_mu'][:,3:][locations[0],:,locations[2],locations[3], locations[4]]
            ints_ret *= self.codebook.to(ints_ret.device)[locations[1]].ne(0)

        output_shape  = res_dict['Samples_si'].shape
        output_shape  = torch.Size([output_shape[0],channels,output_shape[2],output_shape[3],output_shape[4]])

        return xyzi_ix, x_os_3d, y_os_3d, z_os_3d, ints_ret, output_shape
# p_col = []

# Cell
class ISIPostProcess(SIPostProcess):

    def __init__(self, m1_threshold:float = 0.1, samp_threshold=0.1, px_size_zyx=[100,100,100], diag=False):

        super().__init__(m1_threshold = m1_threshold, samp_threshold=samp_threshold, px_size_zyx=px_size_zyx, diag=diag)
        self.m2_threshold = None

    def forward(self, logits):

        device = logits.device
        p = torch.sigmoid(logits)

        batch_size = p.shape[0]
        n_codes = p.shape[1]

        p = p.reshape(batch_size*n_codes,1,*p.shape[-3:])

        with torch.no_grad():

            p_SI = 0
            tot_mask = torch.ones_like(p)
            max_mask = torch.ones_like(p)

            while max_mask.sum():

                # voxels with probability values > threshold,
                # and which where not previously counted as locations, are canditates
                p_cand = torch.where(p>self.m1_threshold, p, torch.zeros_like(p)) * tot_mask

                # localize maximum (nonzero) values within a 3x3x3 volume
                p_cand = F.max_pool3d(p_cand,3,1,padding=1)
                max_mask = torch.eq(p, p_cand).float()
                max_mask[p==0] = 0

                # Add up probability values from the adjacent pixels
                conv = F.conv3d(p, self.filt.to(device), padding=1)
                p_sum = max_mask * conv

                # Add the integrated probabilities to the return tensor.
                p_SI += torch.clamp_max(p_sum, 1)
                # Voxels that where added can not be added again
                tot_mask *= (torch.ones_like(max_mask) - max_mask)

                # The probability mass that contributed to p_sum is removed.
                p_fac = 1/p_sum
                p_fac[torch.isinf(p_fac)] = 0
                p_fac = torch.clamp_max(p_fac, 1)
                p_proc = F.conv3d(p_fac, self.filt.to(device),padding=1)*p

                p = p - p_proc
                torch.clamp_min_(p, 0)

            return p_SI.reshape(batch_size,n_codes,*p.shape[-3:])