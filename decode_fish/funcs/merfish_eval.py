# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/19_MERFISH_routines.ipynb (unless otherwise specified).

__all__ = ['get_benchmark', 'index', 'get_bin_code', 'norm_features', 'approximate_nearest_code', 'vcorrcoef',
           'code_from_groups', 'group_rounds_seq', 'group_rounds_n_nearest', 'group_logorder', 'code_from_xy_logs',
           'match_bench', 'plot_gene_numbers']

# Cell
from ..imports import *
from .file_io import *
from .emitter_io import *
from .utils import *
from .dataset import *
from .plotting import *
from ..engine.noise import estimate_noise_scale
import shutil
from .visualization import *
from .predict import predict

from numba import njit
from scipy.spatial import cKDTree
from .evaluation import matching

import io, requests
from sklearn.neighbors import NearestNeighbors
from starfish import data
import torch.tensor as T
import pprint

# Cell
def get_benchmark(magnitude_threshold=10**0.75*4):

    bench = pd.read_csv(
        io.BytesIO(requests.get('https://d2nhj9g34unfro.cloudfront.net/MERFISH/benchmark_results.csv').content),
        dtype={'barcode': object})

    #See Fig. S4 https://www.pnas.org/content/113/39/11046

    bench_df = bench.copy()
    bench_df = bench_df[bench_df['total_magnitude']>magnitude_threshold]
    bench_df = bench_df[bench_df['area']>3]

    print(len(bench_df))

    experiment = data.MERFISH(use_test_data=True)
    code_ref = experiment.codebook.data.reshape([140,-1], order='F')
    targets = experiment.codebook.indexes['target']

    return bench_df, code_ref, targets

# Cell
@njit
def index(array, item):
    for idx, val in np.ndenumerate(array):
        if val == item:
            return idx[0]
    return None

def get_bin_code(frame_idx, n_imgs=16):
    code = np.zeros(n_imgs, dtype='int8')
    code[frame_idx] = 1
    return code

def norm_features(code, norm_order = 2):

    norm = np.linalg.norm(code, ord=norm_order, axis=1)
    code = code / norm[:, None]

    return code

def approximate_nearest_code(ref_code, pred_code, targets):

    nn = NearestNeighbors(n_neighbors=1, algorithm='ball_tree', metric='euclidean').fit(ref_code)
    metric_output, indices = nn.kneighbors(pred_code)
    gene_ids = np.ravel(targets.values[indices])

    return np.ravel(metric_output), gene_ids, indices

def vcorrcoef(X,y):
    Xm = np.reshape(np.mean(X,axis=1),(X.shape[0],1))
    ym = np.mean(y)
    r_num = np.sum((X-Xm)*(y-ym),axis=1)
    r_den = np.sqrt(np.sum((X-Xm)**2,axis=1)*np.sum((y-ym)**2))
    r = r_num/r_den
    return r

# Cell
def code_from_groups(loc_df):

    # Extracts binary codes from grouping results.

    loc_df = loc_df[loc_df['group_idx'] > 0]

    # Sort by index
    loc_df = loc_df.sort_values('group_idx').reset_index(drop=True)
    group_idx = loc_df['group_idx'].values
    group_idx = np.array(group_idx, dtype=np.uint32)

    # Find group borders by diffing.
    inds = np.where(np.diff(group_idx))[0] + 1

    xy = loc_df.loc[:,['x','y']].values
    xy_sig = loc_df.loc[:,['x_sig','y_sig']].values
    ints = loc_df.loc[:,'int'].values
    frame_idx = loc_df.loc[:,'frame_idx'].values

    codes, rmses, cc, intsum, logs = [], [], [], [], []

    for i in tqdm(range(len(inds)-1)):

        sl = np.s_[inds[i]:inds[i+1]]

        code = get_bin_code(frame_idx[sl])
        codes.append(code)
        cc.append(code.sum())

        # Assigns various metrics to each group that could be used for filtering.

        rmses.append(np.sqrt(np.mean((xy[sl] - xy[sl].mean(0))**2)))
        intsum.append(ints[sl].sum())

        # Get for all combinations of emitter within the group, weighted by their sigma.
        log_dists = torch.distributions.normal.Normal(T([0,0]), torch.sqrt(T(xy_sig[sl][None])**2 + T(xy_sig[sl][:,None])**2)). \
                                             log_prob(T(xy[sl][None]) - T(xy[sl][:,None])).sum(-1)

        log_dists = torch.triu(log_dists, diagonal=1)
        logs.append(log_dists.sum()/torch.count_nonzero(log_dists))

    res_df = loc_df.iloc[inds[:-1]].copy()
    res_df['code'] = codes
    res_df['cc'] = cc
    res_df['rmses'] = rmses
    res_df['int'] = intsum
    res_df['logdist'] = np.array(logs)

    return res_df

# Cell
def group_rounds_seq(pred_df, group_rad=150):

    # Simple sequential grouping, start with emitters in first round, then loop over other rounds grouping the closest emitter from each round within group_rad.

    loc_df=pred_df.copy()
    N_imgs = loc_df['frame_idx'].max() + 1

    loc_df['group_idx'] = -1

    group_count = 0

    for i in tqdm(range(0, N_imgs-1)):

        i_inds = (loc_df['frame_idx'] == i) & (loc_df['group_idx'] == -1)
        i_df = loc_df[(loc_df['frame_idx'] == i) & (loc_df['group_idx'] == -1)].reset_index(drop=True)
        loc_df.loc[i_inds,'group_idx'] = np.arange(len(i_df)) + group_count
        i_df.loc[:,'group_idx'] = np.arange(len(i_df)) + group_count
        group_count += len(i_df)

        tree = cKDTree(i_df.loc[:,['x','y']].values)

        for k in range(i+1, N_imgs):

            k_df = loc_df[(loc_df['frame_idx'] == k) & (loc_df['group_idx'] == -1)].reset_index(drop=True)
            dists, inds = tree.query(k_df.loc[:,['x','y']].values, distance_upper_bound=group_rad)

            i_inds, k_inds = np.unique(inds, return_index=True)
            k_inds = list(k_inds[:-1])
            i_inds = list(i_inds[:-1])

            loc_inds = k_df['loc_idx'].values[k_inds]
            loc_df.loc[loc_inds,'group_idx'] = i_df.loc[i_inds,'group_idx'].values

    return loc_df

# Cell
def group_rounds_n_nearest(pred_df, group_rad=150, n_nearest=15):

    # Start with emitters in first round, group n_nearest emitters from all following imaging rounds.

    loc_df=pred_df.copy()

    N_imgs = loc_df['frame_idx'].max() + 1

    loc_df['group_idx'] = -1
    loc_df['group_logs'] = 0
    print(len(loc_df))

    group_count = 0

    for i in tqdm(range(0, N_imgs)):

        i_inds = (loc_df['frame_idx'] == i) & (loc_df['group_idx'] == -1)
        i_df = loc_df[(loc_df['frame_idx'] == i) & (loc_df['group_idx'] == -1)].reset_index(drop=True)
        i_df.loc[:,'group_idx'] = np.arange(len(i_df)) + group_count
        loc_df.loc[i_inds,'group_idx'] = np.arange(len(i_df)) + group_count
        group_count += len(i_df)

        k_df = loc_df[(loc_df['frame_idx'] > i) & (loc_df['group_idx'] == -1)].reset_index(drop=True)

        tree = cKDTree(k_df.loc[:,['x','y']].values)
        dists, inds = tree.query(i_df.loc[:,['x','y']].values, k = n_nearest, distance_upper_bound=group_rad)

        for n in range(n_nearest):

            k_inds, i_inds = np.unique(inds[:, n], return_index=True)
            k_inds = list(k_inds[:-1])
            i_inds = list(i_inds[:-1])


            loc_inds = k_df['loc_idx'].values[k_inds]
            loc_df.loc[loc_inds,'group_idx'] = i_df.loc[i_inds,'group_idx'].values

    return loc_df

# Cell
import torch.tensor as T
def group_logorder(pred_df, group_rad=150, log_lim=-500):

    # Get neighbours withing group rad. Calculate the sigma weighted distance (as log prob) for all neighbours.
    # Loop through them starting with cosest ones. Limit the lenght of groups to 4.
    loc_df=pred_df.copy().reset_index(drop=True)

    N_imgs = loc_df['frame_idx'].max() + 1

    loc_df['group_idx'] = 0

    tree1 = cKDTree(loc_df.loc[:,['x','y']].values)
    tree2 = cKDTree(loc_df.loc[:,['x','y']].values)

    sdm = tree1.sparse_distance_matrix(tree2, group_rad, output_type='ndarray')

    frame_filt = loc_df['frame_idx'].values[sdm['i']] != loc_df['frame_idx'].values[sdm['j']]

    dists = sdm['v'][frame_filt]
    k_inds = sdm['i'][frame_filt]
    i_inds = sdm['j'][frame_filt]

    log_dists = torch.distributions.normal.Normal(T([0,0]), torch.sqrt(T(loc_df.loc[i_inds,['x_sig','y_sig']].values)**2 +
                                                                       T(loc_df.loc[k_inds,['x_sig','y_sig']].values)**2)). \
                                                                       log_prob(T(loc_df.loc[k_inds,['x','y']].values) - T(loc_df.loc[i_inds,['x','y']].values))

    log_dists = log_dists.sum(-1)
    inds = np.argsort(log_dists).flip(0)
    # Every entry is double because the pointclouds are the same.
    log_dists, k_inds, i_inds = [s[inds][::2] for s in [log_dists, k_inds, i_inds]]

    if log_lim:
        inds = log_dists > log_lim
        log_dists, k_inds, i_inds = [s[inds] for s in [log_dists, k_inds, i_inds]]

#     return group_idx, log_dists, k_inds, i_inds
#     group_idx = log_loop(np.array(group_idx), np.array(log_dists), np.array(k_inds), np.array(i_inds))

    group_count = 1
    # Operate on array for much faster calculations
    group_idx = np.array(loc_df['group_idx'].values, dtype=np.uint32)

    for d, k, i in tqdm(zip(np.array(log_dists), np.array(k_inds, dtype=np.uint32), np.array(i_inds, dtype=np.uint32))):

        i_gidx = group_idx[i]
        k_gidx = group_idx[k]

        sum_gidx = i_gidx + k_gidx

        if not sum_gidx:
            # Both not grouped, create new group
            group_idx[i] = group_count
            group_idx[k] = group_count
            group_count += 1
        else:
            if not k_gidx:
                # k not grouped, i grouped. Assign k to i group
                if np.count_nonzero(group_idx == i_gidx) < 4:
                    group_idx[k] = i_gidx
            elif not i_gidx:
                # i not grouped, k grouped. Assign i to k group
                if np.count_nonzero(group_idx == k_gidx) < 4:
                    group_idx[i] = k_gidx
            else:
                if k_gidx != i_gidx:
                    # Both grouped in different groups. Connect if len <= 5
                    if np.count_nonzero(group_idx == k_gidx) + np.count_nonzero(group_idx == i_gidx) <= 5:
                        group_idx[group_idx == k_gidx] = i_gidx

    loc_df['group_idx'] = group_idx

    return loc_df

# Cell
def code_from_xy_logs(pred_df, code_ref, targets, group_rad=150, prob_smoothing=1):

    # Instead of grouping detections, we instead evaluate some metric (logprob) at a specific coordinate
    # across channels and then find the closes code.

    norm_code = norm_features(code_ref)

    loc_df=pred_df.copy()

    N_imgs = loc_df['frame_idx'].max() + 1

    loc_df = loc_df.sort_values('comb_sig').reset_index(drop=True)

    xy = loc_df.loc[:,['x','y']].values
    xy_sig = loc_df.loc[:,['x_sig','y_sig']].values * prob_smoothing
    fr_idx = loc_df.loc[:,'frame_idx'].values
    grouped_bool = np.zeros(len(loc_df))

    tree = cKDTree(xy)
    code_errs = []

    seed_inds = []
    code_err = []
    code_ind = []

    for i in tqdm(range(len(loc_df))):
#     for i in tqdm(range(15000)):
        if not grouped_bool[i]:

            ball_inds = np.array(tree.query_ball_point(xy[i], group_rad))
            ball_inds = ball_inds[grouped_bool[ball_inds] == 0]

            if len(ball_inds) >= 4:

                frame_probs = np.zeros(N_imgs)

                # Evaluate probs at the position of the seed localization
#                 probs = torch.exp(torch.distributions.normal.Normal(T(xy[ball_inds]), T(xy_sig[ball_inds])).log_prob(T(xy[i])).sum(-1))

                cdf = torch.distributions.normal.Normal(T([0,0]), (torch.sqrt(T(xy_sig[ball_inds][None])**2 + T(xy_sig[ball_inds][:,None])**2))).cdf(-abs(T(xy[ball_inds][None]) - T(xy[ball_inds][:,None]))).prod(-1)
                cdf = cdf*(1-torch.diag(torch.ones(len(cdf))))
                probs = (cdf*4).sum(0)/(len(cdf) - 1)

                # If multiple localizations belong the same frame, chose the one with higehst prob.
                sort_inds = np.argsort(-probs)
                sort_fr_idx = fr_idx[ball_inds][sort_inds]
                unique_inds = sort_inds[np.unique(sort_fr_idx, return_index=True)[1]]

                if len(unique_inds) >= 4:

                    ball_inds = ball_inds[unique_inds]
                    frame_probs[fr_idx[ball_inds]] = probs[unique_inds]

#                     frame_probs = np.clip(frame_probs,0.,np.sort(frame_probs[frame_probs.nonzero()])[1])
#                     frame_probs = frame_probs**(1/prob_smoothing)
#                     code_errors = np.sqrt(((norm_code - norm_features(frame_probs[None]))**2).sum(-1))

#                     frame_probs = frame_probs/frame_probs.max()
#                     code_errors = np.sqrt(((code_ref - (frame_probs[None]))**2).sum(-1))

#                     frame_probs = frame_probs**(1/prob_smoothing)
                    code_errors = 1-vcorrcoef(code_ref, frame_probs)

                    min_ind = np.argmin(code_errors)

                    selected = ball_inds[np.intersect1d(fr_idx[ball_inds], code_ref[min_ind].nonzero()[0], assume_unique=True, return_indices=True)[1]]

                    grouped_bool[selected] = 1

                    seed_inds.append(i)
                    code_err.append(code_errors[min_ind])
                    code_ind.append(min_ind)

    loc_df = loc_df.loc[seed_inds]
    loc_df['code_err'] = code_err
    loc_df['code_inds'] = code_ind
    loc_df['gene'] = targets[code_ind]
    loc_df['code'] = code_ref[code_ind]

    return loc_df

# Cell
def match_bench(pred_df, bench_df):

    bench_match = bench_df.copy()
    bench_match.loc[:,'frame_idx'] = 0
    bench_match.loc[:,'loc_idx'] = np.arange(len(bench_match))
    bench_match.loc[:,'int'] = bench_match['total_magnitude']
    bench_match.loc[:,'z'] = 50/100
    bench_match = px_to_nm(bench_match)

    pred_df.loc[:,'frame_idx'] = 0

    _,_,shift = matching(bench_match, pred_df, tolerance=250, print_res=False)
    print(shift)
    bench_match = shift_df(bench_match, shift=-np.array(shift))

    _,_,shift = matching(bench_match, pred_df, tolerance=250, print_res=False)

    bench_match = shift_df(bench_match, shift=-np.array(shift))
    _,matches,shift = matching(bench_match, pred_df, tolerance=250, print_res=True)

    return matches, bench_match

# Cell
def plot_gene_numbers(bench_counts, res_counts, title='', log=True, corr=True):

    if corr:
        r = np.corrcoef(bench_counts, res_counts)[0, 1]
        r = np.round(r, decimals=3)
    else:
        r = np.sum(res_counts)
    x_lim = np.max([bench_counts.max(), res_counts.max()])
    x = np.linspace(0, x_lim)

    plt.scatter(bench_counts, res_counts, 50, zorder=2)
    plt.plot(x, x, '-k', zorder=1)

    plt.xlabel('Gene copy number Benchmark')
    plt.ylabel('Gene copy number DECODE')
    if log:
        plt.xscale('log')
        plt.yscale('log')
    plt.title(f'{title} r = {r}');