{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.train_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop simulator learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43655/112813388.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdecode_fish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdecode_fish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuncs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdecode_fish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuncs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdecode_fish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuncs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memitter_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (mackelab)/Artur/WorkDB/deepstorm/decode_fish/decode_fish/imports.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m from pandas.core.api import (\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;31m# dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mInt8Dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m from pandas.core.groupby import (\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mGrouper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/pandas/core/groupby/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.core.groupby.generic import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mnanops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m )\n\u001b[0;32m---> 64\u001b[0;31m from pandas.core.aggregation import (\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mmaybe_mangle_lambdas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mreconstruct_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/decode_fish_dev2/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/decode_fish_dev2/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/decode_fish_dev2/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/decode_fish_dev2/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/decode_fish_dev2/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/decode_fish_dev2/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "from decode_fish.funcs.evaluation import *\n",
    "from decode_fish.funcs.file_io import *\n",
    "from decode_fish.funcs.emitter_io import *\n",
    "from decode_fish.funcs.utils import *\n",
    "from decode_fish.funcs.dataset import *\n",
    "from decode_fish.funcs.output_trafo import *\n",
    "from decode_fish.funcs.plotting import *\n",
    "from decode_fish.funcs.predict import *\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as D\n",
    "from torch.utils.data import DataLoader\n",
    "import torch_optimizer\n",
    "from decode_fish.engine.microscope import Microscope\n",
    "from decode_fish.engine.model import UnetDecodeNoBn\n",
    "from decode_fish.engine.point_process import PointProcessUniform\n",
    "from decode_fish.engine.gmm_loss import PointProcessGaussian\n",
    "import shutil\n",
    "import wandb\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from decode_fish.funcs.merfish_eval import *\n",
    "# from decode_fish.funcs.visualization vimport get_simulation_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_logger(pred_df, target_df, iteration, data_str='Sim. '):\n",
    "    \n",
    "    perf_dict,matches,shift = matching(target_df, pred_df, print_res=False,  match_genes=True)\n",
    "    if 'Inp' in data_str:\n",
    "        pred_corr = shift_df(pred_df, shift)\n",
    "        perf_dict, _, _ = matching(target_df, pred_corr, print_res=False,  match_genes=True)\n",
    "\n",
    "    wandb.log({data_str +'Metrics/eff_3d': perf_dict['eff_3d']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/jaccard': perf_dict['jaccard']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/rmse_vol': perf_dict['rmse_vol']}, step=iteration)\n",
    "\n",
    "    wandb.log({data_str +'Metrics/precision': perf_dict['precision']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/recall': perf_dict['recall']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/rmse_x': perf_dict['rmse_x']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/rmse_y': perf_dict['rmse_y']}, step=iteration)\n",
    "    wandb.log({data_str +'Metrics/rmse_z': perf_dict['rmse_z']}, step=iteration)   \n",
    "    \n",
    "    return matches\n",
    "    \n",
    "def load_from_eval_dict(eval_dict):\n",
    "    \n",
    "    if eval_dict.reconstruction.enabled:\n",
    "    \n",
    "        eval_img = load_tiff_image(sorted(glob.glob(eval_dict['image_path']))[eval_dict['img_ind']])\n",
    "        eval_img = eval_img[eval_dict['crop_sl']]\n",
    "        eval_df = None\n",
    "        eval_psf = None\n",
    "        if eval_dict['txt_path'] is not None:\n",
    "            txt_path = sorted(glob.glob(eval_dict['txt_path']))[eval_dict['img_ind']]\n",
    "            eval_df = simfish_to_df(txt_path)\n",
    "            eval_df = crop_df(eval_df, eval_dict['crop_sl'], px_size_zyx=eval_dict['px_size_zyx'])\n",
    "\n",
    "        if eval_dict['psf_path'] is not None:\n",
    "            eval_psf = load_tiff_image(eval_dict['psf_path'])\n",
    "            \n",
    "        return eval_img, eval_df, eval_psf\n",
    "            \n",
    "    if eval_dict.code_stats.enabled:\n",
    "        \n",
    "        return None\n",
    "\n",
    "def save_train_state(save_dir, model, microscope, optim_dict, train_iter):\n",
    "    \n",
    "        torch.save({'state_dict':model.state_dict(), 'scaling':[model.inp_scale, model.inp_offset]}, save_dir/'model.pkl')\n",
    "        torch.save(microscope.state_dict(), save_dir/'microscope.pkl')\n",
    "        \n",
    "        save_dict = {k:v.state_dict() for (k,v) in optim_dict.items()}\n",
    "        save_dict['train_iter'] = train_iter\n",
    "        \n",
    "        torch.save(save_dict, save_dir/'training_state.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def train(cfg,\n",
    "          model, \n",
    "          microscope,\n",
    "          post_proc,\n",
    "          dl, \n",
    "          optim_dict,\n",
    "          eval_dict=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Training loop for autoencoder learning. Alternates between a simulator training step to train the inference network\n",
    "    and an autoencoder step to train the PSF (and microscope) parameters.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): DECODE 3D UNet.\n",
    "        microscope (torch.nn.Module): Microscope class that transforms emitter locations into simulated images.\n",
    "        post_proc (torch.nn.Module): Post processing class that transforms emitter probilities deterministically into binary outputs.\n",
    "        dl  (torch.utils.data.dataloader.DataLoader): Dataloader that returns a random sub volume from the real volume, an estiamted emitter density and background.\n",
    "        optim_dict (dict of torch.optim.Optimizer and torch.optim.lr_scheduler): Dict. with optimizer and scheduler objects for the network and gen. model parameters.\n",
    "        eval_dict  (dict, optional): Dictionary with evaluation parameters\n",
    "        \n",
    "    \"\"\" \n",
    "    \n",
    "    save_dir = Path(cfg.output.save_dir)\n",
    "    \n",
    "    if eval_dict is not None:\n",
    "        eval_vars = load_from_eval_dict(eval_dict)\n",
    "\n",
    "    model.cuda().train()\n",
    "    \n",
    "    # Save initial psf state\n",
    "    torch.save(microscope.psf.state_dict(), str(save_dir) + '/psf_init.pkl' )\n",
    "    \n",
    "    # Load codebook \n",
    "    if 'codebook' in cfg:\n",
    "        bench_df, code_ref, targets = hydra.utils.instantiate(cfg.codebook)\n",
    "#         bench_df = exclude_borders(bench_df, border_size_zyx=[0,4000,4000], img_size=[2048*100,2048*100,2048*100])\n",
    "    \n",
    "    # Controls which genmodel parameters are optimized\n",
    "    for name, p in microscope.named_parameters():\n",
    "        p.requires_grad = cfg.training.mic.par_grads[name]\n",
    "    \n",
    "    for batch_idx in range(cfg.training.start_iter, cfg.training.num_iters):\n",
    "        \n",
    "        t0 = time.time()\n",
    "        x, local_rate, background = next(iter(dl))\n",
    "        \n",
    "#         print('Iter ', time.time()-t0); t0 = time.time()\n",
    "        \n",
    "        optim_dict['optim_net'].zero_grad()\n",
    "        \n",
    "        sim_vars = PointProcessUniform(local_rate[:,0], int_conc=model.int_dist.int_conc.detach(), \n",
    "                                       int_rate=model.int_dist.int_rate.detach(), int_loc=model.int_dist.int_loc.detach(), \n",
    "                                       sim_iters=5, channels=cfg.genm.exp_type.n_channels, n_bits=cfg.genm.exp_type.n_bits, \n",
    "                                       sim_z=cfg.genm.exp_type.pred_z, codebook=torch.tensor(code_ref, dtype=torch.bool), int_option=cfg.training.int_option).sample(from_code_book=True)\n",
    "        \n",
    "        # sim_vars = locs_sl, x_os_sl, y_os_sl, z_os_sl, ints_sl, output_shape, codes\n",
    "#         print('Sim, ', time.time()-t0); t0 = time.time()\n",
    "        xsim = microscope(*sim_vars[:-1], add_noise=True)\n",
    "#         print('Micro, ', time.time()-t0); t0 = time.time()\n",
    "        \n",
    "        if cfg.genm.emitter_noise.rate_fac:\n",
    "            \n",
    "            noise_vars = PointProcessUniform(local_rate[:,0] * cfg.genm.emitter_noise.rate_fac, int_conc=model.int_dist.int_conc.detach() * cfg.genm.emitter_noise.int_fac, \n",
    "                                           int_rate=model.int_dist.int_rate.detach(), int_loc=model.int_dist.int_loc.detach(), \n",
    "                                           sim_iters=5, channels=cfg.genm.exp_type.n_channels, n_bits=1, \n",
    "                                           sim_z=cfg.genm.exp_type.pred_z, codebook=None, int_option=cfg.training.int_option).sample(from_code_book=False)     \n",
    "            \n",
    "#             print('Em. sim ', time.time()-t0); t0 = time.time()\n",
    "            xsim += microscope(*noise_vars[:-1], add_noise=True)\n",
    "#             print('Em Micro, ', time.time()-t0); t0 = time.time()\n",
    "\n",
    "        xsim_noise = microscope.noise(xsim, background, const_theta_sim=cfg.genm.exp_type.const_theta_sim).sample()\n",
    "        \n",
    "        out_sim = model.tensor_to_dict(model(xsim_noise, shuffle_ch=cfg.training.shuffle_ch))\n",
    "        \n",
    "        ppg = PointProcessGaussian(**out_sim)\n",
    "        \n",
    "        count_prob, spatial_prob = ppg.log_prob(*sim_vars[:5], codes=sim_vars[-1], n_bits=cfg.genm.exp_type.n_bits, channels=cfg.genm.exp_type.n_channels, \n",
    "                                                loss_option=cfg.training.loss_option, count_mult=cfg.training.count_mult, cat_logits=cfg.training.cat_logits,\n",
    "                                                slice_rec=cfg.genm.exp_type.slice_rec)\n",
    "        \n",
    "        gmm_loss = -(spatial_prob + cfg.training.net.cnt_loss_scale*count_prob).mean()\n",
    "        \n",
    "        background_loss = F.mse_loss(out_sim['background'], background) * cfg.training.net.bl_loss_scale\n",
    "\n",
    "        loss = gmm_loss + background_loss\n",
    "        \n",
    "        # Update network parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        if cfg.training.net.grad_clip: torch.nn.utils.clip_grad_norm_(model.network.parameters(), max_norm=cfg.training.net.grad_clip, norm_type=2)\n",
    "\n",
    "        optim_dict['optim_net'].step()\n",
    "        optim_dict['sched_net'].step()\n",
    "        \n",
    "#         print('SL ', time.time()-t0); t0 = time.time()\n",
    "            \n",
    "        if batch_idx > min(cfg.training.start_mic,cfg.training.start_int):\n",
    "            \n",
    "            out_inp = model.tensor_to_dict(model(x, shuffle_ch=cfg.training.shuffle_ch))\n",
    "            proc_out_inp = post_proc.get_micro_inp(out_inp, torch.tensor(code_ref), n_bits=cfg.genm.exp_type.n_bits, channels=cfg.genm.exp_type.n_channels)\n",
    "            \n",
    "            if cfg.training.mic.enabled and batch_idx > cfg.training.start_mic:\n",
    "                \n",
    "                optim_dict['optim_mic'].zero_grad()\n",
    "\n",
    "                # Get autoencoder loss\n",
    "                ae_img = microscope(*proc_out_inp, add_noise=False)\n",
    "                \n",
    "                log_p_x_given_z = -microscope.noise(ae_img,out_inp['background'], const_theta_sim=False).log_prob(x).mean()\n",
    "                if cfg.training.mic.norm_reg:\n",
    "                    log_p_x_given_z += cfg.training.mic.norm_reg * (microscope.psf.com_loss())\n",
    "                    \n",
    "                log_p_x_given_z.backward()\n",
    "                if cfg.training.mic.grad_clip:\n",
    "                    torch.nn.utils.clip_grad_norm_(microscope.parameters(), max_norm=cfg.training.mic.grad_clip, norm_type=2)\n",
    "                    \n",
    "                optim_dict['optim_mic'].step()\n",
    "                optim_dict['sched_mic'].step()\n",
    "                \n",
    "#                 print('PSF ', time.time()-t0); t0 = time.time()\n",
    "            \n",
    "            if  cfg.training.int.enabled and batch_idx > cfg.training.start_int and len(proc_out_inp[4]):\n",
    "                \n",
    "                optim_dict['optim_int'].zero_grad()\n",
    "                ints = proc_out_inp[4]\n",
    "                ints = torch.clamp_min(ints, model.int_dist.int_loc.detach() + 0.01)\n",
    "\n",
    "                gamma_int = D.Gamma(model.int_dist.int_conc, model.int_dist.int_rate)\n",
    "                loc_trafo = [D.AffineTransform(loc=model.int_dist.int_loc.detach(), scale=1)]\n",
    "                int_loss = -D.TransformedDistribution(gamma_int, loc_trafo).log_prob(ints.detach()).mean()\n",
    "                \n",
    "                if cfg.training.int.grad_clip:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.int_dist.parameters(), max_norm=cfg.training.mic.grad_clip, norm_type=2)\n",
    "                \n",
    "                int_loss.backward()\n",
    "                optim_dict['optim_int'].step()\n",
    "                optim_dict['sched_int'].step()\n",
    "                \n",
    "#                 print('INT ', time.time()-t0); t0 = time.time()\n",
    "\n",
    "        # Logging\n",
    "        if batch_idx % 10 == 0:\n",
    "            wandb.log({'SL Losses/xyz_loss': spatial_prob.mean().detach().cpu().item()}, step=batch_idx)\n",
    "#             wandb.log({'SL Losses/ints_loss': int_prob.mean().detach().cpu().item()}, step=batch_idx)\n",
    "            wandb.log({'SL Losses/count_loss': (-count_prob.mean()).detach().cpu()}, step=batch_idx)\n",
    "#             wandb.log({'SL Losses/bg_loss': background_loss.detach().cpu()}, step=batch_idx)\n",
    "            wandb.log({'AE Losses/int_mu': model.int_dist.int_conc.item()/model.int_dist.int_rate.item() + model.int_dist.int_loc.item()}, step=batch_idx)\n",
    "            wandb.log({'AE Losses/int_rate': model.int_dist.int_rate.item()}, step=batch_idx)\n",
    "            wandb.log({'AE Losses/int_loc': model.int_dist.int_loc.item()}, step=batch_idx)\n",
    "            wandb.log({'AE Losses/theta': microscope.noise.theta_par.cpu().detach().mean().item()*microscope.noise.theta_scale}, step=batch_idx)\n",
    "\n",
    "            if batch_idx > cfg.training.start_mic: \n",
    "                if cfg.training.mic.enabled:\n",
    "                    wandb.log({'AE Losses/p_x_given_z': log_p_x_given_z.detach().cpu()}, step=batch_idx)\n",
    "                    wandb.log({'AE Losses/RMSE(rec)': torch.sqrt(((x[:,:1]-(ae_img[:,:1]+out_inp['background'][:,:1]))**2).mean()).detach().cpu()}, step=batch_idx)\n",
    "                    wandb.log({'AE Losses/sum(psf)': F.relu(microscope.psf.psf_volume/microscope.psf.psf_volume.max())[0].sum().detach().cpu()}, step=batch_idx)\n",
    "#                     wandb.log({'AE Losses/theta': microscope.theta.item()}, step=batch_idx)\n",
    "        \n",
    "        if batch_idx % cfg.output.log_interval == 0:\n",
    "#             print(batch_idx)\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                pred_df = post_proc.get_df(out_sim)\n",
    "                px_size = cfg.evaluation.px_size_zyx\n",
    "                target_df = sample_to_df(*sim_vars[:5], sim_vars[-1], px_size_zyx=px_size)\n",
    "#                 print(len(pred_df), len(target_df))\n",
    "                matches = eval_logger(pred_df, target_df, batch_idx, data_str='Sim. ')\n",
    "                \n",
    "                wandb.log({'Sim. Metrics/prob_fac': torch.sigmoid(out_sim['logits']).sum().item()/(len(target_df)+0.1)}, step=batch_idx)\n",
    "                wandb.log({'Sim. Metrics/n_em_fac': len(pred_df)/(len(target_df)+0.1)}, step=batch_idx)\n",
    "\n",
    "                if cfg.output.log_figs:\n",
    "            \n",
    "                    sl_fig = sl_plot(x, xsim_noise, nm_to_px(pred_df, px_size), nm_to_px(target_df, px_size), background, out_sim)\n",
    "                    plt.show()\n",
    "                    wandb.log({'SL summary': sl_fig}, step=batch_idx)\n",
    "                    \n",
    "                if cfg.evaluation.reconstruction.enabled:\n",
    "\n",
    "                    eval_img, eval_df, eval_psf = eval_vars\n",
    "\n",
    "                    res_eval = model.tensor_to_dict(model(eval_img[None].cuda()))\n",
    "                    ae_img = microscope(*post_proc.get_micro_inp(res_eval, torch.tensor(code_ref)), n_bits=cfg.genm.exp_type.n_bits, channels=cfg.genm.exp_type.n_channels)\n",
    "                    pred_eval_df = post_proc.get_df(res_eval)\n",
    "                    wandb.log({'AE Losses/N preds(eval)': len(pred_eval_df)}, step=batch_idx)\n",
    "\n",
    "                    if eval_df is not None:\n",
    "                        eval_logger(pred_eval_df, eval_df, batch_idx, data_str='Inp. ')\n",
    "\n",
    "                    if eval_psf is not None:\n",
    "                        wandb.log({'AE Losses/Corr(psf)': np.corrcoef(cpu(eval_psf).reshape(-1), cpu(microscope.psf.psf_volume).reshape(-1))[0,1]}, step=batch_idx)\n",
    "                        wandb.log({'AE Losses/RMSE(psf)': np.sqrt(np.mean((cpu(eval_psf/eval_psf.max())-cpu(microscope.psf.psf_volume/microscope.psf.psf_volume.max()))**2))}, step=batch_idx)\n",
    "\n",
    "                    if cfg.output.log_figs:\n",
    "                        eval_fig = gt_plot(eval_img, nm_to_px(pred_eval_df, px_size), nm_to_px(eval_df, px_size), px_size, ae_img[0]+res_eval['background'][0], microscope.psf)\n",
    "                        plt.show()\n",
    "                        wandb.log({'GT': eval_fig}, step=batch_idx)\n",
    "\n",
    "                if cfg.evaluation.code_stats.enabled:\n",
    "\n",
    "                    res_df = merfish_predict(model, post_proc, [cfg.evaluation.code_stats.image_path], window_size=[None, 256, 256], device='cuda')\n",
    "                    res_df = exclude_borders(res_df, border_size_zyx=[0,4000,4000], img_size=[2048*100,2048*100,2048*100])\n",
    "\n",
    "                    if len(res_df):\n",
    "\n",
    "                        res_df['gene'] = targets[res_df['code_inds']]\n",
    "                        res_df = res_df[res_df['gene'] != 'MALAT1']\n",
    "                        bench_df = bench_df[bench_df['gene'] != 'MALAT1']\n",
    "\n",
    "                        res_sub = res_df.nsmallest(cfg.evaluation.code_stats.top_n, 'comb_sig')\n",
    "\n",
    "                        bench_counts = DF(data=None, index=targets)\n",
    "                        bench_counts['Res_all'] = res_sub.groupby('gene')['gene'].count()\n",
    "                        bench_counts['Bench_all'] = bench_df.groupby('gene')['gene'].count()\n",
    "                        bench_counts = bench_counts.fillna(0)\n",
    "                        r = np.corrcoef(bench_counts['Bench_all'].values, bench_counts['Res_all'].values)[0, 1]   \n",
    "\n",
    "                        blinds = []\n",
    "                        for i,g in enumerate(targets):\n",
    "                            if 'Blank' in g:\n",
    "                                blinds.append(g)\n",
    "\n",
    "                        bc = bench_counts.loc[blinds,'Res_all'].values.sum()\n",
    "\n",
    "                        wandb.log({'AE Losses/code_bench_corr': r}, step=batch_idx)\n",
    "                        wandb.log({'AE Losses/N_blanks_15k': bc}, step=batch_idx)\n",
    "\n",
    "                    wandb.log({'AE Losses/N_pred_tot': len(res_df)}, step=batch_idx)\n",
    "\n",
    "            # storing\n",
    "            save_train_state(save_dir, model, microscope, optim_dict, batch_idx) \n",
    "            \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('../config/experiment/MERFISH_mop_2b.yaml')\n",
    "# cfg = OmegaConf.load('../config/experiment/MERFISH_ci_2d_sl19.yaml')\n",
    "cfg.run_name = 'test'\n",
    "\n",
    "cfg.output.log_interval = 100\n",
    "cfg.training.start_mic = 100000\n",
    "cfg.training.start_int = 100000\n",
    "\n",
    "psf, noise, micro = load_psf_noise_micro(cfg)\n",
    "post_proc = hydra.utils.instantiate(cfg.post_proc_isi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_3d, decode_dl = get_dataloader(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_offset, inp_scale = get_forward_scaling(img_3d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_offset, inp_scale = get_forward_scaling(img_3d[0])\n",
    "# inp_scale = 300\n",
    "# inp_offset = 100\n",
    "model = hydra.utils.instantiate(cfg.network, inp_scale=inp_scale, inp_offset=inp_offset)\n",
    "\n",
    "psf  .to('cuda')\n",
    "model.to('cuda')\n",
    "micro.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_dict = {}\n",
    "optim_dict['optim_net'] = hydra.utils.instantiate(cfg.training.net.opt, params=model.parameters())\n",
    "optim_dict['optim_mic'] = hydra.utils.instantiate(cfg.training.mic.opt, params=micro.parameters())\n",
    "optim_dict['optim_int'] = hydra.utils.instantiate(cfg.training.int.opt, params=model.int_dist.parameters())\n",
    "\n",
    "optim_dict['sched_net'] = hydra.utils.instantiate(cfg.training.net.sched, optimizer=optim_dict['optim_net'])\n",
    "optim_dict['sched_mic'] = hydra.utils.instantiate(cfg.training.mic.sched, optimizer=optim_dict['optim_mic'])\n",
    "optim_dict['sched_int'] = hydra.utils.instantiate(cfg.training.int.sched, optimizer=optim_dict['optim_int'])\n",
    "\n",
    "if cfg.evaluation.reconstruction.enabled:\n",
    "    eval_dict = dict(cfg.evaluation.reconstruction)\n",
    "    eval_dict['crop_sl'] = eval(eval_dict['crop_sl'],{'__builtins__': None},{'s_': np.s_})\n",
    "    eval_dict['px_size_zyx'] = list(eval_dict['px_size_zyx'])\n",
    "else:\n",
    "    eval_dict = None\n",
    "    \n",
    "save_dir = Path(cfg.output.save_dir)\n",
    "save_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume training from a previous checkpoint\n",
    "\n",
    "# cfg.data_path.model_init = cfg.output.save_dir\n",
    "if cfg.data_path.model_init is not None:\n",
    "    print('loading')\n",
    "    model = load_model_state(model, Path(cfg.data_path.model_init)/'model.pkl').cuda()\n",
    "    micro.load_state_dict(torch.load(Path(cfg.data_path.model_init)/'microscope.pkl'))\n",
    "    \n",
    "    train_state_dict = torch.load(Path(cfg.data_path.model_init)/'training_state.pkl')\n",
    "    for k in optim_dict:\n",
    "        optim_dict[k].load_state_dict(train_state_dict[k])\n",
    "        \n",
    "    cfg.training.start_iter = train_state_dict['train_iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_df, code_ref, targets = hydra.utils.instantiate(cfg.codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, local_rate, background = next(iter(decode_dl))\n",
    "\n",
    "optim_dict['optim_net'].zero_grad()\n",
    "        \n",
    "sim_vars = PointProcessUniform(local_rate[:,0], int_conc=model.int_dist.int_conc.detach(), \n",
    "                               int_rate=model.int_dist.int_rate.detach(), int_loc=model.int_dist.int_loc.detach(), \n",
    "                               sim_iters=5, channels=cfg.genm.exp_type.n_channels, n_bits=cfg.genm.exp_type.n_bits, \n",
    "                               sim_z=cfg.genm.exp_type.pred_z, codebook=torch.tensor(code_ref, dtype=torch.bool), int_option=cfg.training.int_option).sample(from_code_book=True)\n",
    "xsim = micro(*sim_vars[:-1], add_noise=True)\n",
    "xsim_noise = micro.noise(xsim, background, const_theta_sim=cfg.genm.exp_type.const_theta_sim).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outp = model.tensor_to_dict(model(xsim_noise)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sl_plot(x, xsim, pred_df, target_df, background, res):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        fig = plt.figure(figsize=(20,4))\n",
    "        plt.subplot(151)\n",
    "        im = plt.imshow(x[0][0].cpu().numpy().max(0))\n",
    "        add_colorbar(im)\n",
    "        plt.axis('off')\n",
    "        plt.title('Real image')\n",
    "\n",
    "        plt.subplot(152)\n",
    "        im = plt.imshow(xsim[0][0].cpu().numpy().max(0))\n",
    "        add_colorbar(im)\n",
    "        plt.axis('off')\n",
    "        plt.title('Sim. image')\n",
    "\n",
    "        plt.subplot(153)\n",
    "        im = plt.imshow(torch.sigmoid(res['logits'][0][0]).cpu().numpy().max(0))\n",
    "        add_colorbar(im)\n",
    "        plt.axis('off')\n",
    "        plt.title('Predicted locations')\n",
    "\n",
    "        plt.subplot(154)\n",
    "        im = plt.imshow(res['xyzi_sigma'][0][0].cpu().numpy().max(0))\n",
    "        add_colorbar(im)\n",
    "        plt.axis('off')\n",
    "        plt.title('Predicted locations')\n",
    "\n",
    "        plt.subplot(155)\n",
    "        im = plt.imshow(res['background'][0][0].cpu().numpy().max(0))\n",
    "        add_colorbar(im)\n",
    "        plt.axis('off')\n",
    "        plt.title('Predicted background')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sl_plot(x, xsim_noise, None, None, background, outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cpu(outp['logits'].reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = wandb.init(project=cfg.output.project, \n",
    "               config=OmegaConf.to_container(cfg, resolve=True),\n",
    "               dir=cfg.output.log_dir,\n",
    "               group=cfg.output.group,\n",
    "               name=cfg.run_name,\n",
    "               mode='disabled'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(cfg=cfg,\n",
    "     model=model, \n",
    "     microscope=micro, \n",
    "     post_proc=post_proc,\n",
    "     dl=decode_dl, \n",
    "     optim_dict=optim_dict, \n",
    "     eval_dict=eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode_fish_dev2]",
   "language": "python",
   "name": "conda-env-decode_fish_dev2-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
