# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/09_output_trafo.ipynb (unless otherwise specified).

__all__ = ['sample_to_df', 'df_to_micro', 'SIPostProcess', 'ISIPostProcess']

# Cell
from ..imports import *
from .utils import *
import torch.nn.functional as F
from .plotting import *
from .emitter_io import *

# Cell
# def sample_to_df(locs, x_os, y_os, z_os, ints, px_size_zyx=[100,100,100], channels=16, n_bits=4):

#     x = locs[-1] + x_os + 0.5
#     y = locs[-2] + y_os + 0.5
#     z = locs[-3] + z_os + 0.5

#     b_inds = torch.cat([torch.tensor([0], device=x_os.device),((x_os[1:] - x_os[:-1]).nonzero() + 1)[:,0],
#                         torch.tensor([len(x_os)], device=x_os.device)])
#     n_gt = len(b_inds) - 1

#     frame_idx = locs[0]
#     ch_idx = locs[1]

#     loc_idx = []
#     for i in range(n_gt):
#         loc_idx += [i] * (b_inds[i+1] - b_inds[i])

#     df = DF({'loc_idx': loc_idx,
#              'frame_idx': frame_idx.cpu(),
#              'ch_idx': ch_idx.cpu(),
#              'x': x.cpu()*px_size_zyx[2],
#              'y': y.cpu()*px_size_zyx[1],
#              'z': z.cpu()*px_size_zyx[0],
#              'int': ints.cpu()})

#     int_arr = np.zeros([n_gt, channels])
#     int_arr[df['loc_idx'], df['ch_idx']] = ints.cpu()

#     df = df.iloc[cpu(b_inds[:-1])]
#     for i in range(16):
#         df[f'int_{i}'] = int_arr[:,i]

#     return df

def sample_to_df(locs, x_os, y_os, z_os, ints, codes, px_size_zyx=[100,100,100], channels=16, n_bits=4):

    x = locs[-1] + x_os + 0.5
    y = locs[-2] + y_os + 0.5
    z = locs[-3] + z_os + 0.5

    b_inds = torch.cat([torch.tensor([0], device=x_os.device),((x_os[1:] - x_os[:-1]).nonzero() + 1)[:,0],
                        torch.tensor([len(x_os)], device=x_os.device)])
    n_gt = len(b_inds) - 1

    frame_idx = locs[0]
    ch_idx = locs[1]

    loc_idx = []
    for i in range(n_gt):
        loc_idx += [i] * (b_inds[i+1] - b_inds[i])

    df = DF({'loc_idx': loc_idx,
             'frame_idx': frame_idx.cpu(),
             'x': x.cpu()*px_size_zyx[2],
             'y': y.cpu()*px_size_zyx[1],
             'z': z.cpu()*px_size_zyx[0]})

    int_arr = np.zeros([n_gt, channels])
    int_arr[df['loc_idx'], ch_idx.cpu()] = ints.cpu()

    df = df.iloc[cpu(b_inds)[:-1]]
    for i in range(16):
        df[f'int_{i}'] = int_arr[:,i]

    df['code_inds'] = codes
    df['ints'] = int_arr.sum(-1)

    return df

def df_to_micro(df, px_size_zyx=[100,100,100]):

    locs = tuple([torch.tensor(df['frame_idx'],dtype=torch.int64).cuda(),
                 torch.zeros(len(df),dtype=torch.int64).cuda(),
                 torch.tensor((df['z']/px_size_zyx[0] + 0.5),dtype=torch.int64).cuda(),
                 torch.tensor((df['y']/px_size_zyx[1] + 0.5),dtype=torch.int64).cuda(),
                 torch.tensor((df['x']/px_size_zyx[2] + 0.5),dtype=torch.int64).cuda()])
    z = (torch.tensor(df['z'],dtype=torch.float32).cuda()-locs[2]*px_size_zyx[0])/px_size_zyx[0] - 0.5
    y = (torch.tensor(df['y'],dtype=torch.float32).cuda()-locs[3]*px_size_zyx[1])/px_size_zyx[1] - 0.5
    x = (torch.tensor(df['x'],dtype=torch.float32).cuda()-locs[4]*px_size_zyx[2])/px_size_zyx[2] - 0.5
    ints = torch.tensor(df['int']).cuda()

    return locs, x, y, z, ints

# Cell
class SIPostProcess(torch.nn.Module):

    def __init__(self, m1_threshold:float = 0.03, m2_threshold:float = 0.3, samp_threshold=0.1, px_size_zyx=[100,100,100], diag=0):

        super().__init__()
        self.m1_threshold = m1_threshold
        self.m2_threshold = m2_threshold
        self.samp_threshold = samp_threshold
        self.diag = diag
        self.px_size_zyx = px_size_zyx

        if not diag:
            d1 = 0; d2 = 0
        else:
            d1 = 1/np.sqrt(2); d2 = 1/np.sqrt(3)
#             d1 = 1; d2 = 1
        self.filt = torch.FloatTensor([[[d2,d1,d2],[d1,1,d1],[d2,d1,d2]],
                                       [[d1, 1,d1],[1, 1, 1],[d1, 1,d1]],
                                       [[d2,d1,d2],[d1,1,d1],[d2,d1,d2]]])[None,None]

    def forward(self, logits):

        device = logits.device
        p = torch.sigmoid(logits)

        with torch.no_grad():

            p_copy = p + 0

            # probability values > threshold are regarded as possible locations
            p_clip = torch.where(p>self.m1_threshold,p,torch.zeros_like(p))

            # localize maximum values within a 3x3 patch
            pool = F.max_pool3d(p_clip,3,1,padding=1)
            max_mask1 = torch.eq(p, pool).float()

            # Add probability values from the 4 adjacent pixels
            conv = F.conv3d(p, self.filt.to(device) ,padding=1)
            p_ps1 = (max_mask1 * conv)

            # In order do be able to identify two fluorophores in adjacent pixels we look for probablity values > 0.5 that are not part of the first mask

            p_copy *= (1-max_mask1)
            p_clip = torch.where(p_copy>self.m2_threshold, p_copy,torch.zeros_like(p_copy))
            max_mask2 = torch.where(p_copy>self.m2_threshold, torch.ones_like(p_copy),torch.zeros_like(p_copy))
            p_ps2 = max_mask2*conv

            # This is our final clustered probablity which we then threshold (normally > 0.7) to get our final discrete locations
            p_ps = p_ps1 + p_ps2

            return p_ps

    def get_si_resdict(self, res_dict, p_si=None):

        if p_si is None:
            p_si = self.forward(res_dict['logits'])

        res_dict['Probs_si'] = p_si
        res_dict['Samples_si'] = torch.where(res_dict['Probs_si'] > self.samp_threshold, torch.ones_like(res_dict['Probs_si']), torch.zeros_like(res_dict['Probs_si']))

        return res_dict

    def get_df(self, res_dict, p_si=None, softmax=False):

        res_dict = self.get_si_resdict(res_dict, p_si)

        res_dict = {k:v.cpu() for (k,v) in res_dict.items()}
        locations = res_dict['Samples_si'].nonzero(as_tuple=True)
        ch0_locs = locations[0], locations[1]*0, locations[2] ,locations[3], locations[4]

        pos_x, pos_y, pos_z = locations[-1] ,locations[-2], locations[-3]

        x = pos_x + res_dict['xyzi_mu'][:,[0]][ch0_locs] + 0.5
        y = pos_y + res_dict['xyzi_mu'][:,[1]][ch0_locs] + 0.5
        z = pos_z + res_dict['xyzi_mu'][:,[2]][ch0_locs] + 0.5

        loc_idx = torch.arange(len(x))
        frame_idx = locations[0]

        df = DF({'loc_idx': loc_idx,
                 'frame_idx': frame_idx,
                 'code_inds': locations[1],
                 'x': x*self.px_size_zyx[2],
                 'y': y*self.px_size_zyx[1],
                 'z': z*self.px_size_zyx[0],
                 'prob': res_dict['Probs_si'][locations],
                 'int': res_dict['xyzi_mu'][:,[3]][ch0_locs],
                 'int_sig': res_dict['xyzi_sigma'][:,[3]][ch0_locs],
                 'x_sig': res_dict['xyzi_sigma'][:,[0]][ch0_locs]*self.px_size_zyx[0],
                 'y_sig': res_dict['xyzi_sigma'][:,[1]][ch0_locs]*self.px_size_zyx[1],
                 'z_sig': res_dict['xyzi_sigma'][:,[2]][ch0_locs]*self.px_size_zyx[2],
                 'comb_sig': torch.sqrt(res_dict['xyzi_sigma'][:,[0]][ch0_locs]**2
                                       +res_dict['xyzi_sigma'][:,[1]][ch0_locs]**2
                                       +res_dict['xyzi_sigma'][:,[2]][ch0_locs]**2)})

        return df

    def get_micro_inp(self, res_dict, p_si=None, channel=0):

        res_dict = self.get_si_resdict(res_dict, p_si)

        locations = res_dict['Samples_si'].nonzero(as_tuple=True)
        locations = [l for l in locations]
        x_os_3d = res_dict['xyzi_mu'][:,[0]][locations]
        y_os_3d = res_dict['xyzi_mu'][:,[1]][locations]
        z_os_3d = res_dict['xyzi_mu'][:,[2]][locations]
        output_shape  = res_dict['Samples_si'].shape

        int_p_mask = torch.where(torch.sigmoid(res_dict['int_logits']) > 0.8, torch.ones_like(res_dict['int_logits']), torch.zeros_like(res_dict['int_logits']))
        ints_3d = (int_p_mask * res_dict['xyzi_mu'][:,3:])[:,[channel]][locations]

#         int_p_mask = torch.where(res_dict['int_logits'] >= res_dict['int_logits'].sort(1, descending=True).values[:,3:4], torch.ones_like(res_dict['int_logits']), torch.zeros_like(res_dict['int_logits']))
#         ints_3d = (int_p_mask * res_dict['xyzi_mu'][:,3:])[:,[channel]][locations]

#         ints_3d = res_dict['xyzi_mu'][:,[3+channel]][locations]

        return locations, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape

# p_col = []

# Cell
class ISIPostProcess(SIPostProcess):

    def __init__(self, m1_threshold:float = 0.1, samp_threshold=0.1, px_size_zyx=[100,100,100], diag=False):

        super().__init__(m1_threshold = m1_threshold, samp_threshold=samp_threshold, px_size_zyx=px_size_zyx, diag=diag)
        self.m2_threshold = None

    def forward(self, logits):

        device = logits.device
        p = torch.sigmoid(logits)

        batch_size = p.shape[0]
        n_codes = p.shape[1]

        p = p.reshape(batch_size*n_codes,1,*p.shape[-3:])

        with torch.no_grad():

            p_SI = 0
            tot_mask = torch.ones_like(p)
            max_mask = torch.ones_like(p)

            while max_mask.sum():

                # voxels with probability values > threshold,
                # and which where not previously counted as locations, are canditates
                p_cand = torch.where(p>self.m1_threshold, p, torch.zeros_like(p)) * tot_mask

                # localize maximum (nonzero) values within a 3x3x3 volume
                p_cand = F.max_pool3d(p_cand,3,1,padding=1)
                max_mask = torch.eq(p, p_cand).float()
                max_mask[p==0] = 0

                # Add up probability values from the adjacent pixels
                conv = F.conv3d(p, self.filt.to(device), padding=1)
                p_sum = max_mask * conv

                # Add the integrated probabilities to the return tensor.
                p_SI += torch.clamp_max(p_sum, 1)
                # Voxels that where added can not be added again
                tot_mask *= (torch.ones_like(max_mask) - max_mask)

                # The probability mass that contributed to p_sum is removed.
                p_fac = 1/p_sum
                p_fac[torch.isinf(p_fac)] = 0
                p_fac = torch.clamp_max(p_fac, 1)
                p_proc = F.conv3d(p_fac, self.filt.to(device),padding=1)*p

                p = p - p_proc
                torch.clamp_min_(p, 0)

            return p_SI.reshape(batch_size,n_codes,*p.shape[-3:])