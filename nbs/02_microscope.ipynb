{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp engine.microscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microscope model\n",
    "\n",
    "> Definition of the classes and functions we use to generate recordings given network outputs or simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of decode_fish.engine.place_psfs failed: Traceback (most recent call last):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from decode_fish.imports import *\n",
    "import torch.nn as nn\n",
    "from decode_fish.funcs.utils import *\n",
    "from torch.jit import script\n",
    "from typing import Union, List\n",
    "import torch.nn.functional as F\n",
    "from decode_fish.funcs.plotting import *\n",
    "from decode_fish.engine.place_psfs import _place_psf, CudaPlaceROI\n",
    "# import elasticdeform.torch as etorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Microscope(nn.Module):\n",
    "    \"\"\"\n",
    "    The Mircoscope module takes  5 vectors 'locations', 'x_os', 'y_os', 'z_os',\n",
    "    'ints_3d' turns them into 3D data through the following steps:\n",
    "    1) Apply continuous shifts to the PSF according to x_os, y_os, z_os\n",
    "    2) Clamping the PSF (retaining only positive values)\n",
    "    3) Normalize the PSF dividing it by it's max value\n",
    "    6) Place point spread function according to locations  to\n",
    "    generate 'x_sim'\n",
    "    7) Multiplies x_sim with scale\n",
    "\n",
    "    Args:\n",
    "        psf (torch.nn.Module): Parametric PSF\n",
    "        noise (torch.nn.Module): Camera noise model\n",
    "        scale(float): Constant for scaling \n",
    "        \n",
    "    Shape:\n",
    "        -Input: locations: Tuple(torch.Tensor)\n",
    "                x_os_val: (N_emitters,)\n",
    "                y_os_val: (N_emitters,)\n",
    "                z_os_val: (N_emitters,)\n",
    "                ints_val: (N_emitters,C)\n",
    "                output_shape: Shape Tuple(BS, C, H, W, D)\n",
    "\n",
    "        -Output: xsim: (BS, C, H, W, D)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, psf: torch.nn.Module=None, noise: Union[torch.nn.Module, None]=None, scale: float = 10000., norm='max', psf_noise=0, pos_noise_xy=0, pos_noise_z=0, slice_rec=False, ch_facs=None, ch_cols=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.psf = psf\n",
    "        self.psf_init_vol = psf.psf_volume.detach().to('cuda')\n",
    "        self.scale = scale\n",
    "        self.noise = noise\n",
    "        self.norm = norm\n",
    "        \n",
    "        self.psf_norm_init = 1.\n",
    "        if slice_rec:\n",
    "            if norm == 'sum':\n",
    "                self.psf_norm_init = self.psf.psf_volume.detach().sum(2, keepdim=True).sum(3, keepdim=True).to('cuda')\n",
    "            if norm == 'max':\n",
    "                self.psf_norm_init = self.psf.psf_volume.detach().amax(2, keepdim=True).amax(3, keepdim=True).to('cuda')\n",
    "        else:\n",
    "            if norm == 'sum':\n",
    "                self.psf_norm_init = self.psf.psf_volume.detach().sum().to('cuda')\n",
    "            if norm == 'max':\n",
    "                self.psf_norm_init = self.psf.psf_volume.detach().amax().to('cuda')        \n",
    "        \n",
    "        self.theta = self.noise.theta_scale * self.noise.theta_par\n",
    "        \n",
    "        self.psf_noise = psf_noise\n",
    "        self.pos_noise_xy = pos_noise_xy\n",
    "        self.pos_noise_z = pos_noise_z\n",
    "\n",
    "        self.slice_rec = slice_rec\n",
    "        self.psf_z_size = self.psf.psf_volume.shape[-3]\n",
    "        self.ch_cols = ch_cols\n",
    "        \n",
    "        self.register_parameter(name='channel_shifts', param=self.noise.channel_shifts)\n",
    "        self.ch_scale = 1. if ch_facs is None else torch.tensor(ch_facs).cuda()\n",
    "        self.register_parameter(name='channel_facs', param=torch.nn.Parameter(torch.ones(len(self.channel_shifts))))\n",
    "        self.ch_norm = self.channel_facs.sum().detach().cuda()\n",
    "            \n",
    "        self.register_parameter(name='theta_par', param=self.noise.theta_par)\n",
    "        self.register_parameter(name='psf_vol', param=self.psf.psf_volume)\n",
    "        \n",
    "    def add_psf_noise(self, psf_stack):\n",
    "\n",
    "        '''Gaussian noise'''\n",
    "        noise = torch.distributions.Normal(loc=0, scale=self.psf_noise).sample(psf_stack.shape).to(psf_stack.device)\n",
    "        noise *= torch.sqrt(psf_stack)\n",
    "#         noise *= torch.rand(len(psf_stack), device='cuda')[:,None,None,None,None]\n",
    "        return psf_stack + noise\n",
    "    \n",
    "        '''Individual elastic deformation for each PSF (to slow)'''\n",
    "#         psf_deformed = torch.cat([etorch.deform_grid(psf, torch.distributions.Normal(loc=0, scale=self.psf_noise).sample([3,3,3,3]).to(psf_stack.device), order=3)[None] \n",
    "#                                   for psf in psf_stack[:,0]])\n",
    "        '''Single deformation for all PSF in batch (kinda stupid)'''\n",
    "#         psf_deformed = etorch.deform_grid(psf_stack[:,0], torch.distributions.Normal(loc=0, scale=self.psf_noise).sample([3,3,3,3]).to(psf_stack.device), axis=(1,2,3),order=3)\n",
    "#         return psf_deformed[:,None]\n",
    "\n",
    "    def add_pos_noise(self, x_os, y_os, z_os):\n",
    "        \n",
    "        # Hardcoded n_bits for now. \n",
    "        x_n = torch.distributions.Normal(loc=0, scale=self.pos_noise_xy).sample(x_os.shape).to(x_os.device).reshape(-1,4)\n",
    "        x_n -= x_n.mean(-1, keepdim=True)\n",
    "        x_os = x_os + x_n.reshape(-1)\n",
    "        y_n = torch.distributions.Normal(loc=0, scale=self.pos_noise_xy).sample(y_os.shape).to(y_os.device).reshape(-1,4)\n",
    "        y_n -= y_n.mean(-1, keepdim=True)\n",
    "        y_os = y_os + y_n.reshape(-1)\n",
    "        z_n = torch.distributions.Normal(loc=0, scale=self.pos_noise_z).sample(z_os.shape).to(z_os.device).reshape(-1,4)\n",
    "        z_n -= z_n.mean(-1, keepdim=True)\n",
    "        z_os = z_os + z_n.reshape(-1)\n",
    "        \n",
    "        return x_os, y_os, z_os\n",
    "\n",
    "    def get_single_ch_inputs(self, locations, x_os_val, y_os_val, z_os_val, i_val, output_shape=None):\n",
    "        \n",
    "        ch_inds = i_val.nonzero(as_tuple=True)\n",
    "        if ch_inds[1].max() > 0:\n",
    "            shifts = self.channel_shifts - self.channel_shifts.mean(0)[None]\n",
    "\n",
    "            x_os_ch = x_os_val[ch_inds[0]] + shifts[ch_inds[1], 0]\n",
    "            y_os_ch = y_os_val[ch_inds[0]] + shifts[ch_inds[1], 1]\n",
    "            z_os_ch = z_os_val[ch_inds[0]] + shifts[ch_inds[1], 2]\n",
    "\n",
    "            i_val = i_val[ch_inds]\n",
    "            \n",
    "            locations = [l[ch_inds[0]] for l in locations]\n",
    "            locations.insert(1,ch_inds[1])   \n",
    "            \n",
    "        return locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape\n",
    "    \n",
    "    def get_psf_norm(self, c_inds = None, z_inds=None):\n",
    "        \n",
    "        if self.norm != 'max' and self.norm != 'sum':\n",
    "            return 1.\n",
    "        if not self.slice_rec:\n",
    "            if self.norm == 'max': psf_norm = self.psf.psf_volume.max() \n",
    "            if self.norm == 'sum': psf_norm = torch.clamp_min(self.psf.psf_volume, 0).sum() \n",
    "            init = self.psf_norm_init     \n",
    "        else:\n",
    "            if self.norm == 'max':\n",
    "                psf_norm = self.psf.psf_volume.amax(2, keepdim=True).amax(3, keepdim=True)\n",
    "            if self.norm == 'sum':\n",
    "                psf_norm = torch.clamp_min(self.psf.psf_volume, 0).sum(2, keepdim=True).sum(3, keepdim=True)\n",
    "            if c_inds is not None:\n",
    "                psf_norm = psf_norm[c_inds, z_inds][:,:,None,None]\n",
    "                init = self.psf_norm_init[c_inds, z_inds][:,:,None,None]\n",
    "            else:\n",
    "                psf_norm = psf_norm[0,z_inds][:,None,None]\n",
    "                init = self.psf_norm_init[0,z_inds][:,None,None]\n",
    "  \n",
    "        return psf_norm/init\n",
    "        \n",
    "    def forward(self, locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, ret_psfs=False, add_noise=False, add_pos_noise=False):\n",
    "        \n",
    "        if len(locations[0]):\n",
    "            c_inds=torch.tensor(self.ch_cols)[locations[1]] if self.ch_cols is not None else None\n",
    "\n",
    "            # Apply continuous shift\n",
    "            if self.slice_rec and self.psf_z_size > 1:\n",
    "                z_os_ch = torch.clamp(z_os_ch,-0.49999,0.49999) + 0.5 # transform to [0,1]\n",
    "                z_scaled = z_os_ch * (self.psf_z_size - 2) # [0, z_size]\n",
    "                z_inds = (z_scaled//1).type(torch.cuda.LongTensor) + 1\n",
    "                z_os = -(z_scaled%1.) + 0.5\n",
    "\n",
    "                if self.pos_noise_xy and add_pos_noise: \n",
    "                    x_os_ch, y_os_ch, z_os = self.add_pos_noise(x_os_ch, y_os_ch, z_os)\n",
    "\n",
    "                psf = self.psf(x_os_ch, y_os_ch, z_os, z_inds, c_inds=c_inds)\n",
    "#                 psf = psf[torch.arange(len(z_os_ch)),:,z_inds][:,:,None]\n",
    "            else:\n",
    "                if self.pos_noise_xy and add_noise: \n",
    "                    x_os_ch, y_os_ch, z_os_ch = self.add_pos_noise(x_os_ch, y_os_ch, z_os_ch)\n",
    "                psf = self.psf(x_os_ch, y_os_ch, z_os_ch, c_inds=c_inds)\n",
    "                z_inds = None\n",
    "                \n",
    "            torch.clamp_min_(psf,0)\n",
    "            psf = psf/self.get_psf_norm(c_inds, z_inds)\n",
    "            \n",
    "            if self.psf_noise and add_noise: \n",
    "                psf = self.add_psf_noise(psf)\n",
    "                \n",
    "            # applying intenseties\n",
    "#             tot_intensity = torch.clamp_min(i_val, 0)  * self.channel_facs[locations[1]]\n",
    "            tot_intensity = torch.clamp_min(i_val, 0)  * (self.ch_scale * self.channel_facs)[locations[1]] * (self.ch_norm/self.channel_facs.sum())\n",
    "    \n",
    "            psf = psf * tot_intensity[:,None,None,None,None]\n",
    "            \n",
    "            if ret_psfs:\n",
    "                return self.scale * psf\n",
    "            \n",
    "            # place psf according to locations\n",
    "            xsim = place_psf(locations, psf, output_shape)\n",
    "            \n",
    "            # scale (not learnable)\n",
    "            xsim = self.scale * xsim\n",
    "            \n",
    "            return xsim\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return torch.zeros(output_shape).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def place_psf(locations, psf_volume, output_shape):\n",
    "    \"\"\"\n",
    "    Places point spread functions (psf_volume) in to corresponding locations.\n",
    "\n",
    "    Args:\n",
    "        locations: tuple with the 5D voxel coordinates\n",
    "        psf_volume: torch.Tensor\n",
    "        output_shape: Shape Tuple(BS, C, H, W, D) \n",
    "\n",
    "    Returns:\n",
    "        placed_psf: torch.Tensor with shape (BS, C, H, W, D)\n",
    "    \"\"\"\n",
    "\n",
    "    b, c, z, y, x = locations\n",
    "    # Deprecated python loop\n",
    "#     placed_psf = _place_psf(psf_volume, b, c, z, y, x, torch.tensor(output_shape))\n",
    "    \n",
    "    # New fancy cuda loop\n",
    "    N_psfs, _, psf_s_z, psf_s_y, psf_s_x = psf_volume.shape   \n",
    "    placed_psf = CudaPlaceROI.apply(psf_volume[:,0], output_shape[0], output_shape[1], output_shape[2], output_shape[3], output_shape[4], N_psfs, psf_s_z, psf_s_y, psf_s_x, b, c, z-psf_s_z//2, y-psf_s_y//2, x-psf_s_x//2)\n",
    "    \n",
    "    assert placed_psf.shape == output_shape\n",
    "    return placed_psf\n",
    "\n",
    "def extract_psf_roi(locations, x_vol, roi_shape):\n",
    "    \"\"\"\n",
    "    Extract ROIs from a given volume\n",
    "    \"\"\"\n",
    "    \n",
    "    batch, ch, z, y, x = locations \n",
    "    rois = _extract_psf_roi(x_vol, batch, ch, z, y, x, roi_shape)\n",
    "    \n",
    "    return rois\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "def get_roi_filt_inds(batch, ch, z, y, x, psf_shape, vol_shape, min_dist=None, slice_rec=False):\n",
    "    \"\"\"\n",
    "    Filter locations that are used for gen. model training.\n",
    "    Returns remaining indices.\n",
    "    \"\"\"\n",
    "    \n",
    "    inds = torch.arange(len(x))\n",
    "    \n",
    "    if min_dist:\n",
    "        # scale z if slice_rec ?? \n",
    "        bczyx = np.stack([cpu(batch)*1000,cpu(ch)*1000,cpu(z),cpu(y),cpu(x)]).T\n",
    "        tree = KDTree(bczyx)\n",
    "        pairs = tree.query_pairs(r=min_dist, output_type='ndarray')\n",
    "        pair_inds = np.unique(pairs.reshape(-1))\n",
    "        \n",
    "    psf_d, psf_h, psf_w = psf_shape[-3:]\n",
    "    vol_d, vol_h, vol_w = vol_shape[-3:]\n",
    "    # Filter locs at the edges\n",
    "    cond = (x > psf_w//2) & (x < vol_w - psf_w//2)\n",
    "    cond*= (y > psf_h//2) & (y < vol_h - psf_h//2)\n",
    "    if not slice_rec:\n",
    "        cond*= (z > psf_d//2) & (z < vol_d - psf_d)   \n",
    "        \n",
    "    if min_dist:\n",
    "        return np.setdiff1d(inds[cond], pair_inds, assume_unique=True)\n",
    "    else:\n",
    "        return inds[cond]\n",
    "    \n",
    "def mic_inp_apply_inds(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, inds):\n",
    "    \n",
    "    locations = [l[inds] for l in locations]\n",
    "    return locations, x_os_ch[inds], y_os_ch[inds], z_os_ch[inds], i_val[inds], output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@script\n",
    "def _extract_psf_roi(x_vol, batch, ch, z, y, x, roi_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract rois. We assume that border conditions are dealt with already. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    psf_b, psf_ch, psf_d, psf_h, psf_w = roi_shape[0], roi_shape[1], roi_shape[2], roi_shape[3], roi_shape[4]\n",
    "    roi_vol = torch.empty(psf_b, psf_ch, psf_d, psf_h, psf_w).to(x_vol.device)    \n",
    "    pad_zyx = [psf_d//2, psf_h//2, psf_w//2]\n",
    "    \n",
    "    z_l = z - pad_zyx[0]\n",
    "    y_l = y - pad_zyx[1]\n",
    "    x_l = x - pad_zyx[2]\n",
    "    \n",
    "    z_h = z + pad_zyx[0] + 1\n",
    "    y_h = y + pad_zyx[1] + 1\n",
    "    x_h = x + pad_zyx[2] + 1\n",
    "    \n",
    "    for idx in range(x.shape[0]):\n",
    "\n",
    "        roi_vol[idx] = x_vol[batch[idx], ch[idx],\n",
    "                         z_l[idx] : z_h[idx],\n",
    "                         y_l[idx] : y_h[idx],\n",
    "                         x_l[idx] : x_h[idx]]\n",
    "        \n",
    "    return roi_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.engine.psf import LinearInterpolatedPSF\n",
    "from decode_fish.engine.noise import sCMOS\n",
    "from decode_fish.engine.point_process import PointProcessUniform\n",
    "from decode_fish.funcs.file_io import get_gaussian_psf\n",
    "from decode_fish.funcs.file_io import get_vol_psf\n",
    "from decode_fish.funcs.output_trafo import sample_to_df\n",
    "\n",
    "# psf = get_gaussian_psf([3,13,13],[.1,1.7,1.7], pred_z=True, n_cols=2).cuda()\n",
    "psf = get_vol_psf('../figures/MF_psf2.tif', n_cols=2)\n",
    "\n",
    "noise = sCMOS(channels=22)\n",
    "\n",
    "# micro = Microscope(psf=psf, noise=noise, scale=100, norm='sum', sum_fac=psf.psf_volume.sum().item()).cuda()\n",
    "micro = Microscope(psf=psf, noise=noise, scale=100, norm='sum',  psf_noise=0.0, pos_noise_xy=0.7, pos_noise_z=0.3, slice_rec=True).cuda()\n",
    "micro.ch_cols = [0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = OmegaConf.load('../config/experiment/MERFISH_mop_4a.yaml')\n",
    "# from decode_fish.funcs.file_io import load_psf_noise_micro\n",
    "# psf, noise, micro = load_psf_noise_micro(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_shifts True\n",
      "channel_facs True\n",
      "theta_par True\n",
      "psf_vol True\n"
     ]
    }
   ],
   "source": [
    "for name, p in micro.named_parameters():\n",
    "    print(name, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_fish.funcs.exp_specific import *\n",
    "bench_df, code_ref, targets = get_merfish_mop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_process = PointProcessUniform(local_rate = torch.ones([3,7,48,48]).cuda()*.0001, int_conc=3, int_rate=1, int_loc=1, sim_iters=5, channels=22, n_bits=4, sim_z=True, codebook=torch.tensor(code_ref, dtype=torch.bool), int_option=2)\n",
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, codes = point_process.sample(from_code_book=True)\n",
    "locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape = micro.get_single_ch_inputs(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape)\n",
    "# df = sample_to_df(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, codes, px_size_zyx=[1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psfs = micro(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, add_noise=False, ret_psfs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.7/site-packages/numba/cuda/compiler.py:865: NumbaPerformanceWarning: \u001b[1mGrid size (49) < 2 * SM count (160) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "xsim = micro(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, add_noise=True, add_pos_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24087499999999998"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1.0440,  0.7444, -1.0476,  0.2227])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsim2 = micro(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, add_noise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_inds = get_roi_filt_inds(*locations, micro.psf.psf_volume.shape, xsim.shape, slice_rec=True, min_dist=10)\n",
    "ch_out_inp = mic_inp_apply_inds(locations, x_os_ch, y_os_ch, z_os_ch, i_val, output_shape, filt_inds)\n",
    "rois = extract_psf_roi(ch_out_inp[0], xsim, torch.tensor(psfs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# rois = extract_psf_roi(ch_out_inp[0], xsim, torch.tensor(psfs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 11)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4752x864 with 22 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plot_channels(xsim[0]-xsim2[0],2, proj_func=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 55., 145., 248., 216., 175.,  95.,  47.,  15.,   3.,   1.]),\n",
       " array([0.04329047, 0.1671234 , 0.29095635, 0.4147893 , 0.53862226,\n",
       "        0.6624552 , 0.78628814, 0.9101211 , 1.033954  , 1.157787  ,\n",
       "        1.2816199 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cpu(torch.sqrt(torch.distributions.Normal(loc=0, scale=0.3).sample([1000])**2 +\n",
    "torch.distributions.Normal(loc=0, scale=0.3).sample([1000])**2 +\n",
    "torch.distributions.Normal(loc=0, scale=0.3).sample([1000])**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check that 2D Z reconstruction is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_rate = torch.zeros([100,7,11,11]).cuda()\n",
    "local_rate[:,0,5,5] = 1.\n",
    "\n",
    "point_process = PointProcessUniform(local_rate =local_rate, int_conc=3, int_rate=1, sim_iters=1, int_loc=1, channels=22, n_bits=4, codebook=torch.tensor(code_ref)[:1], sim_z=True)\n",
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape, codes = point_process.sample(from_code_book=True)\n",
    "df = sample_to_df(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, codes, px_size_zyx=[1,1,1])\n",
    "\n",
    "x_os_3d *= 0 \n",
    "y_os_3d *= 0 \n",
    "ints_3d *= 0 \n",
    "ints_3d += 1\n",
    "z_os_3d = torch.linspace(-0.7,0.7,100).cuda()\n",
    "\n",
    "ch_inp = micro.get_single_ch_inputs(locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape)\n",
    "\n",
    "psf_s = micro(*ch_inp, add_noise=False, ret_psfs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cpu(psf_s)[::22,0,0,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_micro_inp(res_dict, code_ref, p_si=None, n_bits=4, channels=16):\n",
    "\n",
    "    res_dict['Samples_si'] = torch.where(torch.sigmoid(res_dict['logits']) > 0.0091, 1, 0)\n",
    "    # remove dump inds. Wont get reconstructed. \n",
    "    locations = res_dict['Samples_si'][:,:-1].nonzero(as_tuple=True)\n",
    "\n",
    "    xyzi_ix = [locations[0],locations[2],locations[3], locations[4]]\n",
    "    x_os_3d = res_dict['xyzi_mu'][:,0][xyzi_ix]\n",
    "    y_os_3d = res_dict['xyzi_mu'][:,1][xyzi_ix]\n",
    "    z_os_3d = res_dict['xyzi_mu'][:,2][xyzi_ix]\n",
    "    ints_3d = res_dict['xyzi_mu'][:,3][xyzi_ix]\n",
    "    # output_shape  = res_dict['Samples_si'].shape\n",
    "    ints_3d = ints_3d/n_bits+1\n",
    "\n",
    "    ints_ret = ints_3d[:,None].repeat_interleave(channels, 1)\n",
    "#     ch_bin = torch.zeros(ints_ret.shape).to(ints_ret.device)\n",
    "#     ch_bin.scatter_(index=torch.tensor(code_inds).to(ints_ret.device)[locations[1]], dim=1, value=1)\n",
    "    ch_bin = torch.tensor(code_ref)[locations[1]]\n",
    "    ints_ret = ints_ret*ch_bin.to(ints_ret.device)\n",
    "\n",
    "    output_shape  = res_dict['Samples_si'].shape\n",
    "    output_shape  = torch.Size([output_shape[0],channels,output_shape[2],output_shape[3],output_shape[4]])\n",
    "\n",
    "    return xyzi_ix, x_os_3d, y_os_3d, z_os_3d, ints_ret, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_3d, x_os_3d, y_os_3d, z_os_3d, ints_3d, output_shape = get_micro_inp(res_dict, torch.tensor(code_ref), p_si=None, n_bits = 4, channels=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 20_MERFISH_visualization.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode_fish_dev2]",
   "language": "python",
   "name": "conda-env-decode_fish_dev2-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
