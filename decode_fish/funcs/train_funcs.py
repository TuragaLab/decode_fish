# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/13_train.ipynb (unless otherwise specified).

__all__ = ['eval_logger', 'save_train_state', 'exp_train_eval', 'train']

# Cell
from ..imports import *
from .evaluation import *
from .file_io import *
from .emitter_io import *
from .utils import *
from .dataset import *
from .output_trafo import *
from .plotting import *
from .predict import *
from .visualization import *
import torch.nn.functional as F
from torch import distributions as D
from torch.utils.data import DataLoader
import torch_optimizer
from ..engine.microscope import Microscope, get_roi_filt_inds, extract_psf_roi, mic_inp_apply_inds, add_pos_noise
from ..engine.model import UnetDecodeNoBn
from ..engine.point_process import PointProcessUniform, get_phased_ints
from ..engine.gmm_loss import PointProcessGaussian
import shutil
import wandb
import kornia

from hydra import compose, initialize
from .merfish_eval import *
from .exp_specific import *
# from decode_fish.funcs.visualization vimport get_simulation_statistics

# Cell
def eval_logger(pred_df, target_df, iteration, data_str='Sim. '):

    perf_dict,matches,shift = matching(target_df, pred_df, print_res=False,  match_genes=True)
    if 'Inp' in data_str:
        pred_corr = shift_df(pred_df, shift)
        perf_dict, _, _ = matching(target_df, pred_corr, print_res=False,  match_genes=True)

    wandb.log({data_str +'Metrics/eff_3d': perf_dict['eff_3d']}, step=iteration)
    wandb.log({data_str +'Metrics/jaccard': perf_dict['jaccard']}, step=iteration)
    wandb.log({data_str +'Metrics/rmse_vol': perf_dict['rmse_vol']}, step=iteration)

    wandb.log({data_str +'Metrics/precision': perf_dict['precision']}, step=iteration)
    wandb.log({data_str +'Metrics/recall': perf_dict['recall']}, step=iteration)
    wandb.log({data_str +'Metrics/rmse_x': perf_dict['rmse_x']}, step=iteration)
    wandb.log({data_str +'Metrics/rmse_y': perf_dict['rmse_y']}, step=iteration)
    wandb.log({data_str +'Metrics/rmse_z': perf_dict['rmse_z']}, step=iteration)

    return matches

def save_train_state(save_dir, model, microscope, optim_dict, train_iter):

        torch.save({'state_dict':model.state_dict(), 'scaling':[model.inp_scale, model.inp_offset]}, save_dir/'model.pkl')
        torch.save(microscope.state_dict(), save_dir/'microscope.pkl')

        save_dict = {k:v.state_dict() for (k,v) in optim_dict.items()}
        save_dict['train_iter'] = train_iter

        torch.save(save_dict, save_dir/'training_state.pkl')

def exp_train_eval(bench_df, res_df, targets, wandb, batch_idx):

    if len(res_df):

        res_sub = res_df.nsmallest(len(bench_df), 'comb_sig')

        bench_counts = DF(data=None, index=targets)
        bench_counts['Res_all'] = res_sub.groupby('gene')['gene'].count()
        bench_counts['Bench_all'] = bench_df.groupby('gene')['gene'].count()
        bench_counts = bench_counts.fillna(0)

        r = np.corrcoef(bench_counts['Bench_all'].values, bench_counts['Res_all'].values)[0, 1]

        blinds = []
        for i,g in enumerate(targets):
            if 'Blank' in g:
                blinds.append(g)

        bc = bench_counts.loc[blinds,'Res_all'].values.sum()
        bench_bc = bench_counts.loc[blinds,'Bench_all'].values.sum()

        bench_df['z'] = bench_df['z']/1000
        res_sub['z'] = res_sub['z']/100

        wandb.log({'AE Losses/code_bench_corr': r}, step=batch_idx)
        wandb.log({'AE Losses/N_blanks': bc/bench_bc}, step=batch_idx)

        perf_dict, match_df, shifts = matching(bench_df,  res_sub, tolerance=500)
        wandb.log({'AE Losses/jaccard': perf_dict['jaccard']}, step=batch_idx)

    wandb.log({'AE Losses/N_pred_tot': len(res_df)/len(bench_df)}, step=batch_idx)

# Cell
def train(cfg,
          model,
          microscope,
          post_proc,
          dl,
          optim_dict):

    """
    Training loop for autoencoder learning. Alternates between a simulator training step to train the inference network
    and an autoencoder step to train the PSF (and microscope) parameters.

    Args:
        model (torch.nn.Module): DECODE 3D UNet.
        microscope (torch.nn.Module): Microscope class that transforms emitter locations into simulated images.
        post_proc (torch.nn.Module): Post processing class that transforms emitter probilities deterministically into binary outputs.
        dl  (torch.utils.data.dataloader.DataLoader): Dataloader that returns a random sub volume from the real volume, an estiamted emitter density and background.
        optim_dict (dict of torch.optim.Optimizer and torch.optim.lr_scheduler): Dict. with optimizer and scheduler objects for the network and gen. model parameters.

    """

    save_dir = Path(cfg.output.save_dir)
    bench_df = None

    model.cuda().train()

    # Save initial psf state
    torch.save(microscope.psf.state_dict(), str(save_dir) + '/psf_init.pkl' )

    # Load codebook
    if 'codebook' in cfg:
        code_ref, targets = hydra.utils.instantiate(cfg.codebook)

    # Controls which genmodel parameters are optimized
    for name, p in microscope.named_parameters():
        p.requires_grad = cfg.training.mic.par_grads[name]

    calc_log_p_x = False

    # Hacky way to switch between network / genmodel training
    if cfg.training.schedule is not None:
        sched = cfg.training.schedule
        cfg.training.net.enabled = True
        cfg.training.mic.enabled = False
#         cfg.training.int.enabled = False
        switch_iter = sched.pop(0)

    for batch_idx in range(cfg.training.start_iter, cfg.training.num_iters+1):

        if cfg.training.schedule is not None:
            if batch_idx == switch_iter:
                cfg.training.net.enabled = not(cfg.training.net.enabled)
                cfg.training.mic.enabled = not(cfg.training.mic.enabled)
#                 cfg.training.int.enabled = not(cfg.training.int.enabled)
                switch_iter += sched.pop(0)

        t0 = time.time()
        ret_dict = next(iter(dl))
        # Get real data window and rate/background for the simulation
        x, local_rate, background = ret_dict['x'], ret_dict['local_rate'], ret_dict['background']
        zcrop, ycrop, xcrop = ret_dict['crop_z'], ret_dict['crop_y'], ret_dict['crop_x']

        background = background * microscope.get_ch_mult().detach()
        x = x * microscope.get_ch_mult().detach()

        colshift_crop = get_color_shift_inp(microscope.color_shifts, microscope.col_shifts_yx, ycrop, xcrop, cfg.sim.random_crop.crop_sz)

        if cfg.training.net.enabled:

            optim_dict['optim_net'].zero_grad()

            sim_vars = PointProcessUniform(local_rate[:,0], int_conc=model.int_dist.int_conc.detach(),
                                           int_rate=model.int_dist.int_rate.detach(), int_loc=model.int_dist.int_loc.detach(),
                                           sim_iters=5, channels=cfg.genm.exp_type.n_channels, n_bits=cfg.genm.exp_type.n_bits,
                                           sim_z=cfg.genm.exp_type.pred_z, codebook=torch.tensor(code_ref, dtype=torch.bool), int_option=cfg.training.int_option).sample(from_code_book=True)

            # sim_vars = locs_sl, x_os_sl, y_os_sl, z_os_sl, ints_sl, output_shape, codes
#             print('Sim, ', time.time()-t0); t0 = time.time()
            ch_inp = list(microscope.get_single_ch_inputs(*sim_vars[:-1], ycrop=ycrop.flatten(), xcrop=xcrop.flatten()))
            ch_inp[1:4] = add_pos_noise(ch_inp[1:4], [cfg.genm.pos_noise.pos_noise_xy, cfg.genm.pos_noise.pos_noise_xy, cfg.genm.pos_noise.pos_noise_z], cfg.genm.exp_type.n_bits)
            xsim = microscope(*ch_inp, add_noise=True)

            if cfg.genm.phasing:

                phasing_inp = list(microscope.get_single_ch_inputs(*sim_vars[:4], get_phased_ints(sim_vars[4], microscope.ch_cols, microscope.psf.n_cols) ,sim_vars[5], ycrop=ycrop.flatten(), xcrop=xcrop.flatten()))
                phasing_inp[1:4] = add_pos_noise(phasing_inp[1:4], [cfg.genm.pos_noise.pos_noise_xy, cfg.genm.pos_noise.pos_noise_xy, cfg.genm.pos_noise.pos_noise_z], cfg.genm.exp_type.n_bits, rm_mean=False)
                xsim += microscope(*phasing_inp, add_noise=True) * cfg.genm.phasing * torch.rand(xsim.shape, device=xsim.device)
#             print('Micro, ', time.time()-t0); t0 = time.time()

            # Spurious emitter patterns (not from codebook)
            if cfg.genm.emitter_noise.rate_fac:

                noise_vars = PointProcessUniform(local_rate[:,0] * cfg.genm.emitter_noise.rate_fac, int_conc=model.int_dist.int_conc.detach() * cfg.genm.emitter_noise.int_fac,
                                               int_rate=model.int_dist.int_rate.detach(), int_loc=model.int_dist.int_loc.detach(),
                                               sim_iters=5, channels=cfg.genm.exp_type.n_channels, n_bits=1,
                                               sim_z=cfg.genm.exp_type.pred_z, codebook=None, int_option=cfg.training.int_option).sample(from_code_book=False)

                noise_inp = microscope.get_single_ch_inputs(*noise_vars[:-1], ycrop=ycrop.flatten(), xcrop=xcrop.flatten())
                xsim += microscope(*noise_inp, add_noise=True)

            xsim_noise = microscope.noise(xsim, background, const_theta_sim=cfg.genm.exp_type.const_theta_sim).sample()


#             print('Noise. ', time.time()-t0); t0 = time.time()

            out_sim = model.tensor_to_dict(model(torch.concat([xsim_noise,colshift_crop], 1)))

#             print('Model forw. ', time.time()-t0); t0 = time.time()

            ppg = PointProcessGaussian(**out_sim)

            count_prob, spatial_prob = ppg.log_prob(*sim_vars[:5], codes=sim_vars[-1],
                                                    n_bits=cfg.genm.exp_type.n_bits, channels=cfg.genm.exp_type.n_channels,
                                                    loss_option=cfg.training.loss_option,
                                                    count_mult=cfg.training.count_mult, cat_logits=cfg.training.cat_logits,
                                                    slice_rec=cfg.genm.exp_type.slice_rec, z_sig_fac=cfg.training.z_sig_fac,
                                                    int_inf=cfg.genm.exp_type.int_inf)

            gmm_loss = -(spatial_prob + cfg.training.net.cnt_loss_scale*count_prob).mean()

            background_loss = F.mse_loss(out_sim['background'], background) * cfg.training.net.bl_loss_scale

            loss = gmm_loss + background_loss

#             print('Loss calc. ', time.time()-t0); t0 = time.time()

            # Update network parameters
            loss.backward()

            if cfg.training.net.grad_clip: torch.nn.utils.clip_grad_norm_(model.network.parameters(), max_norm=cfg.training.net.grad_clip, norm_type=2)

            optim_dict['optim_net'].step()
            optim_dict['sched_net'].step()

#             print('Grad upd. ', time.time()-t0); t0 = time.time()

        ch_out_inp = [[],[]]
        if batch_idx > min(cfg.training.start_mic,cfg.training.start_int) and batch_idx % cfg.training.mic.freq == 0:

#             out_inp = model.tensor_to_dict(model(x))
            out_inp = model.tensor_to_dict(model(torch.concat([x, colshift_crop], 1)))
            proc_out_inp = post_proc.get_micro_inp(out_inp)

            if cfg.training.mic.enabled and batch_idx > cfg.training.start_mic and len(proc_out_inp[1]) > 0: # and len(proc_out_inp[1]) < 300:
#                 print('Pre filt ', len(proc_out_inp[1]))
                ch_out_inp = microscope.get_single_ch_inputs(*proc_out_inp, ycrop=ycrop.flatten(), xcrop=xcrop.flatten())
                optim_dict['optim_mic'].zero_grad()
                calc_log_p_x = False

                # Get ch_fac loss
                ch_inds = ch_out_inp[0][1]
                int_vals = ch_out_inp[-2]

                int_means = torch.ones(cfg.genm.exp_type.n_channels).cuda()
                for i in range(cfg.genm.exp_type.n_channels):
                    if i in ch_inds:
                        int_means[i] = int_vals[ch_inds == i].mean() / int_vals.mean()

                ch_fac_loss = torch.sqrt(torch.mean((microscope.channel_facs - microscope.channel_facs.detach() / int_means)**2))

                # Get autoencoder loss
                if cfg.training.mic.roi_rec:
                    filt_inds = get_roi_filt_inds(*ch_out_inp[0], microscope.psf.psf_volume.shape, x.shape, slice_rec=cfg.genm.exp_type.slice_rec, min_dist=10)
                    ch_out_inp = mic_inp_apply_inds(*ch_out_inp, filt_inds)
                    if len(ch_out_inp[1]):
                        psf_recs = microscope(*ch_out_inp, ret_psfs=True, add_noise=False)
#                         print('N rec inds ', len(psf_recs))

                        rois = extract_psf_roi(ch_out_inp[0], x, torch.tensor(psf_recs.shape))
                        bgs = extract_psf_roi(ch_out_inp[0], out_inp['background'], torch.tensor(psf_recs.shape))

                        if cfg.training.mic.mean_diff:
                            mean_diff = rois.mean([1,2,3,4], keepdim=True) - (psf_recs.detach()+bgs).mean([1,2,3,4], keepdim=True)
                            rois -= mean_diff

#                         if cfg.training.mic.edge_diff:
#                             bg_edges = torch.cat([bgs[:,0,0,:2,:].flatten(1,2), bgs[:,0,0,-2:,:].flatten(1,2), bgs[:,0,0,:,:2].flatten(1,2), bgs[:,0,0,:,-2:].flatten(1,2)], 1)
#                             rois_edges = torch.cat([rois[:,0,0,:2,:].flatten(1,2), rois[:,0,0,-2:,:].flatten(1,2), rois[:,0,0,:,:2].flatten(1,2), rois[:,0,0,:,-2:].flatten(1,2)], 1)
#                             edge_diff = rois_edges.mean(-1) - bg_edges.mean(-1)
#                             rois -= edge_diff[:,None,None,None,None]

                        log_p_x_given_z = -microscope.noise(psf_recs, bgs, const_theta_sim=False, ch_inds=ch_out_inp[0][1]).log_prob(rois.clamp_min_(1.))

                        log_p_x_given_z = log_p_x_given_z.mean()
                        calc_log_p_x = True

                else:
                    ae_img = microscope(*ch_out_inp, add_noise=False)
                    log_p_x_given_z = -microscope.noise(ae_img, out_inp['background'], const_theta_sim=False).log_prob(x.clamp_min_(1.)).mean()
                    calc_log_p_x = True

                if calc_log_p_x:

#                     print(ch_fac_loss)
                    log_p_x_given_z += ch_fac_loss

                    if cfg.training.mic.norm_reg:
                        log_p_x_given_z += cfg.training.mic.norm_reg * (microscope.psf.com_loss())

                    if cfg.training.mic.l1_reg:
                        log_p_x_given_z += cfg.training.mic.l1_reg * (microscope.psf.l1_diff_norm(microscope.psf_init_vol))

                    log_p_x_given_z.backward()
                    if cfg.training.mic.grad_clip:
                        torch.nn.utils.clip_grad_norm_(microscope.parameters(), max_norm=cfg.training.mic.grad_clip, norm_type=2)

                    optim_dict['optim_mic'].step()

                optim_dict['sched_mic'].step()

            if  cfg.training.int.enabled and batch_idx > cfg.training.start_int:
                if len(ch_out_inp[1]):
                    optim_dict['optim_int'].zero_grad()
                    ints = ch_out_inp[-2]
                    ints = torch.clamp_min(ints, model.int_dist.int_loc.detach() + 0.01)

                    gamma_int = D.Gamma(model.int_dist.int_conc, model.int_dist.int_rate)
                    loc_trafo = [D.AffineTransform(loc=model.int_dist.int_loc.detach(), scale=1)]
                    int_loss = -D.TransformedDistribution(gamma_int, loc_trafo).log_prob(ints.detach()).mean()

                    if cfg.training.int.grad_clip:
                        torch.nn.utils.clip_grad_norm_(model.int_dist.parameters(), max_norm=cfg.training.mic.grad_clip, norm_type=2)

                    int_loss.backward()
                    optim_dict['optim_int'].step()

#                 print('INT ', time.time()-t0); t0 = time.time()

        # Logging
        if batch_idx % 10 == 0:

            if cfg.training.net.enabled:

                wandb.log({'SL Losses/xyz_loss': spatial_prob.mean().detach().cpu().item()}, step=batch_idx)
    #             wandb.log({'SL Losses/ints_loss': int_prob.mean().detach().cpu().item()}, step=batch_idx)
                wandb.log({'SL Losses/count_loss': (-count_prob.mean()).detach().cpu()}, step=batch_idx)
    #             wandb.log({'SL Losses/bg_loss': background_loss.detach().cpu()}, step=batch_idx)

#                 wandb.log({'AE Losses/int_mu': model.int_dist.int_conc.item()/model.int_dist.int_rate.item() + model.int_dist.int_loc.item()}, step=batch_idx)
#                 wandb.log({'AE Losses/int_rate': model.int_dist.int_rate.item()}, step=batch_idx)
#                 wandb.log({'AE Losses/int_loc': model.int_dist.int_loc.item()}, step=batch_idx)
                wandb.log({'AE Losses/theta': microscope.noise.theta_par.cpu().detach().mean().item()*microscope.noise.theta_scale}, step=batch_idx)

            if batch_idx > cfg.training.start_mic:
                if cfg.training.mic.enabled and calc_log_p_x:
                    wandb.log({'AE Losses/p_x_given_z': log_p_x_given_z.detach().cpu()}, step=batch_idx)
                    wandb.log({'AE Losses/RMSE(rec)': torch.sqrt(((rois-(psf_recs+bgs))**2).mean()).detach().cpu()}, step=batch_idx)
#                     wandb.log({'AE Losses/RMSE(rec)': torch.sqrt(((x[:,:1]-(ae_img[:,:1]+out_inp['background'][:,:1]))**2).mean()).detach().cpu()}, step=batch_idx)
                    wandb.log({'AE Losses/sum(psf)': F.relu(microscope.psf.psf_volume/microscope.psf.psf_volume.max())[0].sum().detach().cpu()}, step=batch_idx)
#                     wandb.log({'AE Losses/theta': microscope.theta.item()}, step=batch_idx)

#         if batch_idx > 0 and batch_idx % 1500 == 0:
#             torch.save({'state_dict':model.state_dict(), 'scaling':[model.inp_scale, model.inp_offset]}, save_dir/f'model_{batch_idx}.pkl')

        if batch_idx % cfg.output.log_interval == 0:
            print(batch_idx)

            if cfg.training.net.enabled:

                with torch.no_grad():

                    pred_df = post_proc.get_df(out_sim)
                    px_size = cfg.evaluation.px_size_zyx
                    target_df = sample_to_df(*sim_vars[:5], sim_vars[-1], px_size_zyx=px_size)
    #                 print(len(pred_df), len(target_df))
                    matches = eval_logger(pred_df, target_df, batch_idx, data_str='Sim. ')

                    wandb.log({'Sim. Metrics/prob_fac': torch.sigmoid(out_sim['logits']).sum().item()/(len(target_df)+0.1)}, step=batch_idx)
                    wandb.log({'Sim. Metrics/n_em_fac': len(pred_df)/(len(target_df)+0.1)}, step=batch_idx)

                    if cfg.output.log_figs:

                        sl_fig = sl_plot(x, xsim_noise, nm_to_px(pred_df, px_size), nm_to_px(target_df, px_size), background, out_sim)
                        plt.show()
                        wandb.log({'SL summary': sl_fig}, step=batch_idx)


                    if cfg.evaluation.code_stats.enabled:

                        crop = eval(cfg.evaluation.code_stats.crop,{'__builtins__': None},{'s_': np.s_})
                        if bench_df is None:
                            bench_df = hydra.utils.call(cfg.evaluation.code_stats.bench_func, crop=crop)

                        res_df = window_predict(model, post_proc, dl.dataset.volumes, window_size=[None, 64, 64], device='cuda', crop=crop,
                                                chrom_map=get_color_shift_inp(microscope.color_shifts, microscope.col_shifts_yx)[:,:,None], scale=microscope.get_ch_mult().detach())
                        res_df['gene'] = targets[res_df['code_inds']]
                        res_df = hydra.utils.call(cfg.evaluation.code_stats.df_postp_func, res_df=res_df)
                        exp_train_eval(bench_df, res_df, targets, wandb=wandb, batch_idx=batch_idx)


            # storing
            save_train_state(save_dir, model, microscope, optim_dict, batch_idx)

    wandb.finish()