{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp funcs.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from decode_fish.imports import *\n",
    "from decode_fish.funcs.utils import *\n",
    "from monai.inferers import sliding_window_inference\n",
    "from decode_fish.funcs.emitter_io import append_emitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of decode_fish.engine.place_psfs failed: Traceback (most recent call last):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 480, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "cfg = OmegaConf.load(f'/groups/turaga/home/speisera/Mackebox/Artur/WorkDB/deepstorm/models/fishcod/MERFISH_MOp/sweep_mop_19/norm:escortxz_facs:Truexmean_diff:Truexlr:0.0005//train.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-italian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop size larger than volume in at least one dimension. Crop size changed to (1, 56, 56)\n",
      "7 volumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from decode_fish.funcs.file_io import load_all\n",
    "model, post_proc, micro, img_3d, decode_dl = load_all(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def window_predict(model, post_proc, image_vol, window_size=[None,256,256], crop=np.s_[:,:,:,:,:], bs=1, device='cuda', chrom_map=None, scale=None, progress_bar=False):\n",
    "    pred_df = DF()\n",
    "    with torch.no_grad():\n",
    "                \n",
    "        print(image_vol.shape)\n",
    "        if image_vol.ndim == 4:\n",
    "            image_vol = image_vol[None]\n",
    "            \n",
    "        n_batches = int(np.ceil(len(image_vol)/bs))\n",
    "\n",
    "        if scale is not None:\n",
    "            image_vol = image_vol * scale.to(image_vol.device)\n",
    "\n",
    "        if chrom_map is not None:\n",
    "            image_vol = torch.concat([image_vol,chrom_map.to(image_vol.device).repeat_interleave(len(image_vol),0)], 1)\n",
    "\n",
    "        if crop is not None:\n",
    "            image_vol = image_vol[crop]\n",
    "        \n",
    "        for i in tqdm(range(n_batches), disable=not(progress_bar)):\n",
    "            inp = image_vol[i*bs:(i+1)*bs]\n",
    "            output = sliding_window_inference(inp, window_size, 1, model.to(device), overlap=0.2, sw_device=device, device='cpu', mode='gaussian')\n",
    "            output = model.tensor_to_dict(output)\n",
    "            p_si = sliding_window_inference(output['logits'], window_size, 1, post_proc, overlap=0.2, sw_device=device, device='cpu', mode='gaussian')\n",
    "            i_df = post_proc.get_df(output, p_si)\n",
    "            pred_df = append_emitter_df(pred_df, i_df)\n",
    "            free_mem()\n",
    "        \n",
    "        return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-causing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 22, 1, 2048, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [01:23<00:00, 11.91s/it]\n"
     ]
    }
   ],
   "source": [
    "res_df = window_predict(model, post_proc, decode_dl.dataset.volumes, window_size=[None, 128, 128], crop=np.s_[:,:,:,500:1500,500:1500], device='cuda', chrom_map=get_color_shift_inp(micro.color_shifts, micro.col_shifts_yx)[:,:,None], scale=micro.get_ch_mult())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_idx</th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>code_inds</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>prob</th>\n",
       "      <th>x_sig</th>\n",
       "      <th>y_sig</th>\n",
       "      <th>z_sig</th>\n",
       "      <th>...</th>\n",
       "      <th>int_17</th>\n",
       "      <th>int_sig_17</th>\n",
       "      <th>int_18</th>\n",
       "      <th>int_sig_18</th>\n",
       "      <th>int_19</th>\n",
       "      <th>int_sig_19</th>\n",
       "      <th>int_20</th>\n",
       "      <th>int_sig_20</th>\n",
       "      <th>int_21</th>\n",
       "      <th>int_sig_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74171.859375</td>\n",
       "      <td>41130.691406</td>\n",
       "      <td>26.101784</td>\n",
       "      <td>0.543179</td>\n",
       "      <td>15.858923</td>\n",
       "      <td>14.163632</td>\n",
       "      <td>10.162832</td>\n",
       "      <td>...</td>\n",
       "      <td>2.039867</td>\n",
       "      <td>0.410154</td>\n",
       "      <td>3.554771</td>\n",
       "      <td>0.424439</td>\n",
       "      <td>1.140061</td>\n",
       "      <td>0.226346</td>\n",
       "      <td>0.897971</td>\n",
       "      <td>0.254912</td>\n",
       "      <td>2.315177</td>\n",
       "      <td>0.306522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96872.078125</td>\n",
       "      <td>43359.386719</td>\n",
       "      <td>82.825485</td>\n",
       "      <td>0.505354</td>\n",
       "      <td>13.718910</td>\n",
       "      <td>24.272238</td>\n",
       "      <td>8.824762</td>\n",
       "      <td>...</td>\n",
       "      <td>2.107101</td>\n",
       "      <td>0.521238</td>\n",
       "      <td>0.985963</td>\n",
       "      <td>0.373564</td>\n",
       "      <td>0.416336</td>\n",
       "      <td>0.385557</td>\n",
       "      <td>0.498232</td>\n",
       "      <td>0.287192</td>\n",
       "      <td>4.882941</td>\n",
       "      <td>1.008928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27739.687500</td>\n",
       "      <td>51608.562500</td>\n",
       "      <td>78.598030</td>\n",
       "      <td>0.635778</td>\n",
       "      <td>25.854805</td>\n",
       "      <td>26.916786</td>\n",
       "      <td>23.552073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386799</td>\n",
       "      <td>0.474805</td>\n",
       "      <td>0.369928</td>\n",
       "      <td>0.384921</td>\n",
       "      <td>0.961122</td>\n",
       "      <td>0.961948</td>\n",
       "      <td>0.527913</td>\n",
       "      <td>0.503030</td>\n",
       "      <td>4.809768</td>\n",
       "      <td>1.074089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30754.794922</td>\n",
       "      <td>51744.761719</td>\n",
       "      <td>78.132843</td>\n",
       "      <td>0.523369</td>\n",
       "      <td>31.643612</td>\n",
       "      <td>24.412115</td>\n",
       "      <td>16.417786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738403</td>\n",
       "      <td>0.519148</td>\n",
       "      <td>1.289219</td>\n",
       "      <td>0.771810</td>\n",
       "      <td>2.058728</td>\n",
       "      <td>0.790543</td>\n",
       "      <td>1.411235</td>\n",
       "      <td>0.720317</td>\n",
       "      <td>6.489904</td>\n",
       "      <td>2.228016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19370.750000</td>\n",
       "      <td>35763.464844</td>\n",
       "      <td>59.256752</td>\n",
       "      <td>0.750923</td>\n",
       "      <td>16.137478</td>\n",
       "      <td>17.508348</td>\n",
       "      <td>16.802031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709408</td>\n",
       "      <td>0.474716</td>\n",
       "      <td>0.475889</td>\n",
       "      <td>0.369654</td>\n",
       "      <td>0.932401</td>\n",
       "      <td>0.575597</td>\n",
       "      <td>0.417964</td>\n",
       "      <td>0.362533</td>\n",
       "      <td>2.991047</td>\n",
       "      <td>0.528999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11846</th>\n",
       "      <td>11846</td>\n",
       "      <td>6</td>\n",
       "      <td>240</td>\n",
       "      <td>26360.894531</td>\n",
       "      <td>54250.007812</td>\n",
       "      <td>49.699955</td>\n",
       "      <td>0.688423</td>\n",
       "      <td>17.920855</td>\n",
       "      <td>17.689392</td>\n",
       "      <td>23.722155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410511</td>\n",
       "      <td>0.320712</td>\n",
       "      <td>0.383306</td>\n",
       "      <td>0.202143</td>\n",
       "      <td>0.497893</td>\n",
       "      <td>0.314297</td>\n",
       "      <td>0.154870</td>\n",
       "      <td>0.312463</td>\n",
       "      <td>0.175402</td>\n",
       "      <td>0.268297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>11847</td>\n",
       "      <td>6</td>\n",
       "      <td>240</td>\n",
       "      <td>26846.646484</td>\n",
       "      <td>56829.156250</td>\n",
       "      <td>22.386724</td>\n",
       "      <td>0.998641</td>\n",
       "      <td>9.082379</td>\n",
       "      <td>11.517522</td>\n",
       "      <td>9.780725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225731</td>\n",
       "      <td>0.165710</td>\n",
       "      <td>0.612131</td>\n",
       "      <td>0.209014</td>\n",
       "      <td>0.362049</td>\n",
       "      <td>0.190732</td>\n",
       "      <td>0.348656</td>\n",
       "      <td>0.164641</td>\n",
       "      <td>0.370926</td>\n",
       "      <td>0.231139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>11848</td>\n",
       "      <td>6</td>\n",
       "      <td>241</td>\n",
       "      <td>63397.339844</td>\n",
       "      <td>30798.437500</td>\n",
       "      <td>53.324135</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.773283</td>\n",
       "      <td>9.551782</td>\n",
       "      <td>7.292207</td>\n",
       "      <td>...</td>\n",
       "      <td>5.375982</td>\n",
       "      <td>0.787546</td>\n",
       "      <td>0.787245</td>\n",
       "      <td>0.279420</td>\n",
       "      <td>0.615147</td>\n",
       "      <td>0.226852</td>\n",
       "      <td>4.074576</td>\n",
       "      <td>0.527864</td>\n",
       "      <td>0.624959</td>\n",
       "      <td>0.216693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>11849</td>\n",
       "      <td>6</td>\n",
       "      <td>249</td>\n",
       "      <td>11280.794922</td>\n",
       "      <td>12305.125000</td>\n",
       "      <td>63.883244</td>\n",
       "      <td>0.564273</td>\n",
       "      <td>28.645763</td>\n",
       "      <td>25.192028</td>\n",
       "      <td>15.955474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778318</td>\n",
       "      <td>0.460973</td>\n",
       "      <td>1.964516</td>\n",
       "      <td>0.776545</td>\n",
       "      <td>2.120476</td>\n",
       "      <td>0.816587</td>\n",
       "      <td>0.940884</td>\n",
       "      <td>0.488861</td>\n",
       "      <td>1.465305</td>\n",
       "      <td>0.451530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11850</th>\n",
       "      <td>11850</td>\n",
       "      <td>6</td>\n",
       "      <td>249</td>\n",
       "      <td>81231.062500</td>\n",
       "      <td>38362.957031</td>\n",
       "      <td>82.573792</td>\n",
       "      <td>0.531801</td>\n",
       "      <td>21.793663</td>\n",
       "      <td>32.809696</td>\n",
       "      <td>19.835110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641109</td>\n",
       "      <td>0.663269</td>\n",
       "      <td>0.518250</td>\n",
       "      <td>0.368739</td>\n",
       "      <td>1.406170</td>\n",
       "      <td>0.781761</td>\n",
       "      <td>0.437730</td>\n",
       "      <td>0.544578</td>\n",
       "      <td>0.716562</td>\n",
       "      <td>0.722580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11851 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loc_idx  frame_idx  code_inds             x             y          z  \\\n",
       "0            0          0          1  74171.859375  41130.691406  26.101784   \n",
       "1            1          0          1  96872.078125  43359.386719  82.825485   \n",
       "2            2          0          1  27739.687500  51608.562500  78.598030   \n",
       "3            3          0          1  30754.794922  51744.761719  78.132843   \n",
       "4            4          0          2  19370.750000  35763.464844  59.256752   \n",
       "...        ...        ...        ...           ...           ...        ...   \n",
       "11846    11846          6        240  26360.894531  54250.007812  49.699955   \n",
       "11847    11847          6        240  26846.646484  56829.156250  22.386724   \n",
       "11848    11848          6        241  63397.339844  30798.437500  53.324135   \n",
       "11849    11849          6        249  11280.794922  12305.125000  63.883244   \n",
       "11850    11850          6        249  81231.062500  38362.957031  82.573792   \n",
       "\n",
       "           prob      x_sig      y_sig      z_sig  ...    int_17  int_sig_17  \\\n",
       "0      0.543179  15.858923  14.163632  10.162832  ...  2.039867    0.410154   \n",
       "1      0.505354  13.718910  24.272238   8.824762  ...  2.107101    0.521238   \n",
       "2      0.635778  25.854805  26.916786  23.552073  ...  0.386799    0.474805   \n",
       "3      0.523369  31.643612  24.412115  16.417786  ...  0.738403    0.519148   \n",
       "4      0.750923  16.137478  17.508348  16.802031  ...  0.709408    0.474716   \n",
       "...         ...        ...        ...        ...  ...       ...         ...   \n",
       "11846  0.688423  17.920855  17.689392  23.722155  ...  0.410511    0.320712   \n",
       "11847  0.998641   9.082379  11.517522   9.780725  ...  0.225731    0.165710   \n",
       "11848  1.000000   5.773283   9.551782   7.292207  ...  5.375982    0.787546   \n",
       "11849  0.564273  28.645763  25.192028  15.955474  ...  0.778318    0.460973   \n",
       "11850  0.531801  21.793663  32.809696  19.835110  ...  0.641109    0.663269   \n",
       "\n",
       "         int_18  int_sig_18    int_19  int_sig_19    int_20  int_sig_20  \\\n",
       "0      3.554771    0.424439  1.140061    0.226346  0.897971    0.254912   \n",
       "1      0.985963    0.373564  0.416336    0.385557  0.498232    0.287192   \n",
       "2      0.369928    0.384921  0.961122    0.961948  0.527913    0.503030   \n",
       "3      1.289219    0.771810  2.058728    0.790543  1.411235    0.720317   \n",
       "4      0.475889    0.369654  0.932401    0.575597  0.417964    0.362533   \n",
       "...         ...         ...       ...         ...       ...         ...   \n",
       "11846  0.383306    0.202143  0.497893    0.314297  0.154870    0.312463   \n",
       "11847  0.612131    0.209014  0.362049    0.190732  0.348656    0.164641   \n",
       "11848  0.787245    0.279420  0.615147    0.226852  4.074576    0.527864   \n",
       "11849  1.964516    0.776545  2.120476    0.816587  0.940884    0.488861   \n",
       "11850  0.518250    0.368739  1.406170    0.781761  0.437730    0.544578   \n",
       "\n",
       "         int_21  int_sig_21  \n",
       "0      2.315177    0.306522  \n",
       "1      4.882941    1.008928  \n",
       "2      4.809768    1.074089  \n",
       "3      6.489904    2.228016  \n",
       "4      2.991047    0.528999  \n",
       "...         ...         ...  \n",
       "11846  0.175402    0.268297  \n",
       "11847  0.370926    0.231139  \n",
       "11848  0.624959    0.216693  \n",
       "11849  1.465305    0.451530  \n",
       "11850  0.716562    0.722580  \n",
       "\n",
       "[11851 rows x 55 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data.utils import compute_importance_map, dense_patch_slices, get_valid_patch_size\n",
    "from monai.utils import BlendMode, PytorchPadMode, fall_back_tuple\n",
    "from typing import Any, Callable, List, Sequence, Tuple, Union\n",
    "import torch.nn.functional as F\n",
    "__all__ = [\"sliding_window_inference\"]\n",
    "\n",
    "\n",
    "def sliding_window_inference(\n",
    "    inputs: torch.Tensor,\n",
    "    roi_size: Union[Sequence[int], int],\n",
    "    sw_batch_size: int,\n",
    "    predictor: Callable[..., torch.Tensor],\n",
    "    overlap: float = 0.25,\n",
    "    threshold: float = -1,\n",
    "    mode: Union[BlendMode, str] = BlendMode.CONSTANT,\n",
    "    sigma_scale: Union[Sequence[float], float] = 0.125,\n",
    "    padding_mode: Union[PytorchPadMode, str] = PytorchPadMode.CONSTANT,\n",
    "    cval: float = 0.0,\n",
    "    sw_device: Union[torch.device, str, None] = None,\n",
    "    device: Union[torch.device, str, None] = None,\n",
    "    *args: Any,\n",
    "    **kwargs: Any,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Sliding window inference on `inputs` with `predictor`.\n",
    "\n",
    "    When roi_size is larger than the inputs' spatial size, the input image are padded during inference.\n",
    "    To maintain the same spatial sizes, the output image will be cropped to the original input size.\n",
    "\n",
    "    Args:\n",
    "        inputs: input image to be processed (assuming NCHW[D])\n",
    "        roi_size: the spatial window size for inferences.\n",
    "            When its components have None or non-positives, the corresponding inputs dimension will be used.\n",
    "            if the components of the `roi_size` are non-positive values, the transform will use the\n",
    "            corresponding components of img size. For example, `roi_size=(32, -1)` will be adapted\n",
    "            to `(32, 64)` if the second spatial dimension size of img is `64`.\n",
    "        sw_batch_size: the batch size to run window slices.\n",
    "        predictor: given input tensor `patch_data` in shape NCHW[D], `predictor(patch_data)`\n",
    "            should return a prediction with the same spatial shape and batch_size, i.e. NMHW[D];\n",
    "            where HW[D] represents the patch spatial size, M is the number of output channels, N is `sw_batch_size`.\n",
    "        overlap: Amount of overlap between scans.\n",
    "        mode: {``\"constant\"``, ``\"gaussian\"``}\n",
    "            How to blend output of overlapping windows. Defaults to ``\"constant\"``.\n",
    "\n",
    "            - ``\"constant``\": gives equal weight to all predictions.\n",
    "            - ``\"gaussian``\": gives less weight to predictions on edges of windows.\n",
    "\n",
    "        sigma_scale: the standard deviation coefficient of the Gaussian window when `mode` is ``\"gaussian\"``.\n",
    "            Default: 0.125. Actual window sigma is ``sigma_scale`` * ``dim_size``.\n",
    "            When sigma_scale is a sequence of floats, the values denote sigma_scale at the corresponding\n",
    "            spatial dimensions.\n",
    "        padding_mode: {``\"constant\"``, ``\"reflect\"``, ``\"replicate\"``, ``\"circular\"``}\n",
    "            Padding mode for ``inputs``, when ``roi_size`` is larger than inputs. Defaults to ``\"constant\"``\n",
    "            See also: https://pytorch.org/docs/stable/nn.functional.html#pad\n",
    "        cval: fill value for 'constant' padding mode. Default: 0\n",
    "        sw_device: device for the window data.\n",
    "            By default the device (and accordingly the memory) of the `inputs` is used.\n",
    "            Normally `sw_device` should be consistent with the device where `predictor` is defined.\n",
    "        device: device for the stitched output prediction.\n",
    "            By default the device (and accordingly the memory) of the `inputs` is used. If for example\n",
    "            set to device=torch.device('cpu') the gpu memory consumption is less and independent of the\n",
    "            `inputs` and `roi_size`. Output is on the `device`.\n",
    "        args: optional args to be passed to ``predictor``.\n",
    "        kwargs: optional keyword args to be passed to ``predictor``.\n",
    "\n",
    "    Note:\n",
    "        - input must be channel-first and have a batch dim, supports N-D sliding window.\n",
    "\n",
    "    \"\"\"\n",
    "    num_spatial_dims = len(inputs.shape) - 2\n",
    "    if overlap < 0 or overlap >= 1:\n",
    "        raise AssertionError(\"overlap must be >= 0 and < 1.\")\n",
    "\n",
    "    # determine image spatial size and batch size\n",
    "    # Note: all input images must have the same image size and batch size\n",
    "    image_size_ = list(inputs.shape[2:])\n",
    "    batch_size = inputs.shape[0]\n",
    "\n",
    "    if device is None:\n",
    "        device = inputs.device\n",
    "    if sw_device is None:\n",
    "        sw_device = inputs.device\n",
    "\n",
    "    roi_size = fall_back_tuple(roi_size, image_size_)\n",
    "    # in case that image size is smaller than roi size\n",
    "    image_size = tuple(max(image_size_[i], roi_size[i]) for i in range(num_spatial_dims))\n",
    "    pad_size = []\n",
    "    for k in range(len(inputs.shape) - 1, 1, -1):\n",
    "        diff = max(roi_size[k - 2] - inputs.shape[k], 0)\n",
    "        half = diff // 2\n",
    "        pad_size.extend([half, diff - half])\n",
    "    inputs = F.pad(inputs, pad=pad_size, mode=PytorchPadMode(padding_mode).value, value=cval)\n",
    "\n",
    "    scan_interval = _get_scan_interval(image_size, roi_size, num_spatial_dims, overlap)\n",
    "\n",
    "    # Store all slices in list\n",
    "    slices = dense_patch_slices(image_size, roi_size, scan_interval)\n",
    "    num_win = len(slices)  # number of windows per image\n",
    "    total_slices = num_win * batch_size  # total number of windows\n",
    "\n",
    "    # Create window-level importance map\n",
    "    importance_map = compute_importance_map(\n",
    "        get_valid_patch_size(image_size, roi_size), mode=mode, sigma_scale=sigma_scale, device=device\n",
    "    )\n",
    "    window_output_shape = None\n",
    "    counter = 0\n",
    "\n",
    "    # Perform predictions\n",
    "    output_image, count_map = torch.tensor(0.0, device=device), torch.tensor(0.0, device=device)\n",
    "    _initialized = False\n",
    "    for slice_g in range(0, total_slices, sw_batch_size):\n",
    "        slice_range = range(slice_g, min(slice_g + sw_batch_size, total_slices))\n",
    "        unravel_slice = [\n",
    "            [slice(int(idx / num_win), int(idx / num_win) + 1), slice(None)] + list(slices[idx % num_win])\n",
    "            for idx in slice_range\n",
    "        # ]\n",
    "        window_data = torch.cat([inputs[win_slice] for win_slice in unravel_slice]).to(sw_device)\n",
    "        if window_data.max() > threshold or window_output_shape is None:\n",
    "            seg_prob = predictor(window_data, *args, **kwargs).to(device)  # batched patch segmentation\n",
    "            window_output_shape = seg_prob.shape\n",
    "            counter += 1\n",
    "        else:\n",
    "            seg_prob = torch.zeros(window_output_shape) - 100\n",
    "\n",
    "        if not _initialized:  # init. buffer at the first iteration\n",
    "            output_classes = seg_prob.shape[1]\n",
    "            output_shape = [batch_size, output_classes] + list(image_size)\n",
    "            # allocate memory to store the full output and the count for overlapping parts\n",
    "            output_image = torch.zeros(output_shape, dtype=torch.float32, device=device)\n",
    "            count_map = torch.zeros(output_shape, dtype=torch.float32, device=device)\n",
    "            _initialized = True\n",
    "\n",
    "        # store the result in the proper location of the full output. Apply weights from importance map.\n",
    "        for idx, original_idx in zip(slice_range, unravel_slice):\n",
    "            output_image[original_idx] += importance_map * seg_prob[idx - slice_g]\n",
    "            count_map[original_idx] += importance_map\n",
    "\n",
    "    # account for any overlapping sections\n",
    "    output_image = output_image / count_map\n",
    "\n",
    "    final_slicing: List[slice] = []\n",
    "    for sp in range(num_spatial_dims):\n",
    "        slice_dim = slice(pad_size[sp * 2], image_size_[num_spatial_dims - sp - 1] + pad_size[sp * 2])\n",
    "        final_slicing.insert(0, slice_dim)\n",
    "    while len(final_slicing) < len(output_image.shape):\n",
    "        final_slicing.insert(0, slice(None))\n",
    "        \n",
    "    print(counter)\n",
    "    return output_image[final_slicing]\n",
    "\n",
    "\n",
    "def _get_scan_interval(\n",
    "    image_size: Sequence[int], roi_size: Sequence[int], num_spatial_dims: int, overlap: float\n",
    ") -> Tuple[int, ...]:\n",
    "    \"\"\"\n",
    "    Compute scan interval according to the image size, roi size and overlap.\n",
    "    Scan interval will be `int((1 - overlap) * roi_size)`, if interval is 0,\n",
    "    use 1 instead to make sure sliding window works.\n",
    "\n",
    "    \"\"\"\n",
    "    if len(image_size) != num_spatial_dims:\n",
    "        raise ValueError(\"image coord different from spatial dims.\")\n",
    "    if len(roi_size) != num_spatial_dims:\n",
    "        raise ValueError(\"roi coord different from spatial dims.\")\n",
    "\n",
    "    scan_interval = []\n",
    "    for i in range(num_spatial_dims):\n",
    "        if roi_size[i] == image_size[i]:\n",
    "            scan_interval.append(int(roi_size[i]))\n",
    "        else:\n",
    "            interval = int(roi_size[i] * (1 - overlap))\n",
    "            scan_interval.append(interval if interval > 0 else 1)\n",
    "    return tuple(scan_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_predict(model, post_proc, image_paths, window_size=[None, 128, 128], threshold=-1e6, device='cuda'):\n",
    "    pred_df = DF()\n",
    "    with torch.no_grad():\n",
    "        for p in tqdm(image_paths):\n",
    "            print(p.split('/')[-1])\n",
    "            img = load_tiff_image(p)\n",
    "            z,y,x = img.shape[-3:]\n",
    "            img = img.reshape(-1,z,y,x)\n",
    "            for i in range(len(img)):\n",
    "                print(img[i][None,None].shape)\n",
    "                output = sliding_window_inference(img[i][None,None], window_size, sw_batch_size=1, predictor=model.to(device), overlap=0.2, threshold=threshold, sw_device=device, device='cpu', mode='gaussian')\n",
    "                # output = model.cpu()(img[i][None,None])\n",
    "                output = model.tensor_to_dict(output)\n",
    "                p_si = sliding_window_inference(output['logits'], window_size, sw_batch_size=1, predictor=post_proc, overlap=0.2, threshold=-5, sw_device=device, device='cpu', mode='gaussian')\n",
    "                i_df = post_proc.get_df(output, p_si)\n",
    "                print('N. emitters: ', len(i_df))\n",
    "                pred_df = append_emitter_df(pred_df, i_df)\n",
    "                free_mem()\n",
    "        return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-hands",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_1_smfish_fov_1.tif\n",
      "torch.Size([1, 1, 23, 650, 500])\n",
      "130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.46s/it]\n",
      "  0%|                                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "N. emitters:  737\n",
      "experiment_1_smfish_fov_1.tif\n",
      "torch.Size([1, 1, 23, 650, 500])\n",
      "130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "  0%|                                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "N. emitters:  737\n",
      "experiment_1_smfish_fov_1.tif\n",
      "torch.Size([1, 1, 23, 650, 500])\n",
      "130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "N. emitters:  737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_1_smfish_fov_1.tif\n",
      "torch.Size([1, 1, 23, 650, 500])\n",
      "130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.36s/it]\n",
      "  0%|                                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "N. emitters:  737\n",
      "experiment_1_smfish_fov_1.tif\n",
      "torch.Size([1, 1, 23, 650, 500])\n",
      "130\n",
      "84\n",
      "N. emitters:  737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.249284982681274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(5):\n",
    "    pred_df = selective_predict(model, post_proc, image_paths, threshold=0)\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-import",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of decode_fish.engine.place_psfs failed: Traceback (most recent call last):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 480, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/groups/turaga/home/speisera/anaconda3/envs/decode_fish_dev2/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 329, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_psf.ipynb.\n",
      "Converted 02_microscope.ipynb.\n",
      "Converted 02b_place_psfs.ipynb.\n",
      "Converted 03_noise.ipynb.\n",
      "Converted 04_pointsource.ipynb.\n",
      "Converted 05_gmm_loss.ipynb.\n",
      "Converted 06_plotting.ipynb.\n",
      "Converted 07_file_io.ipynb.\n",
      "Converted 08_dataset.ipynb.\n",
      "Converted 09_output_trafo.ipynb.\n",
      "Converted 10_evaluation.ipynb.\n",
      "Converted 11_emitter_io.ipynb.\n",
      "Converted 12_utils.ipynb.\n",
      "Converted 13_train.ipynb.\n",
      "Converted 15_fit_psf.ipynb.\n",
      "Converted 16_visualization.ipynb.\n",
      "Converted 17_eval_routines.ipynb.\n",
      "Converted 18_predict_funcs.ipynb.\n",
      "Converted 19_MERFISH_routines.ipynb.\n",
      "Converted 22_MERFISH_codenet.ipynb.\n",
      "Converted 23_MERFISH_comparison.ipynb.\n",
      "Converted 24_exp_specific.ipynb.\n",
      "Converted 25_ensembling.ipynb.\n",
      "Converted 25_gen_train.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-whole",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decode_fish_dev2]",
   "language": "python",
   "name": "conda-env-decode_fish_dev2-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
